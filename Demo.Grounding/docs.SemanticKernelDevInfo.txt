Introduction
Completed
100 XP
3 minutes
Suppose you're a developer for Margie's Travel, a global leader in the travel and hospitality industry. The company offers a wide range of services, including flight bookings, hotel reservations, guided tours, and vacation packages. Margie's Travel has a strong global presence, with offices and partners in major cities worldwide. With a commitment to delivering exceptional travel experiences, Margie's Travel is continuously exploring innovative technologies to enhance customer interactions and streamline travel planning. Now they're exploring the integration of cutting-edge artificial intelligence (AI) technology to enhance their services.

To provide travelers with personalized and immersive travel experiences, Margie's Travel decides to integrate a chatbot application into its digital platform. This chatbot, named "TravelBot", is a virtual travel assistant, helping customers plan their trips, discover new destinations, and create detailed itineraries.

You're tasked with creating a proof of concept for TravelBot, demonstrating its ability to understand natural language queries, provide intelligent responses, and assist travelers in planning their trips. To power TravelBot's intelligence and conversational capabilities, you choose to use the Semantic Kernel SDK.

This module guides you through the steps required to develop a proof of concept AI Travel assistant chatbot using the Semantic Kernel SDK. By the end of this module, you complete a small chatbot application that can understand user queries, generate intelligent responses, and provide personalized travel recommendations.

 Note

This is a guided project module where you complete an end-to-end project by following step-by-step instructions. 

Learning objectives
In this module, you practice how to:

Create plugins for the Semantic Kernel.
Create prompts to elicit the best responses from the large language model (LLM).
Manipulate LLM responses to guide the execution of code.
Automatically invoke the correct plugins to complete tasks.
Prerequisites
Experience programming in C#.
Visual Studio Code IDE installed.
Familiarity with Azure and the Azure portal.
Access to Azure OpenAI Services.
Experience creating plugins using the Semantic Kernel SDK.
Experience using Semantic Kernel auto function calling.
Prepare for guided project
Completed
100 XP
5 minutes
This module is a guided project where you use Visual Studio Code to develop a proof-of-concept artificially intelligent travel assistant. The project demonstrates how the Semantic Kernel SDK can interface with a large language model (LLM) to process and retrieve information, and integrate native code to perform specialized tasks. In this project, you develop the functionality to assist users with their travel plans. Let's start by setting up your development environment!

Project overview
In this project, you apply what you learned about the Semantic Kernel SDK. The AI Travel Agent project uses Visual Studio Code to simulate a travel agent that performs tasks such as destination recommendation, currency conversion, and more. This project demonstrates how the Semantic Kernel SDK can be used to create artificially intelligent agents that can automate custom tasks.

Setup
Use the following steps to prepare for the Guided Project exercises:

 Important

You must have .NET Framework 8.0 installed and a Github account to complete these steps.

Open Visual Studio Code

Under the Visual Studio Code Start section, select Clone Git Repository

In the URL bar, enter https://github.com/MicrosoftLearning/APL-2005-Guided-Project.git

In the File Explorer, create a new folder in a location that is easy to find and remember, such as a folder in your Desktop

Click the Select as Repository Destination button

You need to be signed in to GitHub to successfully clone the project

Open the project in Visual Studio Code

In Explorer, right-click the AITravelAgent/Starter folder and click Open in Integrated Terminal

Expand the Starter folder

You should see a "Plugins" folder, a "Prompts" folder, and "Program.cs" file.

Open the Program.cs file and update the following variables with your Azure OpenAI Services deployment name, API key, endpoint

C#

Copy
string yourDeploymentName = "";
string yourEndpoint = "";
string yourKey = "";
 Note

The deployment model must be "gpt-35-turbo-16k" for some of the Semantic Kernel SDK features to work.

Now you're ready to begin the Guided Project exercises. 
Exercise - Create a currency converter
Completed
100 XP
10 minutes
For this exercise, you create a plugin that allows the user to convert currency amounts from one currency to another. Since the model can't access the internet to determine the current exchange rate, you need to provide the exchange rates into your plugin. For this exercise, you use an existing currencies.txt file to provide the exchange rates.

 Important

You need to complete the Setup instructions in the previous unit, Prepare, before you begin this exercise.

Create a native function
In this task, you create a native function that can convert an amount from a base currency to a target currency.

Create a new file named CurrencyConverter.cs in the Plugins/ConvertCurrency folder

In the CurrencyConverter.cs file, add the following code to create a plugin function:

c#

Copy
using AITravelAgent;

class CurrencyConverter
{
    [KernelFunction, 
    Description("Convert an amount from one currency to another")]
    public static string ConvertAmount()
    {
        var currencyDictionary = Currency.Currencies;
    }
}
In this code, you use the KernelFunction decorator to declare your native function. You also use the Description decorator to add a description of what the function does. You can use Currency.Currencies to get a dictionary of currencies and their exchange rates. Next, add some logic to convert a given amount from one currency to another.

Modify your ConvertAmount function with the following code:

c#

Copy
[KernelFunction, Description("Convert an amount from one currency to another")]
public static string ConvertAmount(
    [Description("The target currency code")] string targetCurrencyCode, 
    [Description("The amount to convert")] string amount, 
    [Description("The starting currency code")] string baseCurrencyCode)
{
    var currencyDictionary = Currency.Currencies;

    Currency targetCurrency = currencyDictionary[targetCurrencyCode];
    Currency baseCurrency = currencyDictionary[baseCurrencyCode];

    if (targetCurrency == null)
    {
        return targetCurrencyCode + " was not found";
    }
    else if (baseCurrency == null)
    {
        return baseCurrencyCode + " was not found";
    }
    else
    {
        double amountInUSD = Double.Parse(amount) * baseCurrency.USDPerUnit;
        double result = amountInUSD * targetCurrency.UnitsPerUSD;
        return @$"${amount} {baseCurrencyCode} is approximately 
            {result.ToString("C")} in {targetCurrency.Name}s ({targetCurrencyCode})";
    }
}
In this code, you use the Currency.Currencies dictionary to get the Currency object for the target and base currencies. You then use the Currency object to convert the amount from the base currency to the target currency. Finally, you return a string with the converted amount. Next, let's test your plugin.

 Note

When using the Semantic Kernel SDK in your own projects, you don't need to hardcode data into files if you have access to RESTful APIs. Instead, you can use the Plugins.Core.HttpClient plugin to retrieve data from APIs.

In the Program.cs file, import and invoke your new plugin function with the following code:

c#

Copy
kernel.ImportPluginFromType<CurrencyConverter>();
kernel.ImportPluginFromType<ConversationSummaryPlugin>();
var prompts = kernel.ImportPluginFromPromptDirectory("Prompts");

var result = await kernel.InvokeAsync("CurrencyConverter", 
    "ConvertAmount", 
    new() {
        {"targetCurrencyCode", "USD"}, 
        {"amount", "52000"}, 
        {"baseCurrencyCode", "VND"}
    }
);

Console.WriteLine(result);
In this code, you use the ImportPluginFromType method to import your plugin. Then you use the InvokeAsync method to invoke your plugin function. The InvokeAsync method takes the plugin name, function name, and a dictionary of parameters. Finally, you print the result to the console. Next, run the code to make sure it's working.

In the terminal, enter dotnet run. You should see the following output:

Output

Copy
$52000 VND is approximately $2.13 in US Dollars (USD)
Now that your plugin is working correctly, let's create a natural language prompt that can detect what currencies and amount the user wants to convert.

Create a prompt
In this task, you create a prompt that parses the user's input to identify the target currency, base currency, and amount to convert.

Create a new folder named GetTargetCurrencies in the Prompts folder

In the GetTargetCurrencies folder, create a new file named config.json

Enter the following text into the config.json file:

Output

Copy
{
    "schema": 1,
    "type": "completion",
    "description": "Identify the target currency, base currency, and amount to convert",
    "execution_settings": {
        "default": {
            "max_tokens": 800,
            "temperature": 0
        }
    },
    "input_variables": [
        {
            "name": "input",
            "description": "Text describing some currency amount to convert",
            "required": true
        }
    ]
}
In the GetTargetCurrencies folder, create a new file named skprompt.txt

Enter the following text into the skprompt.txt file:

HTML

Copy
<message role="system">Identify the target currency, base currency, and 
amount from the user's input in the format target|base|amount</message>

For example: 

<message role="user">How much in GBP is 750.000 VND?</message>
<message role="assistant">GBP|VND|750000</message>

<message role="user">How much is 60 USD in New Zealand Dollars?</message>
<message role="assistant">NZD|USD|60</message>

<message role="user">How many Korean Won is 33,000 yen?</message>
<message role="assistant">KRW|JPY|33000</message>

<message role="user">{{$input}}</message>
<message role="assistant">target|base|amount</message>
Check your work
In this task, you run your application and verify your code is working correctly.

Test your new prompt by updating your Program.cs file with the following code:

c#

Copy
kernel.ImportPluginFromType<CurrencyConverter>();
var prompts = kernel.ImportPluginFromPromptDirectory("Prompts");

var result = await kernel.InvokeAsync(prompts["GetTargetCurrencies"],
    new() {
        {"input", "How many Australian Dollars is 140,000 Korean Won worth?"}
    }
);

Console.WriteLine(result);
Enter dotnet run in the terminal. You should see the following output:

Output

Copy
AUD|KRW|140000
 Note

If your code doesn't produce the output you expected, you can review the code in the Solution folder. You may need to adjust the prompt in the skprompt.txt file to produce more exact results.

Now you have a plugin that can convert an amount from one currency to another, and a prompt that can be used to parse the user's input into a format the ConvertAmount function can use. In the next exercise, you can use the user's intent to run your functions.

Exercise - Route user intent
Completed
100 XP
10 minutes
In this exercise, you detect the user's intent and route the conversation to the desired plugins. You can use a provided plugin to retrieve the user's intent. Let's get started!

Update your Program.cs file with the following code:

c#

Copy
kernel.ImportPluginFromType<CurrencyConverter>();
var prompts = kernel.ImportPluginFromPromptDirectory("Prompts");

Console.WriteLine("What would you like to do?");
var input = Console.ReadLine();

var intent = await kernel.InvokeAsync<string>(
    prompts["GetIntent"], 
    new() {{ "input",  input }}
);

In this code, you use the GetIntent prompt to detect the user's intent. You then store the intent in a variable called intent. Next, you route the intent to your CurrencyConverter plugin.

Add the following code to your Program.cs file:

c#

Copy
switch (intent) {
    case "ConvertCurrency": 
        var currencyText = await kernel.InvokeAsync<string>(
            prompts["GetTargetCurrencies"], 
            new() {{ "input",  input }}
        );
        var currencyInfo = currencyText!.Split("|");
        var result = await kernel.InvokeAsync("CurrencyConverter", 
            "ConvertAmount", 
            new() {
                {"targetCurrencyCode", currencyInfo[0]}, 
                {"baseCurrencyCode", currencyInfo[1]},
                {"amount", currencyInfo[2]}, 
            }
        );
        Console.WriteLine(result);
        break;
    default:
        Console.WriteLine("Other intent detected");
        break;
}
The GetIntent plugin returns the following values: ConvertCurrency, SuggestDestinations, SuggestActivities, Translate, HelpfulPhrases, Unknown. You use a switch statement to route the user's intent to the appropriate plugin.

If the user's intent is to convert currency, you use the GetTargetCurrencies prompt to retrieve the currency information. Then you use the CurrencyConverter plugin to convert the amount.

Next, you add some cases to handle the other intents. For now, let's use the automatic function calling capability of the Semantic Kernel SDK to route the intent to the available plugins.

Create the automatic function calling setting by adding the following code to your Program.cs file:

c#

Copy
kernel.ImportPluginFromType<CurrencyConverter>();
var prompts = kernel.ImportPluginFromPromptDirectory("Prompts");

OpenAIPromptExecutionSettings settings = new()
{
    ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions
};

Console.WriteLine("What would you like to do?");
var input = Console.ReadLine();
var intent = await kernel.InvokeAsync<string>(
    prompts["GetIntent"], 
    new() {{ "input",  input }}
);
Next, you add cases to the switch statement for the other intents.

Update your Program.cs file with the following code:

c#

Copy
switch (intent) {
    case "ConvertCurrency": 
        // ...Code you entered previously...
        break;
    case "SuggestDestinations":
    case "SuggestActivities":
    case "HelpfulPhrases":
    case "Translate":
        var autoInvokeResult = await kernel.InvokePromptAsync(input!, new(settings));
        Console.WriteLine(autoInvokeResult);
        break;
    default:
        Console.WriteLine("Other intent detected");
        break;
}
In this code, you use the AutoInvokeKernelFunctions setting to automatically call functions and prompts that are referenced in your kernel. If the user's intent is to convert currency, the CurrencyConverter plugin performs its task.

If the user's intent is to get destination or activity suggestions, translate a phrase, or get helpful phrases in a language, the AutoInvokeKernelFunctions setting automatically calls the existing plugins that were included in the project code.

You can also add code to run the user's input as a prompt to the large language model (LLM) if it doesn't fall under any of these intent cases.

Update the default case with the following code:

c#

Copy
default:
    Console.WriteLine("Sure, I can help with that.");
    var otherIntentResult = await kernel.InvokePromptAsync(input!, new(settings));
    Console.WriteLine(otherIntentResult);
    break;
Now if the user has a different intent, the LLM can handle the user's request. Let's try it out!

Check your work
In this task, you run your application and verify your code is working correctly.

Enter dotnet run in the terminal. When prompted, enter some text similar to the following prompt:

Output

Copy
What would you like to do?
How many TTD is 50 Qatari Riyals?    
You should see output similar to the following response:

Output

Copy
$50 QAR is approximately $93.10 in Trinidadian Dollars (TTD)
Enter dotnet run in the terminal. When prompted, enter some text similar to the following prompt:

Output

Copy
What would you like to do?
I want to go somewhere that has lots of warm sunny beaches and delicious, spicy food!
You should see output similar to the following response:

Output

Copy
Based on your preferences for warm sunny beaches and delicious, spicy food, I have a few destination recommendations for you:

1. Thailand: Known for its stunning beaches, Thailand offers a perfect combination of relaxation and adventure. You can visit popular beach destinations like Phuket, Krabi, or Koh Samui, where you'll find crystal-clear waters and white sandy shores. Thai cuisine is famous for its spiciness, so you'll have plenty of mouthwatering options to try, such as Tom Yum soup, Pad Thai, and Green Curry.

2. Mexico: Mexico is renowned for its beautiful coastal regions and vibrant culture. You can explore destinations like Cancun, Playa del Carmen, or Tulum, which boast stunning beaches along the Caribbean Sea. Mexican cuisine is rich in flavors and spices, offering a wide variety of dishes like tacos, enchiladas, and mole sauces that will satisfy your craving for spicy food.

...

These destinations offer a perfect blend of warm sunny beaches and delicious, spicy food, ensuring a memorable trip for you. Let me know if you need any further assistance or if you have any specific preferences for your trip!
Enter dotnet run in the terminal. When prompted, enter some text similar to the following prompt:

Output

Copy
What would you like to do?
Can you give me a recipe for chicken satay?

You should see a response similar to the following response:

Output

Copy
Sure, I can help with that.
Certainly! Here's a recipe for chicken satay:

...
The intent should be routed to your default case and the LLM should handle the request for a chicken satay recipe, how delicious!

 Note

If your code doesn't produce the output you expected, you can review the code in the Solution folder.

Next, let's modify the routing logic to provide some conversation history to certain plugins. Providing history allows the plugins to retrieve more contextually relevant responses to the user's requests.

Exercise - Provide context cues
Completed
100 XP
10 minutes
In this exercise, you use the conversation history to provide context to the large language model (LLM). You also adjust the code so that it allows the user to continue the conversation, just like a real chatbot. Let's get started!

Modify the code to use a do-while loop to accept the user's input:

c#

Copy
string input;

do 
{
    Console.WriteLine("What would you like to do?");
    input = Console.ReadLine();

    // ...
}
while (!string.IsNullOrWhiteSpace(input));
Now you can keep the conversation going until the user enters a blank line.

Capture details about the user's trip by modifying the SuggestDestinations case:

c#

Copy
case "SuggestDestinations":
    chatHistory.AppendLine("User:" + input);
    var recommendations = await kernel.InvokePromptAsync(input!);
    Console.WriteLine(recommendations);
    break;
Use the trip details in the SuggestActivities case with the following code:

c#

Copy
 case "SuggestActivities":
    var chatSummary = await kernel.InvokeAsync(
        "ConversationSummaryPlugin", 
        "SummarizeConversation", 
        new() {{ "input", chatHistory.ToString() }});
    break;
In this code, you use the built-in SummarizeConversation function to summarize the chat with the user. Next, let's use the summary to suggest activities at the destination.

Extend the SuggestActivities case with the following code:

c#

Copy
var activities = await kernel.InvokePromptAsync(
    input,
    new () {
        {"input", input},
        {"history", chatSummary},
        {"ToolCallBehavior", ToolCallBehavior.AutoInvokeKernelFunctions}
});

chatHistory.AppendLine("User:" + input);
chatHistory.AppendLine("Assistant:" + activities.ToString());

Console.WriteLine(activities);
break;
In this code, you add input and chatSummary as kernel arguments. Then the kernel invokes the prompt and routes it to the SuggestActivities plugin. You also append the user's input and the assistant's response to the chat history and display the results. Next, you need to add the chatSummary variable to the SuggestActivities plugin.

Navigate to Prompts/SuggestActivities/config.json and open the file in Visual Studio Code

Under input_variables, add a variable for the chat history:

JSON

Copy
"input_variables": [
  {
      "name": "history",
      "description": "Some background information about the user",
      "required": false
  },
  {
      "name": "destination",
      "description": "The destination a user wants to visit",
      "required": true
  }
  ]
Navigate to Prompts/SuggestActivities/skprompt.txt and open the file

Add a prompt to use the chat history:

HTML

Copy
You are an experienced travel agent. 
You are helpful, creative, and very friendly. 
Consider the traveler's background: {{$history}}
Leave the rest of the prompt as is. Now the plugin uses the chat history to provide context to the LLM.

Check your work
In this task, you run your application and verify the code is working correctly.

Compare your updated switch cases to the following code:

c#

Copy
case "SuggestDestinations":
        chatHistory.AppendLine("User:" + input);
        var recommendations = await kernel.InvokePromptAsync(input!);
        Console.WriteLine(recommendations);
        break;
case "SuggestActivities":

    var chatSummary = await kernel.InvokeAsync(
        "ConversationSummaryPlugin", 
        "SummarizeConversation", 
        new() {{ "input", chatHistory.ToString() }});

    var activities = await kernel.InvokePromptAsync(
        input!,
        new () {
            {"input", input},
            {"history", chatSummary},
            {"ToolCallBehavior", ToolCallBehavior.AutoInvokeKernelFunctions}
    });

    chatHistory.AppendLine("User:" + input);
    chatHistory.AppendLine("Assistant:" + activities.ToString());

    Console.WriteLine(activities);
    break;
Enter dotnet run in the terminal. When prompted, enter some text similar to the following:

Output

Copy
What would you like to do?
How much is 60 USD in new zealand dollars?
You should receive some output similar to the following:

Output

Copy
$60 USD is approximately $97.88 in New Zealand Dollars (NZD)
What would you like to do?
Enter a prompt for destination suggestions with some context cues, for example:

Output

Copy
What would you like to do?
I'm planning an anniversary trip with my spouse, but they are currently using a wheelchair and accessibility is a must. What are some destinations that would be romantic for us?
You should receive some output with recommendations of accessible destinations.

Enter a prompt for activity suggestions, for example:

Output

Copy
What would you like to do?
What are some things to do in Barcelona?
You should receive recommendations that fit within the previous context, for example, accessible activities in Barcelona similar to the following:

Output

Copy
1. Visit the iconic Sagrada Família: This breathtaking basilica is an iconic symbol of Barcelona's architecture and is known for its unique design by Antoni Gaudí.

2. Explore Park Güell: Another masterpiece by Gaudí, this park offers stunning panoramic views of the city, intricate mosaic work, and whimsical architectural elements.

3. Visit the Picasso Museum: Explore the extensive collection of artworks by the iconic painter Pablo Picasso, showcasing his different periods and styles.
 Note

If your code doesn't produce the output you expected, you can review the code in the Solution folder.

You can continue to test the application with different prompts and context cues. Great work! You've successfully provided context cues to the LLM and adjusted the code to allow the user to continue the conversation.











# Semantic Kernel

## Status

- Python <br/>
  [![Python package](https://img.shields.io/pypi/v/semantic-kernel)](https://pypi.org/project/semantic-kernel/)
- .NET <br/>
  [![Nuget package](https://img.shields.io/nuget/vpre/Microsoft.SemanticKernel)](https://www.nuget.org/packages/Microsoft.SemanticKernel/)[![dotnet Docker](https://github.com/microsoft/semantic-kernel/actions/workflows/dotnet-ci-docker.yml/badge.svg?branch=main)](https://github.com/microsoft/semantic-kernel/actions/workflows/dotnet-ci-docker.yml)[![dotnet Windows](https://github.com/microsoft/semantic-kernel/actions/workflows/dotnet-ci-windows.yml/badge.svg?branch=main)](https://github.com/microsoft/semantic-kernel/actions/workflows/dotnet-ci-windows.yml)
- Java <br/>
  [![Java CICD Builds](https://github.com/microsoft/semantic-kernel/actions/workflows/java-build.yml/badge.svg?branch=java-development)](https://github.com/microsoft/semantic-kernel/actions/workflows/java-build.yml)[![Maven Central](https://maven-badges.herokuapp.com/maven-central/com.microsoft.semantic-kernel/semantickernel-api/badge.svg)](https://maven-badges.herokuapp.com/maven-central/com.microsoft.semantic-kernel/semantickernel-api)

## Overview

[![License: MIT](https://img.shields.io/github/license/microsoft/semantic-kernel)](https://github.com/microsoft/semantic-kernel/blob/main/LICENSE)
[![Discord](https://img.shields.io/discord/1063152441819942922?label=Discord&logo=discord&logoColor=white&color=d82679)](https://aka.ms/SKDiscord)

[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/)
is an SDK that integrates Large Language Models (LLMs) like
[OpenAI](https://platform.openai.com/docs/introduction),
[Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service),
and [Hugging Face](https://huggingface.co/)
with conventional programming languages like C#, Python, and Java. Semantic Kernel achieves this
by allowing you to define [plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins)
that can be chained together
in just a [few lines of code](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/chaining-functions?tabs=Csharp#using-the-runasync-method-to-simplify-your-code).

What makes Semantic Kernel _special_, however, is its ability to _automatically_ orchestrate
plugins with AI. With Semantic Kernel
[planners](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/planner), you
can ask an LLM to generate a plan that achieves a user's unique goal. Afterwards,
Semantic Kernel will execute the plan for the user.

It provides:

- abstractions for AI services (such as chat, text to images, audio to text, etc.) and memory stores
- implementations of those abstractions for services from [OpenAI](https://platform.openai.com/docs/introduction), [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service), [Hugging Face](https://huggingface.co/), local models, and more, and for a multitude of vector databases, such as those from [Chroma](https://docs.trychroma.com/getting-started), [Qdrant](https://qdrant.tech/), [Milvus](https://milvus.io/), and [Azure](https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search)
- a common representation for [plugins](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/plugins), which can then be orchestrated automatically by AI
- the ability to create such plugins from a multitude of sources, including from OpenAPI specifications, prompts, and arbitrary code written in the target language
- extensible support for prompt management and rendering, including built-in handling of common formats like Handlebars and Liquid
- and a wealth of functionality layered on top of these abstractions, such as filters for responsible AI, dependency injection integration, and more.

Semantic Kernel is utilized by enterprises due to its flexibility, modularity and observability. Backed with security enhancing capabilities like telemetry support, and hooks and filters so you’ll feel confident you’re delivering responsible AI solutions at scale.
Semantic Kernel was designed to be future proof, easily connecting your code to the latest AI models evolving with the technology as it advances. When new models are released, you’ll simply swap them out without needing to rewrite your entire codebase.

#### Please star the repo to show your support for this project!

![Enterprise-ready](https://learn.microsoft.com/en-us/semantic-kernel/media/enterprise-ready.png)

## Getting started with Semantic Kernel

The Semantic Kernel SDK is available in C#, Python, and Java. To get started, choose your preferred language below. See the [Feature Matrix](https://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages) for a breakdown of
feature parity between our currently supported languages.

<table width=100%>
  <tbody>
    <tr>
      <td>
        <img align="left" width=52px src="https://user-images.githubusercontent.com/371009/230673036-fad1e8e6-5d48-49b1-a9c1-6f9834e0d165.png">
        <div>
          <a href="dotnet/README.md">Using Semantic Kernel in C#</a> &nbsp<br/>
        </div>
      </td>
      <td>
        <img align="left" width=52px src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg">
        <div>
          <a href="python/README.md">Using Semantic Kernel in Python</a>
        </div>
      </td>
      <td>
        <img align="left" width=52px height=52px src="https://upload.wikimedia.org/wikipedia/en/3/30/Java_programming_language_logo.svg" alt="Java logo">
        <div>
          <a href="https://github.com/microsoft/semantic-kernel/blob/main/java/README.md">Using Semantic Kernel in Java</a>
        </div>
      </td>
    </tr>
  </tbody>
</table>

The quickest way to get started with the basics is to get an API key
from either OpenAI or Azure OpenAI and to run one of the C#, Python, and Java console applications/scripts below.

### For C#:

1. Go to the Quick start page [here](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp) and follow the steps to dive in.
2. After Installing the SDK, we advise you follow the steps and code detailed to write your first console app.
   ![dotnetmap](https://learn.microsoft.com/en-us/semantic-kernel/media/dotnetmap.png)

### For Python:

1. Go to the Quick start page [here](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-python) and follow the steps to dive in.
2. You'll need to ensure that you toggle to Python in the the Choose a programming language table at the top of the page.
   ![pythonmap](https://learn.microsoft.com/en-us/semantic-kernel/media/pythonmap.png)

### For Java:

The Java code is in the [semantic-kernel-java](https://github.com/microsoft/semantic-kernel-java) repository. See
[semantic-kernel-java build](https://github.com/microsoft/semantic-kernel-java/blob/main/BUILD.md) for instructions on
how to build and run the Java code.

Please file Java Semantic Kernel specific issues in
the [semantic-kernel-java](https://github.com/microsoft/semantic-kernel-java) repository.

## Learning how to use Semantic Kernel

The fastest way to learn how to use Semantic Kernel is with our C# and Python Jupyter notebooks. These notebooks
demonstrate how to use Semantic Kernel with code snippets that you can run with a push of a button.

- [Getting Started with C# notebook](dotnet/notebooks/00-getting-started.ipynb)
- [Getting Started with Python notebook](python/samples/getting_started/00-getting-started.ipynb)

Once you've finished the getting started notebooks, you can then check out the main walkthroughs
on our Learn site. Each sample comes with a completed C# and Python project that you can run locally.

1. 📖 [Getting Started](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide)
1. 🔌 [Detailed Samples](https://learn.microsoft.com/en-us/semantic-kernel/get-started/detailed-samples)
1. 💡 [Concepts](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents)

Finally, refer to our API references for more details on the C# and Python APIs:

- [C# API reference](https://learn.microsoft.com/en-us/dotnet/api/microsoft.semantickernel?view=semantic-kernel-dotnet)
- [Python API reference](https://learn.microsoft.com/en-us/python/api/semantic-kernel/semantic_kernel?view=semantic-kernel-python)
- Java API reference (coming soon)

## Visual Studio Code extension: design semantic functions with ease

The Semantic Kernel extension for Visual Studio Code makes it easy to design and test semantic functions. The extension provides an interface for designing semantic functions and allows you to test them with the push of a button with your existing models and data.

## Join the community

We welcome your contributions and suggestions to SK community! One of the easiest
ways to participate is to engage in discussions in the GitHub repository.
Bug reports and fixes are welcome!

For new features, components, or extensions, please open an issue and discuss with
us before sending a PR. This is to avoid rejection as we might be taking the core
in a different direction, but also to consider the impact on the larger ecosystem.

To learn more and get started:

- Read the [documentation](https://aka.ms/sk/learn)
- Learn how to [contribute](https://learn.microsoft.com/en-us/semantic-kernel/get-started/contributing) to the project
- Ask questions in the [GitHub discussions](https://github.com/microsoft/semantic-kernel/discussions)
- Ask questions in the [Discord community](https://aka.ms/SKDiscord)

- Attend [regular office hours and SK community events](COMMUNITY.md)
- Follow the team on our [blog](https://aka.ms/sk/blog)

## Contributor Wall of Fame

[![semantic-kernel contributors](https://contrib.rocks/image?repo=microsoft/semantic-kernel)](https://github.com/microsoft/semantic-kernel/graphs/contributors)

## Code of Conduct

This project has adopted the
[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the
[Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)
or contact [opencode@microsoft.com](mailto:opencode@microsoft.com)
with any additional questions or comments.

# Glossary ✍

To wrap your mind around the concepts we present throughout the kernel, here is a glossary of
commonly used terms

**Semantic Kernel (SK)** - The orchestrator that fulfills a user's ASK with SK's available [PLUGINS](PLUGINS.md).

**Ask** - What a user requests to the Semantic Kernel to help achieve the user's goal.

- "We make ASKs to the SK"

**Plugins** - A domain-specific collection made available to the SK as a group of finely-tuned functions.

- "We have a PLUGIN for using Office better"

**Function** - A computational machine comprised of Semantic AI and/or native code that's available in a [PLUGIN](PLUGINS.md).

- "The Office PLUGIN has many FUNCTIONS"

**Native Function** - expressed with traditional computing language (C#, Python, Typescript)
and easily integrates with SK

**Semantic Function** - expressed in natural language in a text file "*skprompt.txt*" using SK's
[Prompt Template language](PROMPT_TEMPLATE_LANGUAGE.md).
Each semantic function is defined by a unique prompt template file, developed using modern
**prompt engineering** techniques.

**Memory** - a collection of semantic knowledge, based on facts, events, documents, indexed with **[embeddings](EMBEDDINGS.md)**.

<p align="center">
<img width="682" alt="image" src="https://user-images.githubusercontent.com/371009/221690406-caaff98e-87b5-40b7-9c58-cfa9623789b5.png">
</p>

The kernel is designed to encourage **function composition**, allowing users to combine multiple functions
(native and semantic) into a single pipeline.

<p align="center">
<img width="682" alt="image" src="https://user-images.githubusercontent.com/371009/221690156-3f90a8c9-ef90-46f7-a097-beb483656e97.png">
</p>

1 Semantic Kernel Getting Started.md
56.39 KB • 903 extracted lines
Formatting may be inconsistent from source.
# Introduction to Semantic Kernel

- Article
- 06/24/2024
- 6 contributors

Feedback

## In this article

1. [Enterprise ready](https://learn.microsoft.com/en-us/semantic-kernel/overview/#enterprise-ready)
2. [Automating business processes](https://learn.microsoft.com/en-us/semantic-kernel/overview/#automating-business-processes)
3. [Modular and extensible](https://learn.microsoft.com/en-us/semantic-kernel/overview/#modular-and-extensible)
4. [Get started](https://learn.microsoft.com/en-us/semantic-kernel/overview/#get-started)

Semantic Kernel is a lightweight, open-source development kit that lets you easily build AI agents and integrate the latest AI models into your C#, Python, or Java codebase. It serves as an efficient middleware that enables rapid delivery of enterprise-grade solutions.

[](https://learn.microsoft.com/en-us/semantic-kernel/overview/#enterprise-ready)

## Enterprise ready

Microsoft and other Fortune 500 companies are already leveraging Semantic Kernel because it’s flexible, modular, and observable. Backed with security enhancing capabilities like telemetry support, and hooks and filters so you’ll feel confident you’re delivering responsible AI solutions at scale.

Version 1.0+ support across C#, Python, and Java means it’s reliable, committed to non breaking changes. Any existing chat-based APIs are easily expanded to support additional modalities like voice and video.

Semantic Kernel was designed to be future proof, easily connecting your code to the latest AI models evolving with the technology as it advances. When new models are released, you’ll simply swap them out without needing to rewrite your entire codebase.

![Intro Image](https://learn.microsoft.com/en-us/semantic-kernel/media/enterprise-ready.png)

[](https://learn.microsoft.com/en-us/semantic-kernel/overview/#automating-business-processes)

## Automating business processes

Semantic Kernel combines prompts with [existing APIs](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/) to perform actions. By describing your existing code to AI models, they’ll be called to address requests. When a request is made the model calls a function, and Semantic Kernel is the middleware translating the model's request to a function call and passes the results back to the model.

[](https://learn.microsoft.com/en-us/semantic-kernel/overview/#modular-and-extensible)

## Modular and extensible

By adding your existing code as a plugin, you’ll maximize your investment by flexibly integrating AI services through a set of out-of-the-box connectors. Semantic Kernel uses OpenAPI specifications (like Microsoft 365 Copilot) so you can share any extensions with other pro or low-code developers in your company.

![Modular Extensibility](https://learn.microsoft.com/en-us/semantic-kernel/media/designed-for-modular-extensibility.png)

[](https://learn.microsoft.com/en-us/semantic-kernel/overview/#get-started)

## Get started

Now that you know what Semantic Kernel is, get started with the quick start guide. You’ll build agents that automatically call functions to perform actions faster than any other SDK out there.
# Getting started with Semantic Kernel

- Article
- 06/24/2024
- 6 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [Installing the SDK](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#installing-the-sdk)
2. [Quickly get started with notebooks](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#quickly-get-started-with-notebooks)
3. [Writing your first console app](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#writing-your-first-console-app)
4. [Understanding the code](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#understanding-the-code)
5. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#next-steps)

In just a few steps, you can build your first AI agent with Semantic Kernel in either Python, .NET, or Java. This guide will show you how to...

- Install the necessary packages
- Create a back-and-forth conversation with an AI
- Give an AI agent the ability to run your code
- Watch the AI create plans on the fly

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#installing-the-sdk)

## Installing the SDK

Semantic Kernel has several NuGet packages available. For most scenarios, however, you typically only need `Microsoft.SemanticKernel`.

You can install it using the following command:

BashCopy

```
dotnet add package Microsoft.SemanticKernel
```

For the full list of Nuget packages, please refer to the [supported languages article](https://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages).

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#quickly-get-started-with-notebooks)

## Quickly get started with notebooks

If you're a Python or C# developer, you can quickly get started with our notebooks. These notebooks provide step-by-step guides on how to use Semantic Kernel to build AI agents.

![Semantic Kernel notebooks](https://learn.microsoft.com/en-us/semantic-kernel/media/python_getting_started_notebooks.png)

To get started, follow these steps:

1. Clone the [Semantic Kernel repo](https://github.com/microsoft/semantic-kernel)
2. Open the repo in Visual Studio Code
3. Navigate to [_/dotnet/notebooks](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/notebooks)
4. Open _00-getting-started.ipynb_ to get started setting your environment and creating your first AI agent!

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#writing-your-first-console-app)

## Writing your first console app

C#Copy

```
// Import packages
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using Microsoft.SemanticKernel.Connectors.OpenAI;

// Create a kernel with Azure OpenAI chat completion
var builder = Kernel.CreateBuilder().AddAzureOpenAIChatCompletion(modelId, endpoint, apiKey);

// Add enterprise components
builder.Services.AddLogging(services => services.AddConsole().SetMinimumLevel(LogLevel.Trace));

// Build the kernel
Kernel kernel = builder.Build();
var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();

// Add a plugin (the LightsPlugin class is defined below)
kernel.Plugins.AddFromType<LightsPlugin>("Lights");

// Enable planning
OpenAIPromptExecutionSettings openAIPromptExecutionSettings = new() 
{
    ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions
};

// Create a history store the conversation
var history = new ChatHistory();

// Initiate a back-and-forth chat
string? userInput;
do {
    // Collect user input
    Console.Write("User > ");
    userInput = Console.ReadLine();

    // Add user input
    history.AddUserMessage(userInput);

    // Get the response from the AI
    var result = await chatCompletionService.GetChatMessageContentAsync(
        history,
        executionSettings: openAIPromptExecutionSettings,
        kernel: kernel);

    // Print the results
    Console.WriteLine("Assistant > " + result);

    // Add the message from the agent to the chat history
    history.AddMessage(result.Role, result.Content ?? string.Empty);
} while (userInput is not null)
```

The following back-and-forth chat should be similar to what you see in the console. The function calls have been added below to demonstrate how the AI leverages the plugin behind the scenes.

Expand table

|Role|Message|
|---|---|
|🔵 **User**|Please toggle the light|
|🔴 **Assistant (function call)**|`LightsPlugin.GetState()`|
|🟢 **Tool**|`off`|
|🔴 **Assistant (function call)**|`LightsPlugin.ChangeState(true)`|
|🟢 **Tool**|`on`|
|🔴 **Assistant**|The light is now on|

If you're interested in understanding more about the code above, we'll break it down in the next section.

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#understanding-the-code)

## Understanding the code

To make it easier to get started building enterprise apps with Semantic Kernel, we've created a step-by-step that guides you through the process of creating a kernel and using it to interact with AI services.

![Semantic Kernel DotNET map](https://learn.microsoft.com/en-us/semantic-kernel/media/dotnetmap.png)

In the following sections, we'll unpack the above sample by walking through steps **1**, **2**, **3**, **4**, **6**, **9**, and **10**. Everything you need to build a simple agent that is powered by an AI service and can run your code.

- [Import packages](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#1-import-packages)
- [Add AI services](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#2-add-ai-services)
    
- [Enterprise components](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#3-add-enterprise-services) ::: zone-end
- [Build the kernel](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#4-build-the-kernel-and-retrieve-services)
- Add memory (skipped)
- [Add plugins](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#6-add-plugins)
- Create kernel arguments (skipped)
- Create prompts (skipped)
- [Planning](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#9-planning)
- [Invoke](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#10-invoke)

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#1-import-packages)

### 1) Import packages

For this sample, we first started by importing the following packages:

C#Copy

```
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using Microsoft.SemanticKernel.Connectors.OpenAI;
```

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#2-add-ai-services)

### 2) Add AI services

Afterwards, we add the most important part of a kernel: the AI services that you want to use. In this example, we added an Azure OpenAI chat completion service to the kernel builder.

 Note

In this example, we used Azure OpenAI, but you can use any other chat completion service. To see the full list of supported services, refer to the [supported languages article](https://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages). If you need help creating a different service, refer to the [AI services article](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/). There, you'll find guidance on how to use OpenAI or Azure OpenAI models as services.

C#Copy

```
// Create kernel
var builder = Kernel.CreateBuilder()
builder.AddAzureOpenAIChatCompletion(modelId, endpoint, apiKey);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#3-add-enterprise-services)

### 3) Add enterprise services

One of the main benefits of using Semantic Kernel is that it supports enterprise-grade services. In this sample, we added the logging service to the kernel to help debug the AI agent.

C#Copy

```
builder.Services.AddLogging(services => services.AddConsole().SetMinimumLevel(LogLevel.Trace));
```

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#4-build-the-kernel-and-retrieve-services)

### 4) Build the kernel and retrieve services

Once the services have been added, we then build the kernel and retrieve the chat completion service for later use.

C#Copy

```
Kernel kernel = builder.Build();

// Retrieve the chat completion service
var chatCompletionService = kernel.Services.GetRequiredService<IChatCompletionService>();
```

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#6-add-plugins)

### 6) Add plugins

With plugins, can give your AI agent the ability to run your code to retrieve information from external sources or to perform actions. In the above example, we added a plugin that allows the AI agent to interact with a light bulb. Below, we'll show you how to create this plugin.

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#create-a-native-plugin)

#### Create a native plugin

Below, you can see that creating a native plugin is as simple as creating a new class.

In this example, we've created a plugin that can manipulate a light bulb. While this is a simple example, this plugin quickly demonstrates how you can support both...

1. [Retrieval Augmented Generation (RAG)](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag) by providing the AI agent with the state of the light bulb
2. And [task automation](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions) by allowing the AI agent to turn the light bulb on or off.

In your own code, you can create a plugin that interacts with any external service or API to achieve similar results.

C#Copy

```
using System.ComponentModel;
using Microsoft.SemanticKernel;

public class LightsPlugin
{
   // Mock data for the lights
   private readonly List<LightModel> lights = new()
   {
      new LightModel { Id = 1, Name = "Table Lamp", IsOn = false },
      new LightModel { Id = 2, Name = "Porch light", IsOn = false },
      new LightModel { Id = 3, Name = "Chandelier", IsOn = true }
   };

   [KernelFunction("get_lights")]
   [Description("Gets a list of lights and their current state")]
   [return: Description("An array of lights")]
   public async Task<List<LightModel>> GetLightsAsync()
   {
      return lights
   }

   [KernelFunction("change_state")]
   [Description("Changes the state of the light")]
   [return: Description("The updated state of the light; will return null if the light does not exist")]
   public async Task<LightModel?> ChangeStateAsync(int id, bool isOn)
   {
      var light = lights.FirstOrDefault(light => light.Id == id);

      if (light == null)
      {
         return null;
      }

      // Update the light with the new state
      light.IsOn = isOn;

      return light;
   }
}

public class LightModel
{
   [JsonPropertyName("id")]
   public int Id { get; set; }

   [JsonPropertyName("name")]
   public string Name { get; set; }

   [JsonPropertyName("is_on")]
   public bool? IsOn { get; set; }
}
```

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#add-the-plugin-to-the-kernel)

#### Add the plugin to the kernel

Once you've created your plugin, you can add it to the kernel so the AI agent can access it. In the sample, we added the `LightsPlugin` class to the kernel.

C#Copy

```
// Add the plugin to the kernel
kernel.Plugins.AddFromType<LightsPlugin>("Lights");
```

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#9-planning)

### 9) Planning

Semantic Kernel leverages [function calling](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling)–a native feature of most LLMs–to provide [planning](https://learn.microsoft.com/en-us/semantic-kernel/concepts/planning). With function calling, LLMs can request (or call) a particular function to satisfy a user's request. Semantic Kernel then marshals the request to the appropriate function in your codebase and returns the results back to the LLM so the AI agent can generate a final response.

To enable automatic function calling, we first need to create the appropriate execution settings so that Semantic Kernel knows to automatically invoke the functions in the kernel when the AI agent requests them.

C#Copy

```
OpenAIPromptExecutionSettings openAIPromptExecutionSettings = new()
{
    ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions
};
```

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#10-invoke)

### 10) Invoke

Finally, we invoke the AI agent with the plugin. The sample code demonstrates how to generate a [non-streaming response](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/#non-streaming-chat-completion), but you can also generate a [streaming response](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/#streaming-chat-completion) by using the `GetStreamingChatMessageContentAsync` method.

C#Copy

```
// Create chat history
var history = new ChatHistory();

// Get the response from the AI
var result = await chatCompletionService.GetChatMessageContentAsync(
    history,
    executionSettings: openAIPromptExecutionSettings,
    kernel: kernel
);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp#next-steps)

## Next steps

In this guide, you learned how to quickly get started with Semantic Kernel by building a simple AI agent that can interact with an AI service and run your code. To see more examples and learn how to build more complex AI agents, check out our [in-depth samples](https://learn.microsoft.com/en-us/semantic-kernel/get-started/detailed-samples).

# Deep dive into Semantic Kernel

- Article
- 07/25/2024
- 2 contributors

Feedback

Choose a programming language

C#PythonJava

If you want to dive into deeper into Semantic Kernel and learn how to use more advanced functionality not explicitly covered in our Learn documentation, we recommend that you check out our concepts samples that individually demonstrate how to use specific features within the SDK.

Each of the SDKs (Python, C#, and Java) have their own set of samples that walk through the SDK. Each sample is modelled as a test case within our main repo, so you're always guaranteed that the sample will work with the latest nightly version of the SDK! Below are most of the samples you'll find in our concepts project.

[View all C# concept samples on GitHub](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/samples/Concepts)

![Leverage the kernel syntax examples on GitHub](https://learn.microsoft.com/en-us/semantic-kernel/media/tutorials/kernel-syntax-examples.png)

Expand table

|Category|Sample Name|Link|
|---|---|---|
|**Agents**|ComplexChat_NestedShopper|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/ComplexChat_NestedShopper.cs)|
||Legacy_AgentAuthoring|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/Legacy_AgentAuthoring.cs)|
||Legacy_AgentCharts|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/Legacy_AgentCharts.cs)|
||Legacy_AgentCollaboration|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/Legacy_AgentCollaboration.cs)|
||Legacy_AgentDelegation|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/Legacy_AgentDelegation.cs)|
||Legacy_AgentTools|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/Legacy_AgentTools.cs)|
||Legacy_Agents|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/Legacy_Agents.cs)|
||Legacy_ChatCompletionAgent|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/Legacy_ChatCompletionAgent.cs)|
||MixedChat_Agents|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/MixedChat_Agents.cs)|
||OpenAIAssistant_ChartMaker|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/OpenAIAssistant_ChartMaker.cs)|
||OpenAIAssistant_CodeInterpreter|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/OpenAIAssistant_CodeInterpreter.cs)|
||OpenAIAssistant_Retrieval|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Agents/OpenAIAssistant_Retrieval.cs)|
|**Audio to text**|OpenAI_AudioToText|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/AudioToText/OpenAI_AudioToText.cs)|
|Automatic function calling|Gemini_FunctionCalling|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/AutoFunctionCalling/Gemini_FunctionCalling.cs)|
||OpenAI_FunctionCalling|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/AutoFunctionCalling/OpenAI_FunctionCalling.cs)|
|**Semantic caching**|SemanticCachingWithFilters|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Caching/SemanticCachingWithFilters.cs)|
|**Chat completion**|AzureOpenAIWithData_ChatCompletion|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/AzureOpenAIWithData_ChatCompletion.cs)|
||ChatHistoryAuthorName|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/ChatHistoryAuthorName.cs)|
||ChatHistorySerialization|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/ChatHistorySerialization.cs)|
||Connectors_CustomHttpClient|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/Connectors_CustomHttpClient.cs)|
||Connectors_KernelStreaming|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/Connectors_KernelStreaming.cs)|
||Connectors_WithMultipleLLMs|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/Connectors_WithMultipleLLMs.cs)|
||Google_GeminiChatCompletion|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/Google_GeminiChatCompletion.cs)|
||Google_GeminiChatCompletionStreaming|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/Google_GeminiChatCompletionStreaming.cs)|
||Google_GeminiGetModelResult|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/Google_GeminiGetModelResult.cs)|
||Google_GeminiVision|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/Google_GeminiVision.cs)|
||OpenAI_ChatCompletion|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/OpenAI_ChatCompletion.cs)|
||OpenAI_ChatCompletionMultipleChoices|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/OpenAI_ChatCompletionMultipleChoices.cs)|
||OpenAI_ChatCompletionStreaming|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/OpenAI_ChatCompletionStreaming.cs)|
||OpenAI_ChatCompletionStreamingMultipleChoices|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/OpenAI_ChatCompletionStreamingMultipleChoices.cs)|
||OpenAI_ChatCompletionWithVision|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/OpenAI_ChatCompletionWithVision.cs)|
||OpenAI_CustomAzureOpenAIClient|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/OpenAI_CustomAzureOpenAIClient.cs)|
||OpenAI_UsingLogitBias|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/OpenAI_UsingLogitBias.cs)|
||OpenAI_FunctionCalling|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/OpenAI_FunctionCalling.cs)|
||MistralAI_ChatPrompt|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/MistralAI_ChatPrompt.cs)|
||MistralAI_FunctionCalling|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/MistralAI_FunctionCalling.cs)|
||MistralAI_StreamingFunctionCalling|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ChatCompletion/MistralAI_StreamingFunctionCalling.cs)|
|**Dependency injection**|HttpClient_Registration|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/DependencyInjection/HttpClient_Registration.cs)|
||HttpClient_Resiliency|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/DependencyInjection/HttpClient_Resiliency.cs)|
||Kernel_Building|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/DependencyInjection/Kernel_Building.cs)|
||Kernel_Injecting|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/DependencyInjection/Kernel_Injecting.cs)|
|**Filtering**|AutoFunctionInvocationFiltering|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Filtering/AutoFunctionInvocationFiltering.cs)|
||FunctionInvocationFiltering|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Filtering/FunctionInvocationFiltering.cs)|
||Legacy_KernelHooks|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Filtering/Legacy_KernelHooks.cs)|
||PromptRenderFiltering|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Filtering/PromptRenderFiltering.cs)|
||RetryWithFilters|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Filtering/RetryWithFilters.cs)|
||PIIDetectionWithFilters|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Filtering/PIIDetectionWithFilters.cs)|
|**Plugin functions**|Arguments|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Functions/Arguments.cs)|
||FunctionResult_Metadata|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Functions/FunctionResult_Metadata.cs)|
||FunctionResult_StronglyTyped|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Functions/FunctionResult_StronglyTyped.cs)|
||MethodFunctions|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Functions/MethodFunctions.cs)|
||MethodFunctions_Advanced|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Functions/MethodFunctions_Advanced.cs)|
||MethodFunctions_Types|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Functions/MethodFunctions_Types.cs)|
||PromptFunctions_Inline|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Functions/PromptFunctions_Inline.cs)|
||PromptFunctions_MultipleArguments|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Functions/PromptFunctions_MultipleArguments.cs)|
|**Image to text**|HuggingFace_ImageToText|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/ImageToText/HuggingFace_ImageToText.cs)|
|**Local models**|HuggingFace_ChatCompletionWithTGI|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/LocalModels/HuggingFace_ChatCompletionWithTGI.cs)|
||MultipleProviders_ChatCompletion|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/LocalModels/MultipleProviders_ChatCompletion.cs)|
|**Memory**|HuggingFace_EmbeddingGeneration|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Memory/HuggingFace_EmbeddingGeneration.cs)|
||MemoryStore_CustomReadOnly|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Memory/MemoryStore_CustomReadOnly.cs)|
||SemanticTextMemory_Building|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Memory/SemanticTextMemory_Building.cs)|
||TextChunkerUsage|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Memory/TextChunkerUsage.cs)|
||TextChunkingAndEmbedding|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Memory/TextChunkingAndEmbedding.cs)|
||TextMemoryPlugin_GeminiEmbeddingGeneration|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Memory/TextMemoryPlugin_GeminiEmbeddingGeneration.cs)|
||TextMemoryPlugin_MultipleMemoryStore|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Memory/TextMemoryPlugin_MultipleMemoryStore.cs)|
|**Planning**|FunctionCallStepwisePlanning|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Planners/FunctionCallStepwisePlanning.cs)|
||HandlebarsPlanning|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Planners/HandlebarsPlanning.cs)|
|**Plugins**|ApiManifestBasedPlugins|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Plugins/ApiManifestBasedPlugins.cs)|
||ConversationSummaryPlugin|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Plugins/ConversationSummaryPlugin.cs)|
||CreatePluginFromOpenAI_AzureKeyVault|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Plugins/CreatePluginFromOpenAI_AzureKeyVault.cs)|
||CreatePluginFromOpenApiSpec_Github|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Plugins/CreatePluginFromOpenApiSpec_Github.cs)|
||CreatePluginFromOpenApiSpec_Jira|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Plugins/CreatePluginFromOpenApiSpec_Jira.cs)|
||CustomMutablePlugin|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Plugins/CustomMutablePlugin.cs)|
||DescribeAllPluginsAndFunctions|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Plugins/DescribeAllPluginsAndFunctions.cs)|
||GroundednessChecks|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Plugins/GroundednessChecks.cs)|
||ImportPluginFromGrpc|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Plugins/ImportPluginFromGrpc.cs)|
||OpenAIPlugins|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Plugins/OpenAIPlugins.cs)|
|**Prompt templates**|ChatCompletionPrompts|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/PromptTemplates/ChatCompletionPrompts.cs)|
||ChatWithPrompts|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/PromptTemplates/ChatWithPrompts.cs)|
||LiquidPrompts|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/PromptTemplates/LiquidPrompts.cs)|
||MultiplePromptTemplates|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/PromptTemplates/MultiplePromptTemplates.cs)|
||PromptFunctionsWithChatGPT|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/PromptTemplates/PromptFunctionsWithChatGPT.cs)|
||TemplateLanguage|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/PromptTemplates/TemplateLanguage.cs)|
||PromptyFunction|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/PromptTemplates/PromptyFunction.cs)|
|**Retrieval augmented generation**|WithFunctionCallingStepwisePlanner|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/RAG/WithFunctionCallingStepwisePlanner.cs)|
||WithPlugins|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/RAG/WithPlugins.cs)|
|Search|BingAndGooglePlugins|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Search/BingAndGooglePlugins.cs)|
||MyAzureAISearchPlugin|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Search/MyAzureAISearchPlugin.cs)|
||WebSearchQueriesPlugin|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/Search/WebSearchQueriesPlugin.cs)|
|**Text generation**|Custom_TextGenerationService|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/TextGeneration/Custom_TextGenerationService.cs)|
||HuggingFace_TextGeneration|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/TextGeneration/HuggingFace_TextGeneration.cs)|
||OpenAI_TextGenerationStreaming|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/TextGeneration/OpenAI_TextGenerationStreaming.cs)|
|**Text to audio**|OpenAI_TextToAudio|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/TextToAudio/OpenAI_TextToAudio.cs)|
|**Text to image**|OpenAI_TextToImage|[Link](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/Concepts/TextToImage/OpenAI_TextToImageDalle3.cs)|
# What are agents?

- Article
- 06/24/2024
- 5 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [Building your first agent](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#building-your-first-agent)
2. [Putting the pieces together](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#putting-the-pieces-together)
3. [Trying out your agent](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#trying-out-your-agent)
4. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#next-steps)

Agents are software based entities that leverage AI models to do works for you. They are built to perform a wide range of tasks and called different names based on the jobs they do.

For example, an agent built to answer questions is referred to as a chatbot due to it’s chat-based experience. These agents are typically grounded in your own data, like company documents.

An agent built to work along side you is typically called a copilot. These agents help you complete tasks like writing emails or creating other office artifacts by providing recommendations that you choose to either accept or reject.

An agent built to handle repetitive tasks are usually labeled as fully autonomous. They respond to events and perform actions without needing intervention. This is different from a copilot in that it’s doing work for you instead of alongside you.

Semantic Kernel provides you with the infrastructure to build any kind of agent you need without being an expert in AI.

![3 kinds of agents: Chatbot Copilot and Fully autonomous](https://learn.microsoft.com/en-us/semantic-kernel/media/what-are-agents.png)

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#building-your-first-agent)

## Building your first agent

An agent is made up of three core building blocks that harmoniously work together to complete tasks for you. Let’s take a closer look by building a copilot that helps you write and send an email.

![Building Blocks of an Agent](https://learn.microsoft.com/en-us/semantic-kernel/media/building-blocks.png)

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#a-copilot-to-write-and-send-emails)

### A copilot to write and send emails

To create this copilot you’ll need to create a plugin that can send emails, a planner that generates a plan to write an email, and a persona that interacts with you to get the information needed to send the email.

Expand table

|Step|Description|
|---|---|
|1|Get the user's email address and name|
|2|Get the email address of the recipient|
|3|Get the topic of the email|
|4|Generate the subject and body of the email|
|5|Review the email with the user|
|6|Send the email|

To enable this scenario, we would need to create a plugin that can send emails, a planner that can generate a plan to write an email, and a persona that can interact with the user to get the necessary information.

The following sections will walk you through the conceptual building blocks and how to put them together to build your first agent. Afterwards, you can refer to the specific guides for each building block to learn more about how to build them.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#plugins-giving-your-agent-skills)

### Plugins: giving your agent skills

To generate the above plan, the copilot first needs the capabilities necessary to perform these steps. This is where plugins come in. Plugins allow you to give your agent skills via code. For example, you could create a plugin that sends emails, retrieves information from a database, asks for help, or even saves and retrieves memories from previous conversations.

In our example, we can build a simple plugin that sends emails using [native code](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins). Our plugin just has a single function, `send_email`, that takes in the email address, subject, and body of the email. It would then use this information to send the email.

C#Copy

```
using System.ComponentModel;
using Microsoft.SemanticKernel;

public class EmailPlugin
{
    [KernelFunction("send_email")]
    [Description("Sends an email to a recipient.")]
    public async Task SendEmailAsync(
        Kernel kernel,
        List<string> recipientEmails,
        string subject,
        string body
    )
    {
        // Add logic to send an email using the recipientEmails, subject, and body
        // For now, we'll just print out a success message to the console
        Console.WriteLine("Email sent!");
    }
}
```

There are other ways to create plugins. For example, if you have a RestAPI that can send emails, you can automatically create a plugin using its [OpenAPI specification](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins). To learn more about other ways to author plugins, see the [plugins section](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/).

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#planning-completing-multi-step-tasks)

### Planning: completing multi-step tasks

To actually use this plugin (and to wire them up with other steps), the copilot would then need to generate a plan. This is where planning comes in. Planning comes from the built-in ability of LLMs to determine how to iteratively complete a task.

 Note

In the past, special prompts were created by AI app developers to guide the AI in generating a plan that could be consumed by an SDK like Semantic Kernel. However, with the advent of LLMs, AIs can now generate plans directly from a conversation with a user with the aid of function calling.

With built-in planning support form LLMs, using Semantic Kernel is now as easy as invoking a chat completion service with auto function calling enabled.

C#Copy

```
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using Microsoft.SemanticKernel.Connectors.OpenAI;

// Create kernel with an email plugin
var builder = Kernel.CreateBuilder();
builder.Plugins.AddFromType<EmailPlugin>();
Kernel kernel = builder.Build();

// Create chat completion service
AzureOpenAIChatCompletionService chatCompletionService = new (
    deploymentName: "gpt-4",
    apiKey: "YOUR_API_KEY",
    endpoint: "YOUR_AZURE_ENDPOINT"
);

// Enable planning
OpenAIPromptExecutionSettings openAIPromptExecutionSettings = new() 
{
    ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions
};

// Create chat history
var history = new ChatHistory();
history.AddUserMessage("Can you help me write an email for my boss?");

// Get the response from the AI
var result = await chatCompletionService.GetChatMessageContentAsync(
    history,
    executionSettings: openAIPromptExecutionSettings,
    kernel: kernel
);
```

To learn more about planning with Semantic Kernel, see the [planning article](https://learn.microsoft.com/en-us/semantic-kernel/concepts/planning).

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#personas-giving-your-agent-a-job-description)

### Personas: giving your agent a job description

In most cases, using the built-in planning capabilities of LLMs with plugins is sufficient to building an agent, but as you build more domain-specific agents, you may want to add a persona to your agent.

A persona is the instructions that you provide your agent so they can more effectively perform the role you want them to play. At its simplest, the persona could instruct the AI to be polite, ask for clarification when needed, or role-play as a specific job title (e.g., a customer service representative).

For enterprise scenarios, however, you may want to provide more detailed instructions to your agent. For example, you may want to instruct your agent to follow specific rules, ask for approval before taking actions, or escalate to a human if the AI is unable to complete a task.

To provide a persona to your agent, simply pre-pend a system message to the chat history that describes the persona. The AI will then use this persona to guide its interactions with the user.

C#Copy

```
// Create chat history
ChatHistory chatMessages = new ChatHistory("""
    You are a friendly assistant who likes to follow the rules. You will complete required steps
    and request approval before taking any consequential actions. If the user doesn't provide
    enough information for you to complete a task, you will keep asking questions until you have
    enough information to complete the task.
    """);
chatMessages.AddUserMessage("Can you help me write an email for my boss?");

// Get the response from the AI
var result = await chatCompletionService.GetChatMessageContentAsync(
    history,
    executionSettings: openAIPromptExecutionSettings,
    kernel: kernel
);
```

To learn more about authoring effective personas, refer to the [personas article](https://learn.microsoft.com/en-us/semantic-kernel/concepts/personas).

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#putting-the-pieces-together)

## Putting the pieces together

Now that we understand the core building blocks of an agent, we can now combine them together to build our first agent. To do so, we'll initialize our `Kernel` object with our plugins, planners, and persona. Afterwards, we'll use the `Kernel` object to generate a plan and then execute that plan.

C#Copy

```
// Create the kernel
var builder = Kernel.CreateBuilder();
builder.Services.AddLogging(c => c.SetMinimumLevel(LogLevel.Trace).AddDebug());
builder.Services.AddChatCompletionService(kernelSettings);
builder.Plugins.AddFromType<EmailPlugin>();
Kernel kernel = builder.Build();

// Retrieve the chat completion service from the kernel
IChatCompletionService chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();

// Create the chat history
ChatHistory chatMessages = new ChatHistory("""
    You are a friendly assistant who likes to follow the rules. You will complete required steps
    and request approval before taking any consequential actions. If the user doesn't provide
    enough information for you to complete a task, you will keep asking questions until you have
    enough information to complete the task.
    """);

// Start the conversation
while (true)
{
    // Get user input
    System.Console.Write("User > ");
    chatMessages.AddUserMessage(Console.ReadLine()!);

    // Get the chat completions
    OpenAIPromptExecutionSettings openAIPromptExecutionSettings = new()
    {
        FunctionCallBehavior = FunctionCallBehavior.AutoInvokeKernelFunctions
    };
    var result = chatCompletionService.GetStreamingChatMessageContentsAsync(
        chatMessages,
        executionSettings: openAIPromptExecutionSettings,
        kernel: kernel);

    // Stream the results
    string fullMessage = "";
    await foreach (var content in result)
    {
        if (content.Role.HasValue)
        {
            System.Console.Write("Assistant > ");
        }
        System.Console.Write(content.Content);
        fullMessage += content.Content;
    }
    System.Console.WriteLine();

    // Add the message from the agent to the chat history
    chatMessages.AddAssistantMessage(fullMessage);
}
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/agents?pivots=programming-language-csharp#trying-out-your-agent)

## Trying out your agent

Now that we've completed our program, we can give it a test run. Below is a sample conversation with our agent while using gpt-4 model.

Expand table

|Role|Message|
|---|---|
|🔵 **User**|Can you help me write an email for my boss?|
|🔴 **Assistant**|Of course, I'd be happy to help you write an email to your boss. Could you please provide me with more details? Specifically, I need to know:  <br>1. The topic or purpose of the email.  <br>2. Your boss's email address.|
|🔵 **User**|I want to give her an update on last months sales. We broke a bunch of records that I want to share with her, but we did have a challenge selling the X4321 model.|
|🔴 **Assistant**|That sounds like a great topic for an email. Could you please provide me with your boss's email address so I can assist you further?|
|🔵 **User**|Sure! It's sarah@contoso.com|
|🔴 **Assistant**|Great! Here's a plan for your email:  <br>1. **Start with a Clear Subject Line and Greeting**: The subject line should be concise and informative, such as "Update on Last Month's Sales & X4321 Model Challenges". Start the email with a professional greeting, like "Dear Sarah,".  <br>2. **Highlight Achievements and Challenges in Separate Paragraphs**: Begin with the positive news about the record-breaking achievements. Use specific data and examples to illustrate the success. Then, transition to the challenges with the X4321 model. Be honest and clear about the issues, but also suggest potential solutions or steps being taken to address these challenges.  <br>3. **End with a Call to Action and Professional Closing**: If you need Sarah to take any actions, state this clearly towards the end of the email. This could be asking for her input, a meeting to discuss further, or any other relevant action. Close the email professionally with a phrase like "Best regards" or "Sincerely", followed by your name.  <br>Remember to proofread the email for any grammatical errors or unclear statements before sending it. This will help ensure the message is professional and easy to understand.  <br>Would you like me to draft the email for you based on these steps?|
|🔵 **User**|Yes please!|
|🔴 **Assistant**|Sure, here's a draft based on the steps we discussed:  <br>**Subject**: Update on Last Month's Sales & X4321 Model Challenges  <br>**Dear Sarah,**  <br>I hope this email finds you well. I am writing to update you on our sales performance for the past month.  <br>I am pleased to report that we broke several sales records last month. Our team's hard work and dedication have paid off, resulting in significant growth in our overall sales figures. [Here, you can add specific data or examples of the records broken]  <br>However, we did face some challenges with the X4321 model. Despite our best efforts, the sales for this model did not meet our expectations. [Here, you can explain more about the challenges faced]  <br>We are currently working on strategies to improve the sales of the X4321 model. [Here, you can mention any specific steps or plans you have to address the issue]  <br>I would appreciate your input on this matter. If you would like, we can schedule a meeting to discuss this further.  <br>Thank you for your continued support and guidance.  <br>**Best regards,**  <br>[Your Name]  <br>Please review this draft and let me know if you would like to make any changes before I send it.|
|🔵 **User**|Can you add that we increased our revenue by 20%? You can also share that the X4321 didn't sell as well since most customers upgraded to the Y5000 model, but this isn't too bad since it's what helped increase our revenue.|
|🔴 **Assistant**|Absolutely, here's the updated draft:  <br>**Subject**: Update on Last Month's Sales & X4321 Model Challenges  <br>**Dear Sarah,**  <br>I hope this email finds you well. I am writing to update you on our sales performance for the past month.  <br>I am pleased to report that we broke several sales records last month. Our team's hard work and dedication have paid off, resulting in a significant 20% increase in our overall revenue. This growth is a testament to our team's commitment and the quality of our products.  <br>However, we did face some challenges with the X4321 model. Despite our best efforts, the sales for this model did not meet our expectations. Interestingly, most customers upgraded to the Y5000 model, which contributed significantly to our increased revenue. While we aim to improve the sales of all our models, this shift in customer preference is not entirely negative.  <br>We are currently analyzing this trend and working on strategies to leverage it for future sales. Your insights and suggestions would be greatly appreciated.  <br>Thank you for your continued support and guidance.  <br>**Best regards,**  <br>**Stephen**  <br>Please review this updated draft and let me know if you would like to make any changes before I send it.|
|🔵 **User**|Please sign it with Stephen and then you can go ahead and send it to Sarah|
|🟢 **Tool**|Email sent!|
|🔴 **Assistant**|The email has been sent to Sarah. If there's anything else you need assistance with, feel free to ask!|
# Understanding the kernel

- Article
- 07/25/2024
- 5 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [The kernel is at the center of your agents](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel?pivots=programming-language-csharp#the-kernel-is-at-the-center-of-your-agents)
2. [Build a kernel with services and plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel?pivots=programming-language-csharp#build-a-kernel-with-services-and-plugins)
3. [Using Dependency Injection](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel?pivots=programming-language-csharp#using-dependency-injection)
4. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel?pivots=programming-language-csharp#next-steps)

The kernel is the central component of Semantic Kernel. At its simplest, the kernel is a Dependency Injection container that manages all of the services and plugins necessary to run your AI application. If you provide all of your services and plugins to the kernel, they will then be seamlessly used by the AI as needed.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel?pivots=programming-language-csharp#the-kernel-is-at-the-center-of-your-agents)

## The kernel is at the center of your agents

Because the kernel has all of the services and plugins necessary to run both native code and AI services, it is used by nearly every component within the Semantic Kernel SDK to power your agents. This means that if you run any prompt or code in Semantic Kernel, the kernel will always be available to retrieve the necessary services and plugins.

![The kernel is at the center of everything in Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/media/the-kernel-is-at-the-center-of-everything.png)

This is extremely powerful, because it means you as a developer have a single place where you can configure, and most importantly monitor, your AI agents. Take for example, when you invoke a prompt from the kernel. When you do so, the kernel will...

1. Select the best AI service to run the prompt.
2. Build the prompt using the provided prompt template.
3. Send the prompt to the AI service.
4. Receive and parse the response.
5. And finally return the response from the LLM to your application.

Throughout this entire process, you can create events and middleware that are triggered at each of these steps. This means you can perform actions like logging, provide status updates to users, and most importantly responsible AI. All from a single place.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel?pivots=programming-language-csharp#build-a-kernel-with-services-and-plugins)

## Build a kernel with services and plugins

Before building a kernel, you should first understand the two types of components that exist:

Expand table

||Components|Description|
|---|---|---|
|1|**Services**|These consist of both AI services (e.g., chat completion) and other services (e.g., logging and HTTP clients) that are necessary to run your application. This was modelled after the Service Provider pattern in .NET so that we could support dependency ingestion across all languages.|
|2|**Plugins**|These are the components that are used by your AI services and prompt templates to perform work. AI services, for example, can use plugins to retrieve data from a database or call an external API to perform actions.|

To start creating a kernel, import the necessary packages at the top of your file:

C#Copy

```
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.Plugins.Core;
```

Next, you can add services and plugins. Below is an example of how you can add an Azure OpenAI chat completion, a logger, and a time plugin.

C#Copy

```
// Create a kernel with a logger and Azure OpenAI chat completion service
var builder = Kernel.CreateBuilder();
builder.AddAzureOpenAIChatCompletion(modelId, endpoint, apiKey);
builder.Services.AddLogging(c => c.AddDebug().SetMinimumLevel(LogLevel.Trace));
builder.Plugins.AddFromType<TimePlugin>();
Kernel kernel = builder.Build();
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel?pivots=programming-language-csharp#using-dependency-injection)

## Using Dependency Injection

In C#, you can use Dependency Injection to create a kernel. This is done by creating a `ServiceCollection` and adding services and plugins to it. Below is an example of how you can create a kernel using Dependency Injection.

 Tip

We recommend that you create a kernel as a transient service so that it is disposed of after each use because the plugin collection is mutable. The kernel is extremely lightweight (since it's just a container for services and plugins), so creating a new kernel for each use is not a performance concern.

C#Copy

```
using Microsoft.SemanticKernel;

var builder = Host.CreateApplicationBuilder(args);

// Add the OpenAI chat completion service as a singleton
builder.Services.AddOpenAIChatCompletion(
    modelId: "gpt-4",
    apiKey: "YOUR_API_KEY",
    orgId: "YOUR_ORG_ID", // Optional; for OpenAI deployment
    serviceId: "YOUR_SERVICE_ID" // Optional; for targeting specific services within Semantic Kernel
);

// Create singletons of your plugins
builder.Services.AddSingleton(() => new LightsPlugin());
builder.Services.AddSingleton(() => new SpeakerPlugin());

// Create the plugin collection (using the KernelPluginFactory to create plugins from objects)
builder.Services.AddSingleton<KernelPluginCollection>((serviceProvider) => 
    [
        KernelPluginFactory.CreateFromObject(serviceProvider.GetRequiredService<LightsPlugin>()),
        KernelPluginFactory.CreateFromObject(serviceProvider.GetRequiredService<SpeakerPlugin>())
    ]
);

// Finally, create the Kernel service with the service provider and plugin collection
builder.Services.AddTransient((serviceProvider)=> {
    KernelPluginCollection pluginCollection = serviceProvider.GetRequiredService<KernelPluginCollection>();

    return new Kernel(serviceProvider, pluginCollection);
});
```

 Tip

For more samples on how to use dependency injection in C#, refer to the [concept samples](https://learn.microsoft.com/en-us/semantic-kernel/get-started/detailed-samples).

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel?pivots=programming-language-csharp#next-steps)

## Next steps

Now that you understand the kernel, you can learn about all the different AI services that you can add to it.

2 Semantic Kernel AI Services.md
50.27 KB • 967 extracted lines
Formatting may be inconsistent from source.
# Adding AI services to Semantic Kernel

- Article
- 06/24/2024
- 2 contributors

Feedback

One of the main features of Semantic Kernel is its ability to add different AI services to the kernel. This allows you to easily swap out different AI services to compare their performance and to leverage the best model for your needs. In this section, we will provide sample code for adding different AI services to the kernel.

Within Semantic Kernel, there are interfaces for the most popular AI tasks. In the table below, you can see the services that are supported by each of the SDKs.

Expand table

|Services|C#|Python|Java|Notes|
|---|---|---|---|---|
|[Chat completion](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/)|✅|✅|✅||
|Text generation|✅|✅|✅||
|Embedding generation (Experimental)|✅|✅|✅||
|Text-to-image (Experimental)|✅|❌|❌||
|Image-to-text (Experimental)|✅|❌|❌||
|Text-to-audio (Experimental)|✅|❌|❌||
|Audio-to-text (Experimental)|✅|❌|❌||

 Tip

In most scenarios, you will only need to add chat completion to your kernel, but to support multi-modal AI, you can add any of the above services to your kernel.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/#next-steps)

## Next steps

To learn more about each of the services, please refer to the specific articles for each service type. In each of the articles we provide sample code for adding the service to the kernel across multiple AI service providers.
# Chat completion

- Article
- 06/24/2024
- 5 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [Installing the necessary packages](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#installing-the-necessary-packages)
2. [Creating chat completion services](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#creating-chat-completion-services)
3. [Retrieving chat completion services](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#retrieving-chat-completion-services)
4. [Using chat completion services](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#using-chat-completion-services)
5. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#next-steps)

With chat completion, you can simulate a back-and-forth conversation with an AI agent. This is of course useful for creating chat bots, but it can also be used for creating autonomous agents that can complete business processes, generate code, and more. As the primary model type provided by OpenAI, Google, Mistral, Facebook, and others, chat completion is the most common AI service that you will add to your Semantic Kernel project.

When picking out a chat completion model, you will need to consider the following:

- What modalities does the model support (e.g., text, image, audio, etc.)?
- Does it support function calling?
- How fast does it receive and generate tokens?
- How much does each token cost?

 Important

Of all the above questions, the most important is whether the model supports function calling. If it does not, you will not be able to use the model to call your existing code. Most of the latest models from OpenAI, Google, Mistral, and Amazon all support function calling. Support from small language models, however, is still limited.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#installing-the-necessary-packages)

## Installing the necessary packages

Before adding chat completion to your kernel, you will need to install the necessary packages. Below are the packages you will need to install for each AI service provider.

- [Azure OpenAI](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_1_csharp-AzureOpenAI)
- [OpenAI](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_1_csharp-OpenAI)
- [Mistral](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_1_csharp-Mistral)
- [Google](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_1_csharp-Google)
- [Hugging Face](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_1_csharp-HuggingFace)
- [Other](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_1_csharp-other)

BashCopy

```
dotnet add package Microsoft.SemanticKernel.Connectors.OpenAI
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#creating-chat-completion-services)

## Creating chat completion services

Now that you've installed the necessary packages, you can create chat completion services. Below are the several ways you can create chat completion services using Semantic Kernel.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#adding-directly-to-the-kernel)

### Adding directly to the kernel

To add a chat completion service, you can use the following code to add it to the kernel's inner service provider.

- [Azure OpenAI](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_2_csharp-AzureOpenAI)
- [OpenAI](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_2_csharp-OpenAI)
- [Mistral](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_2_csharp-Mistral)
- [Google](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_2_csharp-Google)
- [Hugging Face](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_2_csharp-HuggingFace)
- [Other](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_2_csharp-other)

BashCopy

```
dotnet add package Microsoft.SemanticKernel.Connectors.OpenAI
```

C#Copy

```
using Microsoft.SemanticKernel;

IKernelBuilder kernelBuilder = Kernel.CreateBuilder();
kernelBuilder.AddAzureOpenAIChatCompletion(
    deploymentName: "NAME_OF_YOUR_DEPLOYMENT",
    apiKey: "YOUR_API_KEY",
    endpoint: "YOUR_AZURE_ENDPOINT",
    modelId: "gpt-4", // Optional name of the underlying model if the deployment name doesn't match the model name
    serviceId: "YOUR_SERVICE_ID", // Optional; for targeting specific services within Semantic Kernel
    httpClient: new HttpClient() // Optional; if not provided, the HttpClient from the kernel will be used
);
Kernel kernel = kernelBuilder.Build();
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#using-dependency-injection)

### Using dependency injection

If you're using dependency injection, you'll likely want to add your AI services directly to the service provider. This is helpful if you want to create singletons of your AI services and reuse them in transient kernels.

- [Azure OpenAI](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_3_csharp-AzureOpenAI)
- [OpenAI](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_3_csharp-OpenAI)
- [Mistral](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_3_csharp-Mistral)
- [Google](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_3_csharp-Google)
- [Hugging Face](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_3_csharp-HuggingFace)
- [Other](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_3_csharp-other)

C#Copy

```
using Microsoft.SemanticKernel;

var builder = Host.CreateApplicationBuilder(args);

builder.Services.AddAzureOpenAIChatCompletion(
    deploymentName: "NAME_OF_YOUR_DEPLOYMENT",
    apiKey: "YOUR_API_KEY",
    endpoint: "YOUR_AZURE_ENDPOINT",
    modelId: "gpt-4", // Optional name of the underlying model if the deployment name doesn't match the model name
    serviceId: "YOUR_SERVICE_ID" // Optional; for targeting specific services within Semantic Kernel
);

builder.Services.AddTransient((serviceProvider)=> {
    return new Kernel(serviceProvider);
});
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#creating-standalone-instances)

### Creating standalone instances

Lastly, you can create instances of the service directly so that you can either add them to a kernel later or use them directly in your code without ever injecting them into the kernel or in a service provider.

- [Azure OpenAI](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_4_csharp-AzureOpenAI)
- [OpenAI](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_4_csharp-OpenAI)
- [Mistral](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_4_csharp-Mistral)
- [Google](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_4_csharp-Google)
- [Hugging Face](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_4_csharp-HuggingFace)
- [Other](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#tabpanel_4_csharp-other)

C#Copy

```
using Microsoft.SemanticKernel.Connectors.OpenAI;

AzureOpenAIChatCompletionService chatCompletionService = new (
    deploymentName: "NAME_OF_YOUR_DEPLOYMENT",
    apiKey: "YOUR_API_KEY",
    endpoint: "YOUR_AZURE_ENDPOINT",
    modelId: "gpt-4", // Optional name of the underlying model if the deployment name doesn't match the model name
    httpClient: new HttpClient() // Optional; if not provided, the HttpClient from the kernel will be used
);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#retrieving-chat-completion-services)

## Retrieving chat completion services

Once you've added chat completion services to your kernel, you can retrieve them using the get service method. Below is an example of how you can retrieve a chat completion service from the kernel.

C#Copy

```
var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#using-chat-completion-services)

## Using chat completion services

Now that you have a chat completion service, you can use it to generate responses from an AI agent. There are two main ways to use a chat completion service:

- Non-streaming: You wait for the service to generate an entire response before returning it to the user.
- Streaming: Individual chunks of the response are generated and returned to the user as they are created.

Below are the two ways you can use a chat completion service to generate responses.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#non-streaming-chat-completion)

### Non-streaming chat completion

To use non-streaming chat completion, you can use the following code to generate a response from the AI agent.

C#Copy

```
ChatHistory history = [];
history.AddUserMessage("Hello, how are you?");

var response = await chatCompletionService.GetChatMessageContentAsync(
    history,
    kernel: kernel
);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#streaming-chat-completion)

### Streaming chat completion

To use streaming chat completion, you can use the following code to generate a response from the AI agent.

C#Copy

```
ChatHistory history = [];
history.AddUserMessage("Hello, how are you?");

var response = chatCompletionService.GetStreamingChatMessageContentsAsync(
    chatHistory: history,
    kernel: kernel
);

await foreach (var chunk in response)
{
    Console.Write(chunk);
}
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-csharp#next-steps)

## Next steps

Now that you've added chat completion services to your Semantic Kernel project, you can start creating conversations with your AI agent. To learn more about using a chat completion service, check out the following articles:

- [Using the chat history object](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history)
- [Optimizing function calling with chat completion](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling)

1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fai-services%2Fchat-completion%2Fchat-history%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fai-services%2Fchat-completion%2Fchat-history%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Creating%20and%20managing%20a%20chat%20history%20object%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fai-services%2Fchat-completion%2Fchat-history%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Creating%20and%20managing%20a%20chat%20history%20object%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fai-services%2Fchat-completion%2Fchat-history%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Creating%20and%20managing%20a%20chat%20history%20object%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Creating%20and%20managing%20a%20chat%20history%20object%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fai-services%2Fchat-completion%2Fchat-history%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Chat history

- Article
- 06/24/2024
- 4 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [Creating a chat history object](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-csharp#creating-a-chat-history-object)
2. [Adding richer messages to a chat history](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-csharp#adding-richer-messages-to-a-chat-history)
3. [Simulating function calls](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-csharp#simulating-function-calls)
4. [Inspecting a chat history object](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-csharp#inspecting-a-chat-history-object)
5. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-csharp#next-steps)

The chat history object is used to maintain a record of messages in a chat session. It is used to store messages from different authors, such as users, assistants, tools, or the system. As the primary mechanism for sending and receiving messages, the chat history object is essential for maintaining context and continuity in a conversation.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-csharp#creating-a-chat-history-object)

## Creating a chat history object

A chat history object is a list under the hood, making it easy to create and add messages to.

C#Copy

```
using Microsoft.SemanticKernel.ChatCompletion;

// Create a chat history object
ChatHistory chatHistory = [];

chatHistory.AddSystemMessage("You are a helpful assistant.");
chatHistory.AddUserMessage("What's available to order?");
chatHistory.AddAssistantMessage("We have pizza, pasta, and salad available to order. What would you like to order?");
chatHistory.AddUserMessage("I'd like to have the first option, please.");
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-csharp#adding-richer-messages-to-a-chat-history)

## Adding richer messages to a chat history

The easiest way to add messages to a chat history object is to use the methods above. However, you can also add messages manually by creating a new `ChatMessage` object. This allows you to provide additional information, like names and images content.

C#Copy

```
using Microsoft.SemanticKernel.ChatCompletion;

// Add system message
chatHistory.Add(
    new() {
        Role = AuthorRole.System,
        Content = "You are a helpful assistant"
    }
);

// Add user message with an image
chatHistory.Add(
    new() {
        Role = AuthorRole.User,
        AuthorName = "Laimonis Dumins",
        Items = [
            new TextContent { Text = "What available on this menu" },
            new ImageContent { Uri = new Uri("https://example.com/menu.jpg") }
        ]
    }
);

// Add assistant message
chatHistory.Add(
    new() {
        Role = AuthorRole.Assistant,
        AuthorName = "Restaurant Assistant",
        Content = "We have pizza, pasta, and salad available to order. What would you like to order?"
    }
);

// Add additional message from a different user
chatHistory.Add(
    new() {
        Role = AuthorRole.User,
        AuthorName = "Ema Vargova",
        Content = "I'd like to have the first option, please."
    }
);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-csharp#simulating-function-calls)

## Simulating function calls

In addition to user, assistant, and system roles, you can also add messages from the tool role to simulate function calls. This is useful for teaching the AI how to use plugins and to provide additional context to the conversation.

For example, to inject information about the current user in the chat history without requiring the user to provide the information or having the LLM waste time asking for it, you can use the tool role to provide the information directly.

Below is an example of how we're able to provide user allergies to the assistant by simulating a function call to the `User` plugin.

 Tip

Simulated function calls is particularly helpful for providing details about the current user(s). Today's LLMs have been trained to be particularly sensitive to user information. Even if you provide user details in a system message, the LLM may still choose to ignore it. If you provide it via a user message, or tool message, the LLM is more likely to use it.

C#Copy

```
// Add a simulated function call from the assistant
chatHistory.Add(
    new() {
        Role = AuthorRole.Assistant,
        Items = [
            new FunctionCallContent(
                functionName: "get_user_allergies",
                pluginName: "User",
                id: "0001",
                arguments: new () { {"username", "laimonisdumins"} }
            ),
            new FunctionCallContent(
                functionName: "get_user_allergies",
                pluginName: "User",
                id: "0002",
                arguments: new () { {"username", "emavargova"} }
            )
        ]
    }
);

// Add a simulated function results from the tool role
chatHistory.Add(
    new() {
        Role = AuthorRole.Tool,
        Items = [
            new FunctionResultContent(
                functionName: "get_user_allergies",
                pluginName: "User",
                id: "0001",
                result: "{ \"allergies\": [\"peanuts\", \"gluten\"] }"
            )
        ]
    }
);
chatHistory.Add(
    new() {
        Role = AuthorRole.Tool,
        Items = [
            new FunctionResultContent(
                functionName: "get_user_allergies",
                pluginName: "User",
                id: "0002",
                result: "{ \"allergies\": [\"dairy\", \"soy\"] }"
            )
        ]
    }
);
```

 Important

When simulating tool results, you must always provide the `id` of the function call that the result corresponds to. This is important for the AI to understand the context of the result. Some LLMs, like OpenAI, will throw an error if the `id` is missing or if the `id` does not correspond to a function call.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-csharp#inspecting-a-chat-history-object)

## Inspecting a chat history object

Whenever you pass a chat history object to a chat completion service with auto function calling enabled, the chat history object will be manipulated so that it includes the function calls and results. This allows you to avoid having to manually add these messages to the chat history object and also allows you to inspect the chat history object to see the function calls and results.

You must still, however, add the final messages to the chat history object. Below is an example of how you can inspect the chat history object to see the function calls and results.

C#Copy

```
using Microsoft.SemanticKernel.ChatCompletion;

ChatHistory chatHistory = [
    new() {
        Role = AuthorRole.User,
        Content = "Please order me a pizza"
    }
];

// Get the current length of the chat history object
int currentChatHistoryLength = chatHistory.Count;

// Get the chat message content
ChatMessageContent results = await chatCompletionService.GetChatMessageContentAsync(
    chatHistory,
    kernel: kernel
);

// Get the new messages added to the chat history object
for (int i = currentChatHistoryLength; i < chatHistory.Count; i++)
{
    Console.WriteLine(chatHistory[i]);
}

// Print the final message
Console.WriteLine(results);

// Add the final message to the chat history object
chatHistory.Add(results);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-csharp#next-steps)

## Next steps

Now that you know how to create and manage a chat history object, you can learn more about function calling in the [Function calling](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling) topic.

[Learn how function calling works](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling)

# Function calling with chat completion

- Article
- 06/24/2024
- 5 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [How function calling works](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#how-function-calling-works)
2. [Example: Ordering a pizza](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#example-ordering-a-pizza)
3. [Parallel function calls](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#parallel-function-calls)
4. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#next-steps)

The most powerful feature of chat completion is the ability to call functions from the model. This allows you to create a chat bot that can interact with your existing code, making it possible to automate business processes, create code snippets, and more.

With Semantic Kernel, we simplify the process of using function calling by automatically describing your functions and their parameters to the model and then handling the back-and-forth communication between the model and your code.

When using function calling, however, it's good to understand what's _actually_ happening behind the scenes so that you can optimize your code and make the most of this feature.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#how-function-calling-works)

## How function calling works

When you make a request to a model with function calling enabled, Semantic Kernel performs the following steps:

Expand table

||Step|Description|
|---|---|---|
|1|[**Serialize functions**](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#1-serializing-the-functions)|All of the available functions (and its input parameters) in the kernel are serialized using JSON schema.|
|2|[**Send the messages and functions to the model**](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#2-sending-the-messages-and-functions-to-the-model)|The serialized functions (and the current chat history) are sent to the model as part of the input.|
|3|[**Model processes the input**](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#3-model-processes-the-input)|The model processes the input and generates a response. The response can either be a chat message or a function call|
|4|[**Handle the response**](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#4-handle-the-response)|If the response is a chat message, it is returned to the developer to print the response to the screen. If the response is a function call, however, Semantic Kernel extracts the function name and its parameters.|
|5|[**Invoke the function**](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#5-invoke-the-function)|The extracted function name and parameters are used to invoke the function in the kernel.|
|6|[**Return the function result**](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#6-return-the-function-result)|The result of the function is then sent back to the model as part of the chat history. Steps 2-6 are then repeated until the model sends a termination signal|

The following diagram illustrates the process of function calling:

![Semantic Kernel function calling](https://learn.microsoft.com/en-us/semantic-kernel/media/functioncalling.png)

The following section will use a concrete example to illustrate how function calling works in practice.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#example-ordering-a-pizza)

## Example: Ordering a pizza

Let's assume you have a plugin that allows a user to order a pizza. The plugin has the following functions:

1. `get_pizza_menu`: Returns a list of available pizzas
2. `add_pizza_to_cart`: Adds a pizza to the user's cart
3. `remove_pizza_from_cart`: Removes a pizza from the user's cart
4. `get_pizza_from_cart`: Returns the specific details of a pizza in the user's cart
5. `get_cart`: Returns the user's current cart
6. `checkout`: Checks out the user's cart

In C#, the plugin might look like this:

C#Copy

```
public class OrderPizzaPlugin(
    IPizzaService pizzaService,
    IUserContext userContext,
    IPaymentService paymentService)
{
    [KernelFunction("get_pizza_menu")]
    public async Task<Menu> GetPizzaMenuAsync()
    {
        return await pizzaService.GetMenu();
    }

    [KernelFunction("add_pizza_to_cart")]
    [Description("Add a pizza to the user's cart; returns the new item and updated cart")]
    public async Task<CartDelta> AddPizzaToCart(
        PizzaSize size,
        List<PizzaToppings> toppings,
        int quantity = 1,
        string specialInstructions = ""
    )
    {
        Guid cartId = userContext.GetCartId();
        return await pizzaService.AddPizzaToCart(
            cartId: cartId,
            size: size,
            toppings: toppings,
            quantity: quantity,
            specialInstructions: specialInstructions);
    }

    [KernelFunction("remove_pizza_from_cart")]
    public async Task<RemovePizzaResponse> RemovePizzaFromCart(int pizzaId)
    {
        Guid cartId = userContext.GetCartId();
        return await pizzaService.RemovePizzaFromCart(cartId, pizzaId);
    }

    [KernelFunction("get_pizza_from_cart")]
    [Description("Returns the specific details of a pizza in the user's cart; use this instead of relying on previous messages since the cart may have changed since then.")]
    public async Task<Pizza> GetPizzaFromCart(int pizzaId)
    {
        Guid cartId = await userContext.GetCartIdAsync();
        return await pizzaService.GetPizzaFromCart(cartId, pizzaId);
    }

    [KernelFunction("get_cart")]
    [Description("Returns the user's current cart, including the total price and items in the cart.")]
    public async Task<Cart> GetCart()
    {
        Guid cartId = await userContext.GetCartIdAsync();
        return await pizzaService.GetCart(cartId);
    }

    [KernelFunction("checkout")]
    [Description("Checkouts the user's cart; this function will retrieve the payment from the user and complete the order.")]
    public async Task<CheckoutResponse> Checkout()
    {
        Guid cartId = await userContext.GetCartIdAsync();
        Guid paymentId = await paymentService.RequestPaymentFromUserAsync(cartId);

        return await pizzaService.Checkout(cartId, paymentId);
    }
}
```

You would then add this plugin to the kernel like so:

C#Copy

```
IKernelBuilder kernelBuilder = new KernelBuilder();
kernelBuilder..AddAzureOpenAIChatCompletion(
    deploymentName: "NAME_OF_YOUR_DEPLOYMENT",
    apiKey: "YOUR_API_KEY",
    endpoint: "YOUR_AZURE_ENDPOINT"
);
kernelBuilder.Plugins.AddFromType<OrderPizzaPlugin>("OrderPizza");
Kernel kernel = kernelBuilder.Build();
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#1-serializing-the-functions)

### 1) Serializing the functions

When you create a kernel with the `OrderPizzaPlugin`, the kernel will automatically serialize the functions and their parameters. This is necessary so that the model can understand the functions and their inputs.

For the above plugin, the serialized functions would look like this:

JSONCopy

```
[
  {
    "type": "function",
    "function": {
      "name": "OrderPizza-get_pizza_menu",
      "parameters": {
        "type": "object",
        "properties": {},
        "required": []
      }
    }
  },
  {
    "type": "function",
    "function": {
      "name": "OrderPizza-add_pizza_to_cart",
      "description": "Add a pizza to the user's cart; returns the new item and updated cart",
      "parameters": {
        "type": "object",
        "properties": {
          "size": {
            "type": "string",
            "enum": ["Small", "Medium", "Large"]
          },
          "toppings": {
            "type": "array",
            "items": {
              "type": "string",
              "enum": ["Cheese", "Pepperoni", "Mushrooms"]
            }
          },
          "quantity": {
            "type": "integer",
            "default": 1,
            "description": "Quantity of pizzas"
          },
          "specialInstructions": {
            "type": "string",
            "default": "",
            "description": "Special instructions for the pizza"
          }
        },
        "required": ["size", "toppings"]
      }
    }
  },
  {
    "type": "function",
    "function": {
      "name": "OrderPizza-remove_pizza_from_cart",
      "parameters": {
        "type": "object",
        "properties": {
          "pizzaId": {
            "type": "integer"
          }
        },
        "required": ["pizzaId"]
      }
    }
  },
  {
    "type": "function",
    "function": {
      "name": "OrderPizza-get_pizza_from_cart",
      "description": "Returns the specific details of a pizza in the user's cart; use this instead of relying on previous messages since the cart may have changed since then.",
      "parameters": {
        "type": "object",
        "properties": {
          "pizzaId": {
            "type": "integer"
          }
        },
        "required": ["pizzaId"]
      }
    }
  },
  {
    "type": "function",
    "function": {
      "name": "OrderPizza-get_cart",
      "description": "Returns the user's current cart, including the total price and items in the cart.",
      "parameters": {
        "type": "object",
        "properties": {},
        "required": []
      }
    }
  },
  {
    "type": "function",
    "function": {
      "name": "OrderPizza-checkout",
      "description": "Checkouts the user's cart; this function will retrieve the payment from the user and complete the order.",
      "parameters": {
        "type": "object",
        "properties": {},
        "required": []
      }
    }
  }
]
```

There's a few things to note here which can impact both the performance and the quality of the chat completion:

1. **Verbosity of function schema** – Serializing functions for the model to use doesn't come for free. The more verbose the schema, the more tokens the model has to process, which can slow down the response time and increase costs.
    
     Tip
    
    Keep your functions as simple as possible. In the above example, you'll notice that not _all_ functions have descriptions where the function name is self-explanatory. This is intentional to reduce the number of tokens. The parameters are also kept simple; anything the model shouldn't need to know (like the `cartId` or `paymentId`) are kept hidden. This information is instead provided by internal services.
    
     Note
    
    The one thing you don't need to worry about is the complexity of the return types. You'll notice that the return types are not serialized in the schema. This is because the model doesn't need to know the return type to generate a response. In the step 6, however, we'll see how overly verbose return types can impact the quality of the chat completion.
    
2. **Parameter types** – With the schema, you can specify the type of each parameter. This is important for the model to understand the expected input. In the above example, the `size` parameter is an enum, and the `toppings` parameter is an array of enums. This helps the model generate more accurate responses.
    
     Tip
    
    Avoid, where possible, using `string` as a parameter type. The model can't infer the type of string, which can lead to ambiguous responses. Instead, use enums or other types (e.g., `int`, `float`, and complex types) where possible.
    
3. **Required parameters** - You can also specify which parameters are required. This is important for the model to understand which parameters are _actually_ necessary for the function to work. Later on in step 3, the model will use this information to provide as minimal information as necessary to call the function.
    
     Tip
    
    Only mark parameters as required if they are _actually_ required. This helps the model call functions more quickly and accurately.
    
4. **Function descriptions** – Function descriptions are optional but can help the model generate more accurate responses. In particular, descriptions can tell the model what to expect from the response since the return type is not serialized in the schema. If the model is using functions improperly, you can also add descriptions to provide examples and guidance.
    
    For example, in the `get_pizza_from_cart` function, the description tells the user to use this function instead of relying on previous messages. This is important because the cart may have changed since the last message.
    
     Tip
    
    Before adding a description, ask yourself if the model _needs_ this information to generate a response. If not, consider leaving it out to reduce verbosity. You can always add descriptions later if the model is struggling to use the function properly.
    
5. **Plugin name** – As you can see in the serialized functions, each function has a `name` property. Semantic Kernel uses the plugin name to namespace the functions. This is important because it allows you to have multiple plugins with functions of the same name. For example, you may have plugins for multiple search services, each with their own `search` function. By namespacing the functions, you can avoid conflicts and make it easier for the model to understand which function to call.
    
    Knowing this, you should choose a plugin name that is unique and descriptive. In the above example, the plugin name is `OrderPizza`. This makes it clear that the functions are related to ordering pizza.
    
     Tip
    
    When choosing a plugin name, we recommend removing superfluous words like "plugin" or "service". This helps reduce verbosity and makes the plugin name easier to understand for the model.
    

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#2-sending-the-messages-and-functions-to-the-model)

### 2) Sending the messages and functions to the model

Once the functions are serialized, they are sent to the model along with the current chat history. This allows the model to understand the context of the conversation and the available functions.

In this scenario, we can imagine the user asking the assistant to add a pizza to their cart:

C#Copy

```
ChatHistory chatHistory = [];
chatHistory.AddUserMessage("I'd like to order a pizza!");
```

We can then send this chat history and the serialized functions to the model. The model will use this information to determine the best way to respond.

C#Copy

```
IChatCompletionService chatCompletion = kernel.GetRequiredService<IChatCompletionService>();

OpenAIPromptExecutionSettings openAIPromptExecutionSettings = new() 
{
    ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions
};

ChatResponse response = await chatCompletion.GetChatMessageContentAsync(
    chatHistory,
    executionSettings: openAIPromptExecutionSettings,
    kernel: kernel)
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#3-model-processes-the-input)

### 3) Model processes the input

With both the chat history and the serialized functions, the model can determine the best way to respond. In this case, the model recognizes that the user wants to order a pizza. The model would likely _want_ to call the `add_pizza_to_cart` function, but because we specified the size and toppings as required parameters, the model will ask the user for this information:

C#Copy

```
Console.WriteLine(response);
chatHistory.AddAssistantMessage(response);

// "Before I can add a pizza to your cart, I need to
// know the size and toppings. What size pizza would
// you like? Small, medium, or large?"
```

Since the model wants the user to respond next, a termination signal will be sent to Semantic Kernel to stop automatic function calling until the user responds.

At this point, the user can respond with the size and toppings of the pizza they want to order:

C#Copy

```
chatHistory.AddUserMessage("I'd like a medium pizza with cheese and pepperoni, please.");

response = await chatCompletion.GetChatMessageContentAsync(
    chatHistory,
    kernel: kernel)
```

Now that the model has the necessary information, it can now call the `add_pizza_to_cart` function with the user's input. Behind the scenes, it adds a new message to the chat history that looks like this:

C#Copy

```
"tool_calls": [
    {
        "id": "call_abc123",
        "type": "function",
        "function": {
            "name": "OrderPizzaPlugin-add_pizza_to_cart",
            "arguments": "{\n\"size\": \"Medium\",\n\"toppings\": [\"Cheese\", \"Pepperoni\"]\n}"
        }
    }
]
```

 Tip

It's good to remember that every argument you require must be generated by the model. This means spending tokens to generate the response. Avoid arguments that require many tokens (like a GUID). For example, notice that we use an `int` for the `pizzaId`. Asking the model to send a one to two digit number is much easier than asking for a GUID.

 Important

This step is what makes function calling so powerful. Previously, AI app developers had to create separate processes to extract intent and slot fill functions. With function calling, the model can decide _when_ to call a function and _what_ information to provide.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#4-handle-the-response)

### 4) Handle the response

When Semantic Kernel receives the response from the model, it checks if the response is a function call. If it is, Semantic Kernel extracts the function name and its parameters. In this case, the function name is `OrderPizzaPlugin-add_pizza_to_cart`, and the arguments are the size and toppings of the pizza.

With this information, Semantic Kernel can marshal the inputs into the appropriate types and pass them to the `add_pizza_to_cart` function in the `OrderPizzaPlugin`. In this example, the arguments originate as a JSON string but are deserialized by Semantic Kernel into a `PizzaSize` enum and a `List<PizzaToppings>`.

 Note

Marshaling the inputs into the correct types is one of the key benefits of using Semantic Kernel. Everything from the model comes in as a JSON object, but Semantic Kernel can automatically deserialize these objects into the correct types for your functions.

After marshalling the inputs, Semantic Kernel can also add the function call to the chat history:

C#Copy

```
chatHistory.Add(
    new() {
        Role = AuthorRole.Assistant,
        Items = [
            new FunctionCallContent(
                functionName: "add_pizza_to_cart",
                pluginName: "OrderPizza",
                id: "call_abc123",
                arguments: new () { {"size", "Medium"}, {"toppings", ["Cheese", "Pepperoni"]} }
            )
        ]
    }
);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#5-invoke-the-function)

### 5) Invoke the function

Once Semantic Kernel has the correct types, it can finally invoke the `add_pizza_to_cart` function. Because the plugin uses dependency injection, the function can interact with external services like `pizzaService` and `userContext` to add the pizza to the user's cart.

Not all functions will succeed, however. If the function fails, Semantic Kernel can handle the error and provide a default response to the model. This allows the model to understand what went wrong and generate a response to the user.

 Tip

To ensure a model can self-correct, it's important to provide error messages that clearly communicate what went wrong and how to fix it. This can help the model retry the function call with the correct information.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#6-return-the-function-result)

### 6) Return the function result

After the function has been invoked, the function result is sent back to the model as part of the chat history. This allows the model to understand the context of the conversation and generate a subsequent response.

Behind the scenes, Semantic Kernel adds a new message to the chat history from the tool role that looks like this:

C#Copy

```
chatHistory.Add(
    new() {
        Role = AuthorRole.Tool,
        Items = [
            new FunctionResultContent(
                functionName: "add_pizza_to_cart",
                pluginName: "OrderPizza",
                id: "0001",
                result: "{ \"new_items\": [ { \"id\": 1, \"size\": \"Medium\", \"toppings\": [\"Cheese\",\"Pepperoni\"] } ] }"
            )
        ]
    }
);
```

Notice that the result is a JSON string that the model then needs to process. As before, the model will need to spend tokens consuming this information. This is why it's important to keep the return types as simple as possible. In this case, the return only includes the new items added to the cart, not the entire cart.

 Tip

Be as succinct as possible with your returns. Where possible, only return the information the model needs or summarize the information using another LLM prompt before returning it.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#repeat-steps-2-6)

### Repeat steps 2-6

After the result is returned to the model, the process repeats. The model processes the latest chat history and generates a response. In this case, the model might ask the user if they want to add another pizza to their cart or if they want to check out.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#parallel-function-calls)

## Parallel function calls

In the above example, we demonstrated how an LLM can call a single function. Often this can be slow if you need to call multiple functions in sequence. To speed up the process, several LLMs support parallel function calls. This allows the LLM to call multiple functions at once, speeding up the process.

For example, if a user wants to order multiple pizzas, the LLM can call the `add_pizza_to_cart` function for each pizza at the same time. This can significantly reduce the number of round trips to the LLM and speed up the ordering process.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-csharp#next-steps)

## Next steps

Now that you understand how function calling works, you can now learn how to actually use function calling in Semantic Kernel by referring to the [planning article](https://learn.microsoft.com/en-us/semantic-kernel/concepts/planning)
3 Semantic Kernel Plugins.md
77.79 KB • 1451 extracted lines
Formatting may be inconsistent from source.
# What is a Plugin?

- Article
- 06/24/2024
- 3 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [Anatomy of a plugin](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#anatomy-of-a-plugin)
2. [Getting started with plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#getting-started-with-plugins)

Plugins are a key component of Semantic Kernel. If you have already used plugins from ChatGPT or Copilot extensions in Microsoft 365, you’re already familiar with them. With plugins, you can encapsulate your existing APIs into a collection that can be used by an AI. This allows you to give your AI the ability to perform actions that it wouldn’t be able to do otherwise.

Behind the scenes, Semantic Kernel leverages [function calling](https://platform.openai.com/docs/guides/function-calling), a native feature of most of the latest LLMs to allow LLMs, to perform [planning](https://learn.microsoft.com/en-us/semantic-kernel/concepts/planning) and to invoke your APIs. With function calling, LLMs can request (i.e., call) a particular function. Semantic Kernel then marshals the request to the appropriate function in your codebase and returns the results back to the LLM so the LLM can generate a final response.

![Semantic Kernel Plugin](https://learn.microsoft.com/en-us/semantic-kernel/media/designed-for-modular-extensibility-vertical.png)

Not all AI SDKs have an analogous concept to plugins (most just have functions or tools). In enterprise scenarios, however, plugins are valuable because they encapsulate a set of functionality that mirrors how enterprise developers already develop services and APIs. Plugins also play nicely with dependency injection. Within a plugin's constructor, you can inject services that are necessary to perform the work of the plugin (e.g., database connections, HTTP clients, etc.). This is difficult to accomplish with other SDKs that lack plugins.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#anatomy-of-a-plugin)

## Anatomy of a plugin

At a high-level, a plugin is a group of [functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#importing-different-types-of-plugins) that can be exposed to AI apps and services. The functions within plugins can then be orchestrated by an AI application to accomplish user requests. Within Semantic Kernel, you can invoke these functions automatically with function calling.

 Note

In other platforms, functions are often referred to as "tools" or "actions". In Semantic Kernel, we use the term "functions" since they are typically defined as native functions in your codebase.

Just providing functions, however, is not enough to make a plugin. To power automatic orchestration with function calling, plugins also need to provide details that semantically describe how they behave. Everything from the function's input, output, and side effects need to be described in a way that the AI can understand, otherwise, the AI will not correctly call the function.

For example, the sample `WriterPlugin` plugin on the right has functions with semantic descriptions that describe what each function does. An LLM can then use these descriptions to choose the best functions to call to fulfill a user's ask.

In the picture on the right, an LLM would likely call the `ShortPoem` and `StoryGen` functions to satisfy the users ask thanks to the provided semantic descriptions.

![Semantic description within the WriterPlugin plugin](https://learn.microsoft.com/en-us/semantic-kernel/media/writer-plugin-example.png)

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#importing-different-types-of-plugins)

### Importing different types of plugins

There are two primary ways of importing plugins into Semantic Kernel: using [native code](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins) or using an [OpenAPI specification](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins). The former allows you to author plugins in your existing codebase that can leverage dependencies and services you already have. The latter allows you to import plugins from an OpenAPI specification, which can be shared across different programming languages and platforms.

Below we provide a simple example of importing and using a native plugin. To learn more about how to import these different types of plugins, refer to the following articles:

- [Importing native code](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins)
- [Importing an OpenAPI specification](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins)

 Tip

When getting started, we recommend using native code plugins. As your application matures, and as you work across cross-platform teams, you may want to consider using OpenAPI specifications to share plugins across different programming languages and platforms.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#the-different-types-of-plugin-functions)

### The different types of plugin functions

Within a plugin, you will typically have two different types of functions, those that retrieve data for retrieval augmented generation (RAG) and those that automate tasks. While each type is functionally the same, they are typically used differently within applications that use Semantic Kernel.

For example, with retrieval functions, you may want to use strategies to improve performance (e.g., caching and using cheaper intermediate models for summarization). Whereas with task automation functions, you'll likely want to implement human-in-the-loop approval processes to ensure that tasks are completed correctly.

To learn more about the different types of plugin functions, refer to the following articles:

- [Data retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag)
- [Task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions)

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#getting-started-with-plugins)

## Getting started with plugins

Using plugins within Semantic Kernel is always a three step process:

1. [Define your plugin](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#1-define-your-plugin)
2. [Add the plugin to your kernel](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#2-add-the-plugin-to-your-kernel)
3. [And then either invoke the plugin's functions in either a prompt with function calling](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#3-invoke-the-plugins-functions)

Below we'll provide a high-level example of how to use a plugin within Semantic Kernel. Refer to the links above for more detailed information on how to create and use plugins.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#1-define-your-plugin)

### 1) Define your plugin

The easiest way to create a plugin is by defining a class and annotating its methods with the `KernelFunction` attribute. This let's Semantic Kernel know that this is a function that can be called by an AI or referenced in a prompt.

You can also import plugins from an [OpenAPI specification](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins).

Below, we'll create a plugin that can retrieve the state of lights and alter its state.

 Tip

Since most LLM have been trained with Python for function calling, its recommended to use snake case for function names and property names even if you're using the C# or Java SDK.

C#Copy

```
using System.ComponentModel;
using Microsoft.SemanticKernel;

public class LightsPlugin
{
   // Mock data for the lights
   private readonly List<LightModel> lights = new()
   {
      new LightModel { Id = 1, Name = "Table Lamp", IsOn = false, Brightness = 100, Hex = "FF0000" },
      new LightModel { Id = 2, Name = "Porch light", IsOn = false, Brightness = 50, Hex = "00FF00" },
      new LightModel { Id = 3, Name = "Chandelier", IsOn = true, Brightness = 75, Hex = "0000FF" }
   };

   [KernelFunction("get_lights")]
   [Description("Gets a list of lights and their current state")]
   [return: Description("An array of lights")]
   public async Task<List<LightModel>> GetLightsAsync()
   {
      return lights
   }

   [KernelFunction("get_state")]
   [Description("Gets the state of a particular light")]
   [return: Description("The state of the light")]
   public async Task<LightModel?> GetStateAsync([Description("The ID of the light")] int id)
   {
      // Get the state of the light with the specified ID
      return lights.FirstOrDefault(light => light.Id == id);
   }

   [KernelFunction("change_state")]
   [Description("Changes the state of the light")]
   [return: Description("The updated state of the light; will return null if the light does not exist")]
   public async Task<LightModel?> ChangeStateAsync(int id, LightModel LightModel)
   {
      var light = lights.FirstOrDefault(light => light.Id == id);

      if (light == null)
      {
         return null;
      }

      // Update the light with the new state
      light.IsOn = LightModel.IsOn;
      light.Brightness = LightModel.Brightness;
      light.Hex = LightModel.Hex;

      return light;
   }
}

public class LightModel
{
   [JsonPropertyName("id")]
   public int Id { get; set; }

   [JsonPropertyName("name")]
   public string Name { get; set; }

   [JsonPropertyName("is_on")]
   public bool? IsOn { get; set; }

   [JsonPropertyName("brightness")]
   public byte? Brightness { get; set; }

   [JsonPropertyName("hex")]
   public string? Hex { get; set; }
}
```

Notice that we provide descriptions for the function, return value, and parameters. This is important for the AI to understand what the function does and how to use it.

 Tip

Don't be afraid to provide detailed descriptions for your functions if an AI is having trouble calling them. Few-shot examples, recommendations for when to use (and not use) the function, and guidance on where to get required parameters can all be helpful.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#2-add-the-plugin-to-your-kernel)

### 2) Add the plugin to your kernel

Once you've defined your plugin, you can add it to your kernel by creating a new instance of the plugin and adding it to the kernel's plugin collection.

This example demonstrates the easiest way of adding a class as a plugin with the `AddFromType` method. To learn about other ways of adding plugins, refer to the [adding native plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins) article.

C#Copy

```
var builder = new KernelBuilder();
builder.Plugins.AddFromType<LightsPlugin>("Lights")
Kernel kernel = builder.Build();
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#3-invoke-the-plugins-functions)

### 3) Invoke the plugin's functions

Finally, you can have the AI invoke your plugin's functions by using function calling. Below is an example that demonstrates how to coax the AI to call the `get_lights` function from the `Lights` plugin before calling the `change_state` function to turn on a light.

C#Copy

```
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using Microsoft.SemanticKernel.Connectors.OpenAI;

// Create a kernel with Azure OpenAI chat completion
var builder = Kernel.CreateBuilder().AddAzureOpenAIChatCompletion(modelId, endpoint, apiKey);

// Build the kernel
Kernel kernel = builder.Build();
var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();

// Add a plugin (the LightsPlugin class is defined below)
kernel.Plugins.AddFromType<LightsPlugin>("Lights");

// Enable planning
OpenAIPromptExecutionSettings openAIPromptExecutionSettings = new() 
{
    ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions
};

// Create a history store the conversation
var history = new ChatHistory();
history.AddUserMessage("Please turn on the lamp");

// Get the response from the AI
var result = await chatCompletionService.GetChatMessageContentAsync(
   history,
   executionSettings: openAIPromptExecutionSettings,
   kernel: kernel);

// Print the results
Console.WriteLine("Assistant > " + result);

// Add the message from the agent to the chat history
history.AddAssistantMessage(result);
```

With the above code, you should get a response that looks like the following:

Expand table

|Role|Message|
|---|---|
|🔵 **User**|Please turn on the lamp|
|🔴 **Assistant (function call)**|`Lights.get_lights()`|
|🟢 **Tool**|`[{ "id": 1, "name": "Table Lamp", "isOn": false, "brightness": 100, "hex": "FF0000" }, { "id": 2, "name": "Porch light", "isOn": false, "brightness": 50, "hex": "00FF00" }, { "id": 3, "name": "Chandelier", "isOn": true, "brightness": 75, "hex": "0000FF" }]`|
|🔴 **Assistant (function call)**|Lights.change_state(1, { "isOn": true })|
|🟢 **Tool**|`{ "id": 1, "name": "Table Lamp", "isOn": true, "brightness": 100, "hex": "FF0000" }`|
|🔴 **Assistant**|The lamp is now on|

 Tip

While you can invoke a plugin function directly, this is not advised because the AI should be the one deciding which functions to call. If you need explicit control over which functions are called, consider using standard methods in your codebase instead of plugins.

1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-native-plugins%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-native-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Provide%20native%20code%20to%20your%20agents%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-native-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Provide%20native%20code%20to%20your%20agents%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-native-plugins%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Provide%20native%20code%20to%20your%20agents%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Provide%20native%20code%20to%20your%20agents%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-native-plugins%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Add native code as a plugin

- Article
- 06/24/2024
- 3 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [Providing the LLM with the right information](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#providing-the-llm-with-the-right-information)
2. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#next-steps)

The easiest way to provide an AI agent with capabilities that are not natively supported is to wrap native code into a plugin. This allows you to leverage your existing skills as an app developer to extend the capabilities of your AI agents.

Behind the scenes, Semantic Kernel will then use the descriptions you provide, along with reflection, to semantically describe the plugin to the AI agent. This allows the AI agent to understand the capabilities of the plugin and how to interact with it.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#providing-the-llm-with-the-right-information)

## Providing the LLM with the right information

When authoring a plugin, you need to provide the AI agent with the right information to understand the capabilities of the plugin and its functions. This includes:

- The name of the plugin
- The names of the functions
- The descriptions of the functions
- The parameters of the functions
- The schema of the parameters

The value of Semantic Kernel is that it can automatically generate most of this information from the code itself. As a developer, this just means that you must provide the semantic descriptions of the functions and parameters so the AI agent can understand them. If you properly comment and annotate your code, however, you likely already have this information on hand.

Below, we'll walk through the two different ways of providing your AI agent with native code and how to provide this semantic information.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#defining-a-plugin-using-a-class)

### Defining a plugin using a class

The easiest way to create a native plugin is to start with a class and then add methods annotated with the `KernelFunction` attribute. It is also recommended to liberally use the `Description` annotation to provide the AI agent with the necessary information to understand the function.

C#Copy

```
public class LightsPlugin
{
   private readonly List<LightModel> _lights;

   public LightsPlugin(LoggerFactory loggerFactory, List<LightModel> lights)
   {
      _lights = lights;
   }

   [KernelFunction("get_lights")]
   [Description("Gets a list of lights and their current state")]
   [return: Description("An array of lights")]
   public async Task<List<LightModel>> GetLightsAsync()
   {
      return _lights;
   }

   [KernelFunction("change_state")]
   [Description("Changes the state of the light")]
   [return: Description("The updated state of the light; will return null if the light does not exist")]
   public async Task<LightModel?> ChangeStateAsync(LightModel changeState)
   {
      // Find the light to change
      var light = _lights.FirstOrDefault(l => l.Id == changeState.Id);

      // If the light does not exist, return null
      if (light == null)
      {
         return null;
      }

      // Update the light state
      light.IsOn = changeState.IsOn;
      light.Brightness = changeState.Brightness;
      light.Color = changeState.Color;

      return light;
   }
}
```

 Tip

Because the LLMs are predominantly trained on Python code, it is recommended to use snake_case for function names and parameters (even if you're using C# or Java). This will help the AI agent better understand the function and its parameters.

If your function has a complex object as an input variable, Semantic Kernel will also generate a schema for that object and pass it to the AI agent. Similar to functions, you should provide `Description` annotations for properties that are non-obvious to the AI. Below is the definition for the `LightState` class and the `Brightness` enum.

C#Copy

```
using System.Text.Json.Serialization;

public class LightModel
{
   [JsonPropertyName("id")]
   public int Id { get; set; }

   [JsonPropertyName("name")]
   public string? Name { get; set; }

   [JsonPropertyName("is_on")]
   public bool? IsOn { get; set; }

   [JsonPropertyName("brightness")]
   public enum? Brightness { get; set; }

   [JsonPropertyName("color")]
   [Description("The color of the light with a hex code (ensure you include the # symbol)")]
   public string? Color { get; set; }
}

[JsonConverter(typeof(JsonStringEnumConverter))]
public enum Brightness
{
   Low,
   Medium,
   High
}
```

 Note

While this is a "fun" example, it does a good job showing just how complex a plugin's parameters can be. In this single case, we have a complex object with _four_ different types of properties: an integer, string, boolean, and enum. Semantic Kernel's value is that it can automatically generate the schema for this object and pass it to the AI agent and marshal the parameters generated by the AI agent into the correct object.

Once you're done authoring your plugin class, you can add it to the kernel using the `AddFromType<>` or `AddFromObject` methods.

 Tip

When creating a function, always ask yourself "how can I give the AI additional help to use this function?" This can include using specific input types (avoid strings where possible), providing descriptions, and examples.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#adding-a-plugin-using-the-addfromobject-method)

#### Adding a plugin using the `AddFromObject` method

The `AddFromObject` method allows you to add an instance of the plugin class directly to the plugin collection in case you want to directly control how the plugin is constructed.

For example, the constructor of the `LightsPlugin` class requires the list of lights. In this case, you can create an instance of the plugin class and add it to the plugin collection.

C#Copy

```
List<LightModel> lights = new()
   {
      new LightModel { Id = 1, Name = "Table Lamp", IsOn = false, Brightness = Brightness.Medium, Color = "#FFFFFF" },
      new LightModel { Id = 2, Name = "Porch light", IsOn = false, Brightness = Brightness.High, Color = "#FF0000" },
      new LightModel { Id = 3, Name = "Chandelier", IsOn = true, Brightness = Brightness.Low, Color = "#FFFF00" }
   };

kernel.Plugins.AddFromObject(new LightsPlugin(lights));
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#adding-a-plugin-using-the-addfromtype-method)

#### Adding a plugin using the `AddFromType<>` method

When using the `AddFromType<>` method, the kernel will automatically use dependency injection to create an instance of the plugin class and add it to the plugin collection.

This is helpful if your constructor requires services or other dependencies to be injected into the plugin. For example, our `LightsPlugin` class may require a logger and a light service to be injected into it instead of a list of lights.

C#Copy

```
public class LightsPlugin
{
   private readonly Logger _logger;
   private readonly LightService _lightService;

   public LightsPlugin(LoggerFactory loggerFactory, LightService lightService)
   {
      _logger = loggerFactory.CreateLogger<LightsPlugin>();
      _lightService = lightService;
   }

   [KernelFunction("get_lights")]
   [Description("Gets a list of lights and their current state")]
   [return: Description("An array of lights")]
   public async Task<List<LightModel>> GetLightsAsync()
   {
      _logger.LogInformation("Getting lights");
      return lightService.GetLights();
   }

   [KernelFunction("change_state")]
   [Description("Changes the state of the light")]
   [return: Description("The updated state of the light; will return null if the light does not exist")]
   public async Task<LightModel?> ChangeStateAsync(LightModel changeState)
   {
      _logger.LogInformation("Changing light state");
      return lightService.ChangeState(changeState);
   }
}
```

With Dependency Injection, you can add the required services and plugins to the kernel builder before building the kernel.

C#Copy

```
var builder = Kernel.CreateBuilder();

// Add dependencies for the plugin
builder.Services.AddLogging(loggingBuilder => loggingBuilder.AddConsole().SetMinimumLevel(LogLevel.Trace));
builder.Services.AddSingleton<LightService>();

// Add the plugin to the kernel
builder.Plugins.AddFromType<LightsPlugin>("Lights");

// Build the kernel
Kernel kernel = builder.Build();
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#defining-a-plugin-using-a-collection-of-functions)

### Defining a plugin using a collection of functions

Less common but still useful is defining a plugin using a collection of functions. This is particularly useful if you need to dynamically create a plugin from a set of functions at runtime.

Using this process requires you to use the function factory to create individual functions before adding them to the plugin.

C#Copy

```
kernel.Plugins.AddFromFunctions("time_plugin",
[
    KernelFunctionFactory.CreateFromMethod(
        method: () => DateTime.Now,
        functionName: "get_time",
        description: "Get the current time"
    ),
    KernelFunctionFactory.CreateFromMethod(
        method: (DateTime start, DateTime end) => (end - start).TotalSeconds,
        functionName: "diff_time",
        description: "Get the difference between two times in seconds"
    )
]);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#additional-strategies-for-adding-native-code-with-dependency-injection)

### Additional strategies for adding native code with Dependency Injection

If you're working with Dependency Injection, there are additional strategies you can take to create and add plugins to the kernel. Below are some examples of how you can add a plugin using Dependency Injection.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#inject-a-plugin-collection)

#### Inject a plugin collection

 Tip

We recommend making your plugin collection a transient service so that it is disposed of after each use since the plugin collection is mutable. Creating a new plugin collection for each use is cheap, so it should not be a performance concern.

C#Copy

```
var builder = Host.CreateApplicationBuilder(args);

// Create native plugin collection
builder.Services.AddTransient((serviceProvider)=>{
   KernelPluginCollection pluginCollection = [];
   pluginCollection.AddFromType<LightsPlugin>("Lights");

   return pluginCollection;
});

// Create the kernel service
builder.Services.AddTransient<Kernel>((serviceProvider)=> {
   KernelPluginCollection pluginCollection = serviceProvider.GetRequiredService<KernelPluginCollection>();

   return new Kernel(serviceProvider, pluginCollection);
});
```

 Tip

As mentioned in the [kernel article](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel), the kernel is extremely lightweight, so creating a new kernel for each use as a transient is not a performance concern.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#generate-your-plugins-as-singletons)

#### Generate your plugins as singletons

Plugins are not mutable, so its typically safe to create them as singletons. This can be done by using the plugin factory and adding the resulting plugin to your service collection.

C#Copy

```
var builder = Host.CreateApplicationBuilder(args);

// Create singletons of your plugin
builder.Services.AddKeyedSingleton("LightPlugin", (serviceProvider, key) => {
    return KernelPluginFactory.CreateFromType<LightsPlugin>();
});

// Create a kernel service with singleton plugin
builder.Services.AddTransient((serviceProvider)=> {
    KernelPluginCollection pluginCollection = [
      serviceProvider.GetRequiredKeyedService<KernelPlugin>("LightPlugin")
    ];

    return new Kernel(serviceProvider, pluginCollection);
});
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#next-steps)

## Next steps

Now that you know how to create a plugin, you can now learn how to use them with your AI agent. Depending on the type of functions you've added to your plugins, there are different patterns you should follow. For retrieval functions, refer to the [using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag) article. For task automation functions, refer to the [using task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions) article.

[Learn about using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag)

1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-openapi-plugins%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-openapi-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Give%20agents%20access%20to%20OpenAPI%20APIs%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-openapi-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Give%20agents%20access%20to%20OpenAPI%20APIs%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-openapi-plugins%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Give%20agents%20access%20to%20OpenAPI%20APIs%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Give%20agents%20access%20to%20OpenAPI%20APIs%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-openapi-plugins%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Add plugins from OpenAPI specifications

- Article
- 06/24/2024
- 2 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [An example OpenAPI specification](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#an-example-openapi-specification)
2. [Adding the OpenAPI plugin](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#adding-the-openapi-plugin)
3. [Tips and tricks for adding OpenAPI plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#tips-and-tricks-for-adding-openapi-plugins)
4. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#next-steps)

Often in an enterprise, you already have a set of APIs that perform real work. These could be used by other automation services or power front-end applications that humans interact with. In Semantic Kernel, you can add these exact same APIs as plugins so your agents can also use them.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#an-example-openapi-specification)

## An example OpenAPI specification

Take for example an API that allows you to alter the state of light bulbs. The OpenAPI specification for this API might look like this:

JSONCopy

```
{
   "openapi": "3.0.1",
   "info": {
      "title": "Light API",
      "version": "v1"
   },
   "paths": {
      "/Light": {
         "get": {
            "tags": [
               "Light"
            ],
            "summary": "Retrieves all lights in the system.",
            "operationId": "get_all_lights",
            "responses": {
               "200": {
                  "description": "Returns a list of lights with their current state",
                  "application/json": {
                     "schema": {
                        "type": "array",
                        "items": {
                              "$ref": "#/components/schemas/LightStateModel"
                        }
                     }
                  }
               }
            }
         }
      },
      "/Light/{id}": {
         "post": {
               "tags": [
                  "Light"
               ],
               "summary": "Changes the state of a light.",
               "operationId": "change_light_state",
               "parameters": [
                  {
                     "name": "id",
                     "in": "path",
                     "description": "The ID of the light to change from the get_all_lights tool.",
                     "required": true,
                     "style": "simple",
                     "schema": {
                           "type": "string"
                     }
                  }
               ],
               "requestBody": {
                  "description": "The new state of the light and change parameters.",
                  "content": {
                     "application/json": {
                           "schema": {
                              "$ref": "#/components/schemas/ChangeStateRequest"
                           }
                     }
                  }
               },
               "responses": {
                  "200": {
                     "description": "Returns the updated light state",
                     "content": {
                           "application/json": {
                              "schema": {
                                 "$ref": "#/components/schemas/LightStateModel"
                              }
                           }
                     }
                  },
                  "404": {
                     "description": "If the light is not found"
                  }
               }
         }
      }
   },
   "components": {
      "schemas": {
         "ChangeStateRequest": {
               "type": "object",
               "properties": {
                  "isOn": {
                     "type": "boolean",
                     "description": "Specifies whether the light is turned on or off.",
                     "nullable": true
                  },
                  "hexColor": {
                     "type": "string",
                     "description": "The hex color code for the light.",
                     "nullable": true
                  },
                  "brightness": {
                     "type": "integer",
                     "description": "The brightness level of the light.",
                     "format": "int32",
                     "nullable": true
                  },
                  "fadeDurationInMilliseconds": {
                     "type": "integer",
                     "description": "Duration for the light to fade to the new state, in milliseconds.",
                     "format": "int32",
                     "nullable": true
                  },
                  "scheduledTime": {
                     "type": "string",
                     "description": "Use ScheduledTime to synchronize lights. It's recommended that you asynchronously create tasks for each light that's scheduled to avoid blocking the main thread.",
                     "format": "date-time",
                     "nullable": true
                  }
               },
               "additionalProperties": false,
               "description": "Represents a request to change the state of the light."
         },
         "LightStateModel": {
               "type": "object",
               "properties": {
                  "id": {
                     "type": "string",
                     "nullable": true
                  },
                  "name": {
                     "type": "string",
                     "nullable": true
                  },
                  "on": {
                     "type": "boolean",
                     "nullable": true
                  },
                  "brightness": {
                     "type": "integer",
                     "format": "int32",
                     "nullable": true
                  },
                  "hexColor": {
                     "type": "string",
                     "nullable": true
                  }
               },
               "additionalProperties": false
         }
      }
   }
}
```

This specification provides everything needed by the AI to understand the API and how to interact with it. The API includes two endpoints: one to get all lights and another to change the state of a light. It also provides the following:

- Semantic descriptions for the endpoints and their parameters
- The types of the parameters
- The expected responses

Since the AI agent can understand this specification, you can add it as a plugin to the agent.

 Tip

If you have existing OpenAPI specifications, you may need to make alterations to make them easier for an AI to understand them. For example, you may need to provide guidance in the descriptions. For more tips on how to make your OpenAPI specifications AI-friendly, see [Tips and tricks for adding OpenAPI plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#tips-and-tricks-for-adding-openapi-plugins).

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#adding-the-openapi-plugin)

## Adding the OpenAPI plugin

With a few lines of code, you can add the OpenAPI plugin to your agent. The following code snippet shows how to add the light plugin from the OpenAPI specification above:

C#Copy

```
await kernel.ImportPluginFromOpenApiAsync(
   pluginName: "lights",
   uri: new Uri("https://example.com/v1/swagger.json"),
   executionParameters: new OpenApiFunctionExecutionParameters()
   {
      // Determines whether payload parameter names are augmented with namespaces.
      // Namespaces prevent naming conflicts by adding the parent parameter name
      // as a prefix, separated by dots
      EnablePayloadNamespacing = true
   }
);
```

Afterwards, you can use the plugin in your agent as if it were a native plugin.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#tips-and-tricks-for-adding-openapi-plugins)

## Tips and tricks for adding OpenAPI plugins

Since OpenAPI specifications are typically designed for humans, you may need to make some alterations to make them easier for an AI to understand. Here are some tips and tricks to help you do that:

Expand table

|Recommendation|Description|
|---|---|
|**Version control your API specifications**|Instead of pointing to a live API specification, consider checking-in and versioning your Swagger file. This will allow your AI researchers to test (and alter) the API specification used by the AI agent without affecting the live API and vice versa.|
|**Limit the number of endpoints**|Try to limit the number of endpoints in your API. Consolidate similar functionalities into single endpoints with optional parameters to reduce complexity.|
|**Use descriptive names for endpoints and parameters**|Ensure that the names of your endpoints and parameters are descriptive and self-explanatory. This helps the AI understand their purpose without needing extensive explanations.|
|**Use consistent naming conventions**|Maintain consistent naming conventions throughout your API. This reduces confusion and helps the AI learn and predict the structure of your API more easily.|
|**Simplify your API specifications**|Often, OpenAPI specifications are very detailed and include a lot of information that isn't necessary for the AI agent to help a user. The simpler the API, the fewer tokens you need to spend to describe it, and the fewer tokens the AI needs to send requests to it.|
|**Avoid string parameters**|When possible, avoid using string parameters in your API. Instead, use more specific types like integers, booleans, or enums. This will help the AI understand the API better.|
|**Provide examples in descriptions**|When humans use Swagger files, they typically are able to test the API using the Swagger UI, which includes sample requests and responses. Since the AI agent can't do this, consider providing examples in the descriptions of the parameters.|
|**Reference other endpoints in descriptions**|Often, AIs will confuse similar endpoints. To help the AI differentiate between endpoints, consider referencing other endpoints in the descriptions. For example, you could say "This endpoint is similar to the `get_all_lights` endpoint, but it only returns a single light."|
|**Provide helpful error messages**|While not within the OpenAPI specification, consider providing error messages that help the AI self-correct. For example, if a user provides an invalid ID, consider providing an error message that suggests the AI agent get the correct ID from the `get_all_lights` endpoint.|

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#next-steps)

## Next steps

Now that you know how to create a plugin, you can now learn how to use them with your AI agent. Depending on the type of functions you've added to your plugins, there are different patterns you should follow. For retrieval functions, refer to the [using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag) article. For task automation functions, refer to the [using task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions) article.

[Learn about using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag)

1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-logic-apps-as-plugins%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-logic-apps-as-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Give%20agents%20access%20to%20Logic%20Apps%20via%20plugins%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-logic-apps-as-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Give%20agents%20access%20to%20Logic%20Apps%20via%20plugins%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-logic-apps-as-plugins%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Give%20agents%20access%20to%20Logic%20Apps%20via%20plugins%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Give%20agents%20access%20to%20Logic%20Apps%20via%20plugins%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-logic-apps-as-plugins%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Add Logic Apps as plugins

- Article
- 06/24/2024
- 1 contributor

Feedback

## In this article

1. [Importing Logic Apps as plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#importing-logic-apps-as-plugins)
2. [Setting up Logic Apps for Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#setting-up-logic-apps-for-semantic-kernel)
3. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#next-steps)

Often in an enterprise, you already have a set of workflows that perform real work in Logic Apps. These could be used by other automation services or power front-end applications that humans interact with. In Semantic Kernel, you can add these exact same workflows as plugins so your agents can also use them.

Take for example the Logic Apps workflows used by the Semantic Kernel team to answer questions about new PRs. With the following workflows, an agent has everything it needs to retrieve code changes, search for related files, and check failure logs.

![Logic Apps](https://learn.microsoft.com/en-us/semantic-kernel/media/logic-apps-workflows.png)

- **Search files** – to find code snippets that are relevant to a given problem
- **Get file** – to retrieve the contents of a file in the GitHub repository
- **Get PR details** – to retrieve the details of a PR (e.g., the PR title, description, and author)
- **Get PR files** – to retrieve the files that were changed in a PR
- **Get build and test failures** – to retrieve the build and test failures for a given GitHub action run
- **Get log file** – to retrieve the log file for a given GitHub action run

Leveraging Logic Apps for Semantic Kernel plugins is also a great way to take advantage of the over [1,400 connectors available in Logic Apps](https://learn.microsoft.com/en-us/connectors/connector-reference/connector-reference-logicapps-connectors). This means you can easily connect to a wide variety of services and systems without writing any code.

 Important

Today, you can only add standard Logic Apps (also known as single-tenant Logic Apps) as plugins. Consumption Logic Apps are coming soon.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#importing-logic-apps-as-plugins)

## Importing Logic Apps as plugins

To add Logic Apps workflows to Semantic Kernel, you'll use the same methods as loading in an [OpenAPI specifications](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins). Below is some sample code.

C#Copy

```
await kernel.ImportPluginFromOpenApiAsync(
    pluginName: "openapi_plugin",
    uri: new Uri("https://example.azurewebsites.net/swagger.json"),
    executionParameters: new OpenApiFunctionExecutionParameters()
    {
        // Determines whether payload parameter names are augmented with namespaces.
        // Namespaces prevent naming conflicts by adding the parent parameter name
        // as a prefix, separated by dots
        EnablePayloadNamespacing = true
    }
);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#setting-up-logic-apps-for-semantic-kernel)

## Setting up Logic Apps for Semantic Kernel

Before you can import a Logic App as a plugin, you must first set up the Logic App to be accessible by Semantic Kernel. This involves enabling metadata endpoints and configuring your application for Easy Auth before finally importing the Logic App as a plugin with authentication.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#enable-metadata-endpoints)

### Enable metadata endpoints

For the easiest setup, you can enable unauthenticated access to the metadata endpoints for your Logic App. This will allow you to import your Logic App as a plugin into Semantic Kernel without needing to create a custom HTTP client to handle authentication for the initial import.

The below host.json file will create two unauthenticated endpoints. You can do this in azure portal by [going to kudu console and editing the host.json file](https://learn.microsoft.com/en-us/azure/logic-apps/edit-app-settings-host-settings?tabs=azure-portal#manage-host-settings---hostjson) located at _C:\home\site\wwwroot\host.json_.

JSONCopy

```
{ 
  "version": "2.0", 
  "extensionBundle": { 
    "id": "Microsoft.Azure.Functions.ExtensionBundle.Workflows", 
    "version": "[1.*, 2.0.0)" 
  }, 
  "extensions": { 
    "http": { 
      "routePrefix": "" 
    }, 
    "workflow": { 
      "MetadataEndpoints": { 
        "plugin": { 
          "enable": true, 
          "Authentication":{ 
              "Type":"Anonymous" 
          } 
        }, 
        "openapi": { 
          "enable": true, 
          "Authentication":{ 
              "Type":"Anonymous" 
          } 
        } 
      }, 
      "Settings": { 
        "Runtime.Triggers.RequestTriggerDefaultApiVersion": "2020-05-01-preview" 
      } 
    } 
  } 
} 
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#configure-your-application-for-easy-auth)

### Configure your application for Easy Auth

You now want to secure your Logic App workflows so only authorized users can access them. You can do this by enabling Easy Auth on your Logic App. This will allow you to use the same authentication mechanism as your other Azure services, making it easier to manage your security policies.

For an in-depth walkthrough on setting up Easy Auth, refer to this tutorial titled [Trigger workflows in Standard logic apps with Easy Auth](https://techcommunity.microsoft.com/t5/azure-integration-services-blog/trigger-workflows-in-standard-logic-apps-with-easy-auth/ba-p/3207378).

For those already familiar with Easy Auth (and already have an Entra client app you want to use), this is the configuration you’ll want to post to Azure management.

BashCopy

```
#!/bin/bash

# Variables
subscription_id="[SUBSCRIPTION_ID]"
resource_group="[RESOURCE_GROUP]"
app_name="[APP_NAME]"
api_version="2022-03-01"
arm_token="[ARM_TOKEN]"
tenant_id="[TENANT_ID]"
aad_client_id="[AAD_CLIENT_ID]"
object_ids=("[OBJECT_ID_FOR_USER1]" "[OBJECT_ID_FOR_USER2]" "[OBJECT_ID_FOR_APP1]")

# Convert the object_ids array to a JSON array
object_ids_json=$(printf '%s\n' "${object_ids[@]}" | jq -R . | jq -s .)

# Request URL
url="https://management.azure.com/subscriptions/$subscription_id/resourceGroups/$resource_group/providers/Microsoft.Web/sites/$app_name/config/authsettingsV2?api-version=$api_version"

# JSON payload
json_payload=$(cat <<EOF
{
    "properties": {
        "platform": {
            "enabled": true,
            "runtimeVersion": "~1"
        },
        "globalValidation": {
            "requireAuthentication": true,
            "unauthenticatedClientAction": "AllowAnonymous"
        },
        "identityProviders": {
            "azureActiveDirectory": {
                "enabled": true,
                "registration": {
                    "openIdIssuer": "https://sts.windows.net/$tenant_id/",
                    "clientId": "$aad_client_id"
                },
                "validation": {
                    "jwtClaimChecks": {},
                    "allowedAudiences": [
                        "api://$aad_client_id"
                    ],
                    "defaultAuthorizationPolicy": {
                        "allowedPrincipals": {
                            "identities": $object_ids_json
                        }
                    }
                }
            },
            "facebook": {
                "enabled": false,
                "registration": {},
                "login": {}
            },
            "gitHub": {
                "enabled": false,
                "registration": {},
                "login": {}
            },
            "google": {
                "enabled": false,
                "registration": {},
                "login": {},
                "validation": {}
            },
            "twitter": {
                "enabled": false,
                "registration": {}
            },
            "legacyMicrosoftAccount": {
                "enabled": false,
                "registration": {},
                "login": {},
                "validation": {}
            },
            "apple": {
                "enabled": false,
                "registration": {},
                "login": {}
            }
        }
    }
}
EOF
)

# HTTP PUT request
curl -X PUT "$url" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $arm_token" \
    -d "$json_payload"
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#use-logic-apps-with-semantic-kernel-as-a-plugin)

### Use Logic Apps with Semantic Kernel as a plugin

Now that you have your Logic App secured and the metadata endpoints enabled, you’ve finished all the hard parts. You can now import your Logic App as a plugin into Semantic Kernel using the OpenAPI import method.

When you create your plugin, you’ll want to provide a custom HTTP client that can handle the authentication for your Logic App. This will allow you to use the plugin in your AI agents without needing to worry about the authentication.

Below is an example in C# that leverages interactive auth to acquire a token and authenticate the user for the Logic App.

C#Copy

```
string ClientId = "[AAD_CLIENT_ID]";
string TenantId = "[TENANT_ID]";
string Authority = $"https://login.microsoftonline.com/{TenantId}";
string[] Scopes = new string[] { "api://[AAD_CIENT_ID]/SKLogicApp" };

var app = PublicClientApplicationBuilder.Create(ClientId)
            .WithAuthority(Authority)
            .WithDefaultRedirectUri() // Uses http://localhost for a console app
            .Build();

AuthenticationResult authResult = null;
try
{
    authResult = await app.AcquireTokenInteractive(Scopes).ExecuteAsync();
}
catch (MsalException ex)
{
    Console.WriteLine("An error occurred acquiring the token: " + ex.Message);
}

// Add the plugin to the kernel with a custom HTTP client for authentication
kernel.Plugins.Add(await kernel.ImportPluginFromOpenApiAsync(
    pluginName: "[NAME_OF_PLUGIN]",
    uri: new Uri("https://[LOGIC_APP_NAME].azurewebsites.net/swagger.json"),
    executionParameters: new OpenApiFunctionExecutionParameters()
    {
        HttpClient = new HttpClient()
        {
            DefaultRequestHeaders =
            {
                Authorization = new AuthenticationHeaderValue("Bearer", authResult.AccessToken)
            }
        },
    }
));
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#next-steps)

## Next steps

Now that you know how to create a plugin, you can now learn how to use them with your AI agent. Depending on the type of functions you've added to your plugins, there are different patterns you should follow. For retrieval functions, refer to the [using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag) article. For task automation functions, refer to the [using task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions) article.

[Learn about using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag)

1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-data-retrieval-functions-for-rag%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-data-retrieval-functions-for-rag%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Retrieve%20data%20from%20plugins%20for%20RAG%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-data-retrieval-functions-for-rag%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Retrieve%20data%20from%20plugins%20for%20RAG%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-data-retrieval-functions-for-rag%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Retrieve%20data%20from%20plugins%20for%20RAG%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Retrieve%20data%20from%20plugins%20for%20RAG%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-data-retrieval-functions-for-rag%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Using plugins for Retrieval Augmented Generation (RAG)

- Article
- 06/24/2024
- 1 contributor

Feedback

## In this article

1. [Semantic vs classic search](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#semantic-vs-classic-search)
2. [Dynamic vs pre-fetched data retrieval](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#dynamic-vs-pre-fetched-data-retrieval)
3. [Keeping data secure](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#keeping-data-secure)
4. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#next-steps)

Often, your AI agents must retrieve data from external sources to generate grounded responses. Without this additional context, your AI agents may hallucinate or provide incorrect information. To address this, you can use plugins to retrieve data from external sources.

When considering plugins for Retrieval Augmented Generation (RAG), you should ask yourself two questions:

1. How will you (or your AI agent) "search" for the required data? Do you need [semantic search](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#semantic-search) or [classic search](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#classic-search)?
2. Do you already know the data the AI agent needs ahead of time ([pre-fetched data](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#pre-fetched-data-retrieval)), or does the AI agent need to retrieve the data [dynamically](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#dynamic-data-retrieval)?
3. How will you keep your data secure and [prevent oversharing of sensitive information](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#keeping-data-secure)?

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#semantic-vs-classic-search)

## Semantic vs classic search

When developing plugins for Retrieval Augmented Generation (RAG), you can use two types of search: semantic search and classic search.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#semantic-search)

### Semantic Search

Semantic search utilizes vector databases to understand and retrieve information based on the meaning and context of the query rather than just matching keywords. This method allows the search engine to grasp the nuances of language, such as synonyms, related concepts, and the overall intent behind a query.

Semantic search excels in environments where user queries are complex, open-ended, or require a deeper understanding of the content. For example, searching for "best smartphones for photography" would yield results that consider the context of photography features in smartphones, rather than just matching the words "best," "smartphones," and "photography."

When providing an LLM with a semantic search function, you typically only need to define a function with a single search query. The LLM will then use this function to retrieve the necessary information. Below is an example of a semantic search function that uses Azure AI Search to find documents similar to a given query.

C#Copy

```
using System.ComponentModel;
using System.Text.Json.Serialization;
using Azure;
using Azure.Search.Documents;
using Azure.Search.Documents.Indexes;
using Azure.Search.Documents.Models;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.Embeddings;

public class InternalDocumentsPlugin
{
    private readonly ITextEmbeddingGenerationService _textEmbeddingGenerationService;
    private readonly SearchIndexClient _indexClient;

    public AzureAISearchPlugin(ITextEmbeddingGenerationService textEmbeddingGenerationService, SearchIndexClient indexClient)
    {
        _textEmbeddingGenerationService = textEmbeddingGenerationService;
        _indexClient = indexClient;
    }

    [KernelFunction("Search")]
    [Description("Search for a document similar to the given query.")]
    public async Task<string> SearchAsync(string query)
    {
        // Convert string query to vector
        ReadOnlyMemory<float> embedding = await _textEmbeddingGenerationService.GenerateEmbeddingAsync(query);

        // Get client for search operations
        SearchClient searchClient = _indexClient.GetSearchClient("default-collection");

        // Configure request parameters
        VectorizedQuery vectorQuery = new(embedding);
        vectorQuery.Fields.Add("vector");

        SearchOptions searchOptions = new() { VectorSearch = new() { Queries = { vectorQuery } } };

        // Perform search request
        Response<SearchResults<IndexSchema>> response = await searchClient.SearchAsync<IndexSchema>(searchOptions);

        // Collect search results
        await foreach (SearchResult<IndexSchema> result in response.Value.GetResultsAsync())
        {
            return result.Document.Chunk; // Return text from first result
        }

        return string.Empty;
    }

    private sealed class IndexSchema
    {
        [JsonPropertyName("chunk")]
        public string Chunk { get; set; }

        [JsonPropertyName("vector")]
        public ReadOnlyMemory<float> Vector { get; set; }
    }
}
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#classic-search)

### Classic Search

Classic search, also known as attribute-based or criteria-based search, relies on filtering and matching exact terms or values within a dataset. It is particularly effective for database queries, inventory searches, and any situation where filtering by specific attributes is necessary.

For example, if a user wants to find all orders placed by a particular customer ID or retrieve products within a specific price range and category, classic search provides precise and reliable results. Classic search, however, is limited by its inability to understand context or variations in language.

 Tip

In most cases, your existing services already support classic search. Before implementing a semantic search, consider whether your existing services can provide the necessary context for your AI agents.

Take for example, a plugin that retrieves customer information from a CRM system using classic search. Here, the AI simply needs to call the `GetCustomerInfoAsync` function with a customer ID to retrieve the necessary information.

C#Copy

```
using System.ComponentModel;
using Microsoft.SemanticKernel;

public class CRMPlugin
{
    private readonly CRMService _crmService;

    public CRMPlugin(CRMService crmService)
    {
        _crmService = crmService;
    }

    [KernelFunction("GetCustomerInfo")]
    [Description("Retrieve customer information based on the given customer ID.")]
    public async Task<Customer> GetCustomerInfoAsync(string customerId)
    {
        return await _crmService.GetCustomerInfoAsync(customerId);
    }
}
```

Achieving the same search functionality with semantic search would likely be impossible or impractical due to the non-deterministic nature of semantic queries.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#when-to-use-each)

### When to Use Each

Choosing between semantic and classic search depends on the nature of the query. It is ideal for content-heavy environments like knowledge bases and customer support where users might ask questions or look for products using natural language. Classic search, on the other hand, should be employed when precision and exact matches are important.

In some scenarios, you may need to combine both approaches to provide comprehensive search capabilities. For instance, a chatbot assisting customers in an e-commerce store might use semantic search to understand user queries and classic search to filter products based on specific attributes like price, brand, or availability.

Below is an example of a plugin that combines semantic and classic search to retrieve product information from an e-commerce database.

C#Copy

```
using System.ComponentModel;
using Microsoft.SemanticKernel;

public class ECommercePlugin
{
    [KernelFunction("search_products")]
    [Description("Search for products based on the given query.")]
    public async Task<IEnumerable<Product>> SearchProductsAsync(string query, ProductCategories category = null, decimal? minPrice = null, decimal? maxPrice = null)
    {
        // Perform semantic and classic search with the given parameters
    }
}
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#dynamic-vs-pre-fetched-data-retrieval)

## Dynamic vs pre-fetched data retrieval

When developing plugins for Retrieval Augmented Generation (RAG), you must also consider whether the data retrieval process is static or dynamic. This allows you to optimize the performance of your AI agents by retrieving data only when necessary.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#dynamic-data-retrieval)

### Dynamic data retrieval

In most cases, the user query will determine the data that the AI agent needs to retrieve. For example, a user might ask for the difference between two different products. The AI agent would then need to dynamically retrieve the product information from a database or API to generate a response using [function calling](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling). It would be impractical to pre-fetch all possible product information ahead of time and give it to the AI agent.

Below is an example of a back-and-forth chat between a user and an AI agent where dynamic data retrieval is necessary.

Expand table

|Role|Message|
|---|---|
|🔵 **User**|Can you tell me about the best mattresses?|
|🔴 **Assistant (function call)**|`Products.Search("mattresses")`|
|🟢 **Tool**|`[{"id": 25323, "name": "Cloud Nine"},{"id": 63633, "name": "Best Sleep"}]`|
|🔴 **Assistant**|Sure! We have both Cloud Nine and Best Sleep|
|🔵 **User**|What's the difference between them?|
|🔴 **Assistant (function call)**|`Products.GetDetails(25323)` `Products.GetDetails(63633)`|
|🟢 **Tool**|`{ "id": 25323, "name": "Cloud Nine", "price": 1000, "material": "Memory foam" }`|
|🟢 **Tool**|`{ "id": 63633, "name": "Best Sleep", "price": 1200, "material": "Latex" }`|
|🔴 **Assistant**|Cloud Nine is made of memory foam and costs $1000. Best Sleep is made of latex and costs $1200.|

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#pre-fetched-data-retrieval)

### Pre-fetched data Retrieval

Static data retrieval involves fetching data from external sources and _always_ providing it to the AI agent. This is useful when the data is required for every request or when the data is relatively stable and doesn't change frequently.

Take for example, an agent that always answers questions about the local weather. Assuming you have a `WeatherPlugin`, you can pre-fetch weather data from a weather API and provide it in the chat history. This allows the agent to generate responses about the weather without wasting time requesting the data from the API.

C#Copy

```
using System.Text.Json;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;

IKernelBuilder builder = Kernel.CreateBuilder();
builder.AddAzureOpenAIChatCompletion(deploymentName, endpoint, apiKey);
builder.Plugins.AddFromType<WeatherPlugin>();
Kernel kernel = builder.Build();

// Get the weather
var weather = await kernel.Plugins.GetFunction("WeatherPlugin", "get_weather").InvokeAsync(kernel);

// Initialize the chat history with the weather
ChatHistory chatHistory = new ChatHistory("The weather is:\n" + JsonSerializer.Serialize(weather));

// Simulate a user message
chatHistory.AddUserMessage("What is the weather like today?");

// Get the answer from the AI agent
IChatCompletionService chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();
var result = await chatCompletionService.GetChatMessageContentAsync(chatHistory);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#keeping-data-secure)

## Keeping data secure

When retrieving data from external sources, it is important to ensure that the data is secure and that sensitive information is not exposed. To prevent oversharing of sensitive information, you can use the following strategies:

Expand table

|Strategy|Description|
|---|---|
|**Use the user's auth token**|Avoid creating service principals used by the AI agent to retrieve information for users. Doing so makes it difficult to verify that a user has access to the retrieved information.|
|**Avoid recreating search services**|Before creating a new search service with a vector DB, check if one already exists for the service that has the required data. By reusing existing services, you can avoid duplicating sensitive content, leverage existing access controls, and use existing filtering mechanisms that only return data the user has access to.|
|**Store reference in vector DBs instead of content**|Instead of duplicating sensitive content to vector DBs, you can store references to the actual data. For a user to access this information, their auth token must first be used to retrieve the real data.|

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#next-steps)

## Next steps

Now that you now how to ground your AI agents with data from external sources, you can now learn how to use AI agents to automate business processes. To learn more, see [using task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions).

[Learn about task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions)
1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-task-automation-functions%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-task-automation-functions%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Allow%20agents%20to%20automate%20tasks%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-task-automation-functions%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Allow%20agents%20to%20automate%20tasks%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-task-automation-functions%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Allow%20agents%20to%20automate%20tasks%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Allow%20agents%20to%20automate%20tasks%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-task-automation-functions%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Task automation with agents

- Article
- 09/09/2024
- 2 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [Requiring user consent](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions?pivots=programming-language-csharp#requiring-user-consent)
2. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions?pivots=programming-language-csharp#next-steps)

Most AI agents today simply retrieve data and respond to user queries. AI agents, however, can achieve much more by using plugins to automate tasks on behalf of users. This allows users to delegate tasks to AI agents, freeing up time for more important work.

Once AI Agents start performing actions, however, it's important to ensure that they are acting in the best interest of the user. This is why we provide hooks / filters to allow you to control what actions the AI agent can take.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions?pivots=programming-language-csharp#requiring-user-consent)

## Requiring user consent

When an AI agent is about to perform an action on behalf of a user, it should first ask for the user's consent. This is especially important when the action involves sensitive data or financial transactions.

In Semantic Kernel, you can use the function invocation filter. This filter is always called whenever a function is invoked from an AI agent. To create a filter, you need to implement the `IFunctionInvocationFilter` interface and then add it as a service to the kernel.

Here's an example of a function invocation filter that requires user consent:

C#Copy

```
public class ApprovalFilterExample() : IFunctionInvocationFilter
{
    public async Task OnFunctionInvocationAsync(FunctionInvocationContext context, Func<FunctionInvocationContext, Task> next)
    {
        if (context.Function.PluginName == "DynamicsPlugin" && context.Function.Name == "create_order")
        {
            Console.WriteLine("System > The agent wants to create an approval, do you want to proceed? (Y/N)");
            string shouldProceed = Console.ReadLine()!;

            if (shouldProceed != "Y")
            {
                context.Result = new FunctionResult(context.Result, "The order creation was not approved by the user");
                return;
            }

            await next(context);
        }
    }
}
```

You can then add the filter as a service to the kernel:

C#Copy

```
IKernelBuilder builder = Kernel.CreateBuilder();
builder.Services.AddSingleton<IFunctionInvocationFilter, ApprovalFilterExample>();
Kernel kernel = builder.Build();
```

Now, whenever the AI agent tries to create an order using the `DynamicsPlugin`, the user will be prompted to approve the action.

 Tip

Whenever a function is cancelled or fails, you should provide the AI agent with a meaningful error message so it can respond appropriately. For example, if we didn't let the AI agent know that the order creation was not approved, it would assume that the order failed due to a technical issue and would try to create the order again.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions?pivots=programming-language-csharp#next-steps)

## Next steps

Now that you've learned how to allow agents to automate tasks, you can learn how to allow agents to automatically create plans to address user needs.
3 Semantic Kernel Plugins.md
77.79 KB • 1451 extracted lines
Formatting may be inconsistent from source.
# What is a Plugin?

- Article
- 06/24/2024
- 3 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [Anatomy of a plugin](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#anatomy-of-a-plugin)
2. [Getting started with plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#getting-started-with-plugins)

Plugins are a key component of Semantic Kernel. If you have already used plugins from ChatGPT or Copilot extensions in Microsoft 365, you’re already familiar with them. With plugins, you can encapsulate your existing APIs into a collection that can be used by an AI. This allows you to give your AI the ability to perform actions that it wouldn’t be able to do otherwise.

Behind the scenes, Semantic Kernel leverages [function calling](https://platform.openai.com/docs/guides/function-calling), a native feature of most of the latest LLMs to allow LLMs, to perform [planning](https://learn.microsoft.com/en-us/semantic-kernel/concepts/planning) and to invoke your APIs. With function calling, LLMs can request (i.e., call) a particular function. Semantic Kernel then marshals the request to the appropriate function in your codebase and returns the results back to the LLM so the LLM can generate a final response.

![Semantic Kernel Plugin](https://learn.microsoft.com/en-us/semantic-kernel/media/designed-for-modular-extensibility-vertical.png)

Not all AI SDKs have an analogous concept to plugins (most just have functions or tools). In enterprise scenarios, however, plugins are valuable because they encapsulate a set of functionality that mirrors how enterprise developers already develop services and APIs. Plugins also play nicely with dependency injection. Within a plugin's constructor, you can inject services that are necessary to perform the work of the plugin (e.g., database connections, HTTP clients, etc.). This is difficult to accomplish with other SDKs that lack plugins.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#anatomy-of-a-plugin)

## Anatomy of a plugin

At a high-level, a plugin is a group of [functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#importing-different-types-of-plugins) that can be exposed to AI apps and services. The functions within plugins can then be orchestrated by an AI application to accomplish user requests. Within Semantic Kernel, you can invoke these functions automatically with function calling.

 Note

In other platforms, functions are often referred to as "tools" or "actions". In Semantic Kernel, we use the term "functions" since they are typically defined as native functions in your codebase.

Just providing functions, however, is not enough to make a plugin. To power automatic orchestration with function calling, plugins also need to provide details that semantically describe how they behave. Everything from the function's input, output, and side effects need to be described in a way that the AI can understand, otherwise, the AI will not correctly call the function.

For example, the sample `WriterPlugin` plugin on the right has functions with semantic descriptions that describe what each function does. An LLM can then use these descriptions to choose the best functions to call to fulfill a user's ask.

In the picture on the right, an LLM would likely call the `ShortPoem` and `StoryGen` functions to satisfy the users ask thanks to the provided semantic descriptions.

![Semantic description within the WriterPlugin plugin](https://learn.microsoft.com/en-us/semantic-kernel/media/writer-plugin-example.png)

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#importing-different-types-of-plugins)

### Importing different types of plugins

There are two primary ways of importing plugins into Semantic Kernel: using [native code](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins) or using an [OpenAPI specification](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins). The former allows you to author plugins in your existing codebase that can leverage dependencies and services you already have. The latter allows you to import plugins from an OpenAPI specification, which can be shared across different programming languages and platforms.

Below we provide a simple example of importing and using a native plugin. To learn more about how to import these different types of plugins, refer to the following articles:

- [Importing native code](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins)
- [Importing an OpenAPI specification](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins)

 Tip

When getting started, we recommend using native code plugins. As your application matures, and as you work across cross-platform teams, you may want to consider using OpenAPI specifications to share plugins across different programming languages and platforms.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#the-different-types-of-plugin-functions)

### The different types of plugin functions

Within a plugin, you will typically have two different types of functions, those that retrieve data for retrieval augmented generation (RAG) and those that automate tasks. While each type is functionally the same, they are typically used differently within applications that use Semantic Kernel.

For example, with retrieval functions, you may want to use strategies to improve performance (e.g., caching and using cheaper intermediate models for summarization). Whereas with task automation functions, you'll likely want to implement human-in-the-loop approval processes to ensure that tasks are completed correctly.

To learn more about the different types of plugin functions, refer to the following articles:

- [Data retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag)
- [Task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions)

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#getting-started-with-plugins)

## Getting started with plugins

Using plugins within Semantic Kernel is always a three step process:

1. [Define your plugin](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#1-define-your-plugin)
2. [Add the plugin to your kernel](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#2-add-the-plugin-to-your-kernel)
3. [And then either invoke the plugin's functions in either a prompt with function calling](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#3-invoke-the-plugins-functions)

Below we'll provide a high-level example of how to use a plugin within Semantic Kernel. Refer to the links above for more detailed information on how to create and use plugins.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#1-define-your-plugin)

### 1) Define your plugin

The easiest way to create a plugin is by defining a class and annotating its methods with the `KernelFunction` attribute. This let's Semantic Kernel know that this is a function that can be called by an AI or referenced in a prompt.

You can also import plugins from an [OpenAPI specification](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins).

Below, we'll create a plugin that can retrieve the state of lights and alter its state.

 Tip

Since most LLM have been trained with Python for function calling, its recommended to use snake case for function names and property names even if you're using the C# or Java SDK.

C#Copy

```
using System.ComponentModel;
using Microsoft.SemanticKernel;

public class LightsPlugin
{
   // Mock data for the lights
   private readonly List<LightModel> lights = new()
   {
      new LightModel { Id = 1, Name = "Table Lamp", IsOn = false, Brightness = 100, Hex = "FF0000" },
      new LightModel { Id = 2, Name = "Porch light", IsOn = false, Brightness = 50, Hex = "00FF00" },
      new LightModel { Id = 3, Name = "Chandelier", IsOn = true, Brightness = 75, Hex = "0000FF" }
   };

   [KernelFunction("get_lights")]
   [Description("Gets a list of lights and their current state")]
   [return: Description("An array of lights")]
   public async Task<List<LightModel>> GetLightsAsync()
   {
      return lights
   }

   [KernelFunction("get_state")]
   [Description("Gets the state of a particular light")]
   [return: Description("The state of the light")]
   public async Task<LightModel?> GetStateAsync([Description("The ID of the light")] int id)
   {
      // Get the state of the light with the specified ID
      return lights.FirstOrDefault(light => light.Id == id);
   }

   [KernelFunction("change_state")]
   [Description("Changes the state of the light")]
   [return: Description("The updated state of the light; will return null if the light does not exist")]
   public async Task<LightModel?> ChangeStateAsync(int id, LightModel LightModel)
   {
      var light = lights.FirstOrDefault(light => light.Id == id);

      if (light == null)
      {
         return null;
      }

      // Update the light with the new state
      light.IsOn = LightModel.IsOn;
      light.Brightness = LightModel.Brightness;
      light.Hex = LightModel.Hex;

      return light;
   }
}

public class LightModel
{
   [JsonPropertyName("id")]
   public int Id { get; set; }

   [JsonPropertyName("name")]
   public string Name { get; set; }

   [JsonPropertyName("is_on")]
   public bool? IsOn { get; set; }

   [JsonPropertyName("brightness")]
   public byte? Brightness { get; set; }

   [JsonPropertyName("hex")]
   public string? Hex { get; set; }
}
```

Notice that we provide descriptions for the function, return value, and parameters. This is important for the AI to understand what the function does and how to use it.

 Tip

Don't be afraid to provide detailed descriptions for your functions if an AI is having trouble calling them. Few-shot examples, recommendations for when to use (and not use) the function, and guidance on where to get required parameters can all be helpful.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#2-add-the-plugin-to-your-kernel)

### 2) Add the plugin to your kernel

Once you've defined your plugin, you can add it to your kernel by creating a new instance of the plugin and adding it to the kernel's plugin collection.

This example demonstrates the easiest way of adding a class as a plugin with the `AddFromType` method. To learn about other ways of adding plugins, refer to the [adding native plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins) article.

C#Copy

```
var builder = new KernelBuilder();
builder.Plugins.AddFromType<LightsPlugin>("Lights")
Kernel kernel = builder.Build();
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp#3-invoke-the-plugins-functions)

### 3) Invoke the plugin's functions

Finally, you can have the AI invoke your plugin's functions by using function calling. Below is an example that demonstrates how to coax the AI to call the `get_lights` function from the `Lights` plugin before calling the `change_state` function to turn on a light.

C#Copy

```
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using Microsoft.SemanticKernel.Connectors.OpenAI;

// Create a kernel with Azure OpenAI chat completion
var builder = Kernel.CreateBuilder().AddAzureOpenAIChatCompletion(modelId, endpoint, apiKey);

// Build the kernel
Kernel kernel = builder.Build();
var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();

// Add a plugin (the LightsPlugin class is defined below)
kernel.Plugins.AddFromType<LightsPlugin>("Lights");

// Enable planning
OpenAIPromptExecutionSettings openAIPromptExecutionSettings = new() 
{
    ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions
};

// Create a history store the conversation
var history = new ChatHistory();
history.AddUserMessage("Please turn on the lamp");

// Get the response from the AI
var result = await chatCompletionService.GetChatMessageContentAsync(
   history,
   executionSettings: openAIPromptExecutionSettings,
   kernel: kernel);

// Print the results
Console.WriteLine("Assistant > " + result);

// Add the message from the agent to the chat history
history.AddAssistantMessage(result);
```

With the above code, you should get a response that looks like the following:

Expand table

|Role|Message|
|---|---|
|🔵 **User**|Please turn on the lamp|
|🔴 **Assistant (function call)**|`Lights.get_lights()`|
|🟢 **Tool**|`[{ "id": 1, "name": "Table Lamp", "isOn": false, "brightness": 100, "hex": "FF0000" }, { "id": 2, "name": "Porch light", "isOn": false, "brightness": 50, "hex": "00FF00" }, { "id": 3, "name": "Chandelier", "isOn": true, "brightness": 75, "hex": "0000FF" }]`|
|🔴 **Assistant (function call)**|Lights.change_state(1, { "isOn": true })|
|🟢 **Tool**|`{ "id": 1, "name": "Table Lamp", "isOn": true, "brightness": 100, "hex": "FF0000" }`|
|🔴 **Assistant**|The lamp is now on|

 Tip

While you can invoke a plugin function directly, this is not advised because the AI should be the one deciding which functions to call. If you need explicit control over which functions are called, consider using standard methods in your codebase instead of plugins.

1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-native-plugins%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-native-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Provide%20native%20code%20to%20your%20agents%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-native-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Provide%20native%20code%20to%20your%20agents%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-native-plugins%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Provide%20native%20code%20to%20your%20agents%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Provide%20native%20code%20to%20your%20agents%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-native-plugins%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Add native code as a plugin

- Article
- 06/24/2024
- 3 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [Providing the LLM with the right information](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#providing-the-llm-with-the-right-information)
2. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#next-steps)

The easiest way to provide an AI agent with capabilities that are not natively supported is to wrap native code into a plugin. This allows you to leverage your existing skills as an app developer to extend the capabilities of your AI agents.

Behind the scenes, Semantic Kernel will then use the descriptions you provide, along with reflection, to semantically describe the plugin to the AI agent. This allows the AI agent to understand the capabilities of the plugin and how to interact with it.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#providing-the-llm-with-the-right-information)

## Providing the LLM with the right information

When authoring a plugin, you need to provide the AI agent with the right information to understand the capabilities of the plugin and its functions. This includes:

- The name of the plugin
- The names of the functions
- The descriptions of the functions
- The parameters of the functions
- The schema of the parameters

The value of Semantic Kernel is that it can automatically generate most of this information from the code itself. As a developer, this just means that you must provide the semantic descriptions of the functions and parameters so the AI agent can understand them. If you properly comment and annotate your code, however, you likely already have this information on hand.

Below, we'll walk through the two different ways of providing your AI agent with native code and how to provide this semantic information.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#defining-a-plugin-using-a-class)

### Defining a plugin using a class

The easiest way to create a native plugin is to start with a class and then add methods annotated with the `KernelFunction` attribute. It is also recommended to liberally use the `Description` annotation to provide the AI agent with the necessary information to understand the function.

C#Copy

```
public class LightsPlugin
{
   private readonly List<LightModel> _lights;

   public LightsPlugin(LoggerFactory loggerFactory, List<LightModel> lights)
   {
      _lights = lights;
   }

   [KernelFunction("get_lights")]
   [Description("Gets a list of lights and their current state")]
   [return: Description("An array of lights")]
   public async Task<List<LightModel>> GetLightsAsync()
   {
      return _lights;
   }

   [KernelFunction("change_state")]
   [Description("Changes the state of the light")]
   [return: Description("The updated state of the light; will return null if the light does not exist")]
   public async Task<LightModel?> ChangeStateAsync(LightModel changeState)
   {
      // Find the light to change
      var light = _lights.FirstOrDefault(l => l.Id == changeState.Id);

      // If the light does not exist, return null
      if (light == null)
      {
         return null;
      }

      // Update the light state
      light.IsOn = changeState.IsOn;
      light.Brightness = changeState.Brightness;
      light.Color = changeState.Color;

      return light;
   }
}
```

 Tip

Because the LLMs are predominantly trained on Python code, it is recommended to use snake_case for function names and parameters (even if you're using C# or Java). This will help the AI agent better understand the function and its parameters.

If your function has a complex object as an input variable, Semantic Kernel will also generate a schema for that object and pass it to the AI agent. Similar to functions, you should provide `Description` annotations for properties that are non-obvious to the AI. Below is the definition for the `LightState` class and the `Brightness` enum.

C#Copy

```
using System.Text.Json.Serialization;

public class LightModel
{
   [JsonPropertyName("id")]
   public int Id { get; set; }

   [JsonPropertyName("name")]
   public string? Name { get; set; }

   [JsonPropertyName("is_on")]
   public bool? IsOn { get; set; }

   [JsonPropertyName("brightness")]
   public enum? Brightness { get; set; }

   [JsonPropertyName("color")]
   [Description("The color of the light with a hex code (ensure you include the # symbol)")]
   public string? Color { get; set; }
}

[JsonConverter(typeof(JsonStringEnumConverter))]
public enum Brightness
{
   Low,
   Medium,
   High
}
```

 Note

While this is a "fun" example, it does a good job showing just how complex a plugin's parameters can be. In this single case, we have a complex object with _four_ different types of properties: an integer, string, boolean, and enum. Semantic Kernel's value is that it can automatically generate the schema for this object and pass it to the AI agent and marshal the parameters generated by the AI agent into the correct object.

Once you're done authoring your plugin class, you can add it to the kernel using the `AddFromType<>` or `AddFromObject` methods.

 Tip

When creating a function, always ask yourself "how can I give the AI additional help to use this function?" This can include using specific input types (avoid strings where possible), providing descriptions, and examples.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#adding-a-plugin-using-the-addfromobject-method)

#### Adding a plugin using the `AddFromObject` method

The `AddFromObject` method allows you to add an instance of the plugin class directly to the plugin collection in case you want to directly control how the plugin is constructed.

For example, the constructor of the `LightsPlugin` class requires the list of lights. In this case, you can create an instance of the plugin class and add it to the plugin collection.

C#Copy

```
List<LightModel> lights = new()
   {
      new LightModel { Id = 1, Name = "Table Lamp", IsOn = false, Brightness = Brightness.Medium, Color = "#FFFFFF" },
      new LightModel { Id = 2, Name = "Porch light", IsOn = false, Brightness = Brightness.High, Color = "#FF0000" },
      new LightModel { Id = 3, Name = "Chandelier", IsOn = true, Brightness = Brightness.Low, Color = "#FFFF00" }
   };

kernel.Plugins.AddFromObject(new LightsPlugin(lights));
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#adding-a-plugin-using-the-addfromtype-method)

#### Adding a plugin using the `AddFromType<>` method

When using the `AddFromType<>` method, the kernel will automatically use dependency injection to create an instance of the plugin class and add it to the plugin collection.

This is helpful if your constructor requires services or other dependencies to be injected into the plugin. For example, our `LightsPlugin` class may require a logger and a light service to be injected into it instead of a list of lights.

C#Copy

```
public class LightsPlugin
{
   private readonly Logger _logger;
   private readonly LightService _lightService;

   public LightsPlugin(LoggerFactory loggerFactory, LightService lightService)
   {
      _logger = loggerFactory.CreateLogger<LightsPlugin>();
      _lightService = lightService;
   }

   [KernelFunction("get_lights")]
   [Description("Gets a list of lights and their current state")]
   [return: Description("An array of lights")]
   public async Task<List<LightModel>> GetLightsAsync()
   {
      _logger.LogInformation("Getting lights");
      return lightService.GetLights();
   }

   [KernelFunction("change_state")]
   [Description("Changes the state of the light")]
   [return: Description("The updated state of the light; will return null if the light does not exist")]
   public async Task<LightModel?> ChangeStateAsync(LightModel changeState)
   {
      _logger.LogInformation("Changing light state");
      return lightService.ChangeState(changeState);
   }
}
```

With Dependency Injection, you can add the required services and plugins to the kernel builder before building the kernel.

C#Copy

```
var builder = Kernel.CreateBuilder();

// Add dependencies for the plugin
builder.Services.AddLogging(loggingBuilder => loggingBuilder.AddConsole().SetMinimumLevel(LogLevel.Trace));
builder.Services.AddSingleton<LightService>();

// Add the plugin to the kernel
builder.Plugins.AddFromType<LightsPlugin>("Lights");

// Build the kernel
Kernel kernel = builder.Build();
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#defining-a-plugin-using-a-collection-of-functions)

### Defining a plugin using a collection of functions

Less common but still useful is defining a plugin using a collection of functions. This is particularly useful if you need to dynamically create a plugin from a set of functions at runtime.

Using this process requires you to use the function factory to create individual functions before adding them to the plugin.

C#Copy

```
kernel.Plugins.AddFromFunctions("time_plugin",
[
    KernelFunctionFactory.CreateFromMethod(
        method: () => DateTime.Now,
        functionName: "get_time",
        description: "Get the current time"
    ),
    KernelFunctionFactory.CreateFromMethod(
        method: (DateTime start, DateTime end) => (end - start).TotalSeconds,
        functionName: "diff_time",
        description: "Get the difference between two times in seconds"
    )
]);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#additional-strategies-for-adding-native-code-with-dependency-injection)

### Additional strategies for adding native code with Dependency Injection

If you're working with Dependency Injection, there are additional strategies you can take to create and add plugins to the kernel. Below are some examples of how you can add a plugin using Dependency Injection.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#inject-a-plugin-collection)

#### Inject a plugin collection

 Tip

We recommend making your plugin collection a transient service so that it is disposed of after each use since the plugin collection is mutable. Creating a new plugin collection for each use is cheap, so it should not be a performance concern.

C#Copy

```
var builder = Host.CreateApplicationBuilder(args);

// Create native plugin collection
builder.Services.AddTransient((serviceProvider)=>{
   KernelPluginCollection pluginCollection = [];
   pluginCollection.AddFromType<LightsPlugin>("Lights");

   return pluginCollection;
});

// Create the kernel service
builder.Services.AddTransient<Kernel>((serviceProvider)=> {
   KernelPluginCollection pluginCollection = serviceProvider.GetRequiredService<KernelPluginCollection>();

   return new Kernel(serviceProvider, pluginCollection);
});
```

 Tip

As mentioned in the [kernel article](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel), the kernel is extremely lightweight, so creating a new kernel for each use as a transient is not a performance concern.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#generate-your-plugins-as-singletons)

#### Generate your plugins as singletons

Plugins are not mutable, so its typically safe to create them as singletons. This can be done by using the plugin factory and adding the resulting plugin to your service collection.

C#Copy

```
var builder = Host.CreateApplicationBuilder(args);

// Create singletons of your plugin
builder.Services.AddKeyedSingleton("LightPlugin", (serviceProvider, key) => {
    return KernelPluginFactory.CreateFromType<LightsPlugin>();
});

// Create a kernel service with singleton plugin
builder.Services.AddTransient((serviceProvider)=> {
    KernelPluginCollection pluginCollection = [
      serviceProvider.GetRequiredKeyedService<KernelPlugin>("LightPlugin")
    ];

    return new Kernel(serviceProvider, pluginCollection);
});
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-native-plugins?pivots=programming-language-csharp#next-steps)

## Next steps

Now that you know how to create a plugin, you can now learn how to use them with your AI agent. Depending on the type of functions you've added to your plugins, there are different patterns you should follow. For retrieval functions, refer to the [using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag) article. For task automation functions, refer to the [using task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions) article.

[Learn about using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag)

1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-openapi-plugins%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-openapi-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Give%20agents%20access%20to%20OpenAPI%20APIs%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-openapi-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Give%20agents%20access%20to%20OpenAPI%20APIs%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-openapi-plugins%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Give%20agents%20access%20to%20OpenAPI%20APIs%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Give%20agents%20access%20to%20OpenAPI%20APIs%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-openapi-plugins%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Add plugins from OpenAPI specifications

- Article
- 06/24/2024
- 2 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [An example OpenAPI specification](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#an-example-openapi-specification)
2. [Adding the OpenAPI plugin](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#adding-the-openapi-plugin)
3. [Tips and tricks for adding OpenAPI plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#tips-and-tricks-for-adding-openapi-plugins)
4. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#next-steps)

Often in an enterprise, you already have a set of APIs that perform real work. These could be used by other automation services or power front-end applications that humans interact with. In Semantic Kernel, you can add these exact same APIs as plugins so your agents can also use them.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#an-example-openapi-specification)

## An example OpenAPI specification

Take for example an API that allows you to alter the state of light bulbs. The OpenAPI specification for this API might look like this:

JSONCopy

```
{
   "openapi": "3.0.1",
   "info": {
      "title": "Light API",
      "version": "v1"
   },
   "paths": {
      "/Light": {
         "get": {
            "tags": [
               "Light"
            ],
            "summary": "Retrieves all lights in the system.",
            "operationId": "get_all_lights",
            "responses": {
               "200": {
                  "description": "Returns a list of lights with their current state",
                  "application/json": {
                     "schema": {
                        "type": "array",
                        "items": {
                              "$ref": "#/components/schemas/LightStateModel"
                        }
                     }
                  }
               }
            }
         }
      },
      "/Light/{id}": {
         "post": {
               "tags": [
                  "Light"
               ],
               "summary": "Changes the state of a light.",
               "operationId": "change_light_state",
               "parameters": [
                  {
                     "name": "id",
                     "in": "path",
                     "description": "The ID of the light to change from the get_all_lights tool.",
                     "required": true,
                     "style": "simple",
                     "schema": {
                           "type": "string"
                     }
                  }
               ],
               "requestBody": {
                  "description": "The new state of the light and change parameters.",
                  "content": {
                     "application/json": {
                           "schema": {
                              "$ref": "#/components/schemas/ChangeStateRequest"
                           }
                     }
                  }
               },
               "responses": {
                  "200": {
                     "description": "Returns the updated light state",
                     "content": {
                           "application/json": {
                              "schema": {
                                 "$ref": "#/components/schemas/LightStateModel"
                              }
                           }
                     }
                  },
                  "404": {
                     "description": "If the light is not found"
                  }
               }
         }
      }
   },
   "components": {
      "schemas": {
         "ChangeStateRequest": {
               "type": "object",
               "properties": {
                  "isOn": {
                     "type": "boolean",
                     "description": "Specifies whether the light is turned on or off.",
                     "nullable": true
                  },
                  "hexColor": {
                     "type": "string",
                     "description": "The hex color code for the light.",
                     "nullable": true
                  },
                  "brightness": {
                     "type": "integer",
                     "description": "The brightness level of the light.",
                     "format": "int32",
                     "nullable": true
                  },
                  "fadeDurationInMilliseconds": {
                     "type": "integer",
                     "description": "Duration for the light to fade to the new state, in milliseconds.",
                     "format": "int32",
                     "nullable": true
                  },
                  "scheduledTime": {
                     "type": "string",
                     "description": "Use ScheduledTime to synchronize lights. It's recommended that you asynchronously create tasks for each light that's scheduled to avoid blocking the main thread.",
                     "format": "date-time",
                     "nullable": true
                  }
               },
               "additionalProperties": false,
               "description": "Represents a request to change the state of the light."
         },
         "LightStateModel": {
               "type": "object",
               "properties": {
                  "id": {
                     "type": "string",
                     "nullable": true
                  },
                  "name": {
                     "type": "string",
                     "nullable": true
                  },
                  "on": {
                     "type": "boolean",
                     "nullable": true
                  },
                  "brightness": {
                     "type": "integer",
                     "format": "int32",
                     "nullable": true
                  },
                  "hexColor": {
                     "type": "string",
                     "nullable": true
                  }
               },
               "additionalProperties": false
         }
      }
   }
}
```

This specification provides everything needed by the AI to understand the API and how to interact with it. The API includes two endpoints: one to get all lights and another to change the state of a light. It also provides the following:

- Semantic descriptions for the endpoints and their parameters
- The types of the parameters
- The expected responses

Since the AI agent can understand this specification, you can add it as a plugin to the agent.

 Tip

If you have existing OpenAPI specifications, you may need to make alterations to make them easier for an AI to understand them. For example, you may need to provide guidance in the descriptions. For more tips on how to make your OpenAPI specifications AI-friendly, see [Tips and tricks for adding OpenAPI plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#tips-and-tricks-for-adding-openapi-plugins).

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#adding-the-openapi-plugin)

## Adding the OpenAPI plugin

With a few lines of code, you can add the OpenAPI plugin to your agent. The following code snippet shows how to add the light plugin from the OpenAPI specification above:

C#Copy

```
await kernel.ImportPluginFromOpenApiAsync(
   pluginName: "lights",
   uri: new Uri("https://example.com/v1/swagger.json"),
   executionParameters: new OpenApiFunctionExecutionParameters()
   {
      // Determines whether payload parameter names are augmented with namespaces.
      // Namespaces prevent naming conflicts by adding the parent parameter name
      // as a prefix, separated by dots
      EnablePayloadNamespacing = true
   }
);
```

Afterwards, you can use the plugin in your agent as if it were a native plugin.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#tips-and-tricks-for-adding-openapi-plugins)

## Tips and tricks for adding OpenAPI plugins

Since OpenAPI specifications are typically designed for humans, you may need to make some alterations to make them easier for an AI to understand. Here are some tips and tricks to help you do that:

Expand table

|Recommendation|Description|
|---|---|
|**Version control your API specifications**|Instead of pointing to a live API specification, consider checking-in and versioning your Swagger file. This will allow your AI researchers to test (and alter) the API specification used by the AI agent without affecting the live API and vice versa.|
|**Limit the number of endpoints**|Try to limit the number of endpoints in your API. Consolidate similar functionalities into single endpoints with optional parameters to reduce complexity.|
|**Use descriptive names for endpoints and parameters**|Ensure that the names of your endpoints and parameters are descriptive and self-explanatory. This helps the AI understand their purpose without needing extensive explanations.|
|**Use consistent naming conventions**|Maintain consistent naming conventions throughout your API. This reduces confusion and helps the AI learn and predict the structure of your API more easily.|
|**Simplify your API specifications**|Often, OpenAPI specifications are very detailed and include a lot of information that isn't necessary for the AI agent to help a user. The simpler the API, the fewer tokens you need to spend to describe it, and the fewer tokens the AI needs to send requests to it.|
|**Avoid string parameters**|When possible, avoid using string parameters in your API. Instead, use more specific types like integers, booleans, or enums. This will help the AI understand the API better.|
|**Provide examples in descriptions**|When humans use Swagger files, they typically are able to test the API using the Swagger UI, which includes sample requests and responses. Since the AI agent can't do this, consider providing examples in the descriptions of the parameters.|
|**Reference other endpoints in descriptions**|Often, AIs will confuse similar endpoints. To help the AI differentiate between endpoints, consider referencing other endpoints in the descriptions. For example, you could say "This endpoint is similar to the `get_all_lights` endpoint, but it only returns a single light."|
|**Provide helpful error messages**|While not within the OpenAPI specification, consider providing error messages that help the AI self-correct. For example, if a user provides an invalid ID, consider providing an error message that suggests the AI agent get the correct ID from the `get_all_lights` endpoint.|

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-csharp#next-steps)

## Next steps

Now that you know how to create a plugin, you can now learn how to use them with your AI agent. Depending on the type of functions you've added to your plugins, there are different patterns you should follow. For retrieval functions, refer to the [using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag) article. For task automation functions, refer to the [using task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions) article.

[Learn about using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag)

1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-logic-apps-as-plugins%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-logic-apps-as-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Give%20agents%20access%20to%20Logic%20Apps%20via%20plugins%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-logic-apps-as-plugins%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Give%20agents%20access%20to%20Logic%20Apps%20via%20plugins%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-logic-apps-as-plugins%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Give%20agents%20access%20to%20Logic%20Apps%20via%20plugins%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Give%20agents%20access%20to%20Logic%20Apps%20via%20plugins%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fadding-logic-apps-as-plugins%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Add Logic Apps as plugins

- Article
- 06/24/2024
- 1 contributor

Feedback

## In this article

1. [Importing Logic Apps as plugins](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#importing-logic-apps-as-plugins)
2. [Setting up Logic Apps for Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#setting-up-logic-apps-for-semantic-kernel)
3. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#next-steps)

Often in an enterprise, you already have a set of workflows that perform real work in Logic Apps. These could be used by other automation services or power front-end applications that humans interact with. In Semantic Kernel, you can add these exact same workflows as plugins so your agents can also use them.

Take for example the Logic Apps workflows used by the Semantic Kernel team to answer questions about new PRs. With the following workflows, an agent has everything it needs to retrieve code changes, search for related files, and check failure logs.

![Logic Apps](https://learn.microsoft.com/en-us/semantic-kernel/media/logic-apps-workflows.png)

- **Search files** – to find code snippets that are relevant to a given problem
- **Get file** – to retrieve the contents of a file in the GitHub repository
- **Get PR details** – to retrieve the details of a PR (e.g., the PR title, description, and author)
- **Get PR files** – to retrieve the files that were changed in a PR
- **Get build and test failures** – to retrieve the build and test failures for a given GitHub action run
- **Get log file** – to retrieve the log file for a given GitHub action run

Leveraging Logic Apps for Semantic Kernel plugins is also a great way to take advantage of the over [1,400 connectors available in Logic Apps](https://learn.microsoft.com/en-us/connectors/connector-reference/connector-reference-logicapps-connectors). This means you can easily connect to a wide variety of services and systems without writing any code.

 Important

Today, you can only add standard Logic Apps (also known as single-tenant Logic Apps) as plugins. Consumption Logic Apps are coming soon.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#importing-logic-apps-as-plugins)

## Importing Logic Apps as plugins

To add Logic Apps workflows to Semantic Kernel, you'll use the same methods as loading in an [OpenAPI specifications](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins). Below is some sample code.

C#Copy

```
await kernel.ImportPluginFromOpenApiAsync(
    pluginName: "openapi_plugin",
    uri: new Uri("https://example.azurewebsites.net/swagger.json"),
    executionParameters: new OpenApiFunctionExecutionParameters()
    {
        // Determines whether payload parameter names are augmented with namespaces.
        // Namespaces prevent naming conflicts by adding the parent parameter name
        // as a prefix, separated by dots
        EnablePayloadNamespacing = true
    }
);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#setting-up-logic-apps-for-semantic-kernel)

## Setting up Logic Apps for Semantic Kernel

Before you can import a Logic App as a plugin, you must first set up the Logic App to be accessible by Semantic Kernel. This involves enabling metadata endpoints and configuring your application for Easy Auth before finally importing the Logic App as a plugin with authentication.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#enable-metadata-endpoints)

### Enable metadata endpoints

For the easiest setup, you can enable unauthenticated access to the metadata endpoints for your Logic App. This will allow you to import your Logic App as a plugin into Semantic Kernel without needing to create a custom HTTP client to handle authentication for the initial import.

The below host.json file will create two unauthenticated endpoints. You can do this in azure portal by [going to kudu console and editing the host.json file](https://learn.microsoft.com/en-us/azure/logic-apps/edit-app-settings-host-settings?tabs=azure-portal#manage-host-settings---hostjson) located at _C:\home\site\wwwroot\host.json_.

JSONCopy

```
{ 
  "version": "2.0", 
  "extensionBundle": { 
    "id": "Microsoft.Azure.Functions.ExtensionBundle.Workflows", 
    "version": "[1.*, 2.0.0)" 
  }, 
  "extensions": { 
    "http": { 
      "routePrefix": "" 
    }, 
    "workflow": { 
      "MetadataEndpoints": { 
        "plugin": { 
          "enable": true, 
          "Authentication":{ 
              "Type":"Anonymous" 
          } 
        }, 
        "openapi": { 
          "enable": true, 
          "Authentication":{ 
              "Type":"Anonymous" 
          } 
        } 
      }, 
      "Settings": { 
        "Runtime.Triggers.RequestTriggerDefaultApiVersion": "2020-05-01-preview" 
      } 
    } 
  } 
} 
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#configure-your-application-for-easy-auth)

### Configure your application for Easy Auth

You now want to secure your Logic App workflows so only authorized users can access them. You can do this by enabling Easy Auth on your Logic App. This will allow you to use the same authentication mechanism as your other Azure services, making it easier to manage your security policies.

For an in-depth walkthrough on setting up Easy Auth, refer to this tutorial titled [Trigger workflows in Standard logic apps with Easy Auth](https://techcommunity.microsoft.com/t5/azure-integration-services-blog/trigger-workflows-in-standard-logic-apps-with-easy-auth/ba-p/3207378).

For those already familiar with Easy Auth (and already have an Entra client app you want to use), this is the configuration you’ll want to post to Azure management.

BashCopy

```
#!/bin/bash

# Variables
subscription_id="[SUBSCRIPTION_ID]"
resource_group="[RESOURCE_GROUP]"
app_name="[APP_NAME]"
api_version="2022-03-01"
arm_token="[ARM_TOKEN]"
tenant_id="[TENANT_ID]"
aad_client_id="[AAD_CLIENT_ID]"
object_ids=("[OBJECT_ID_FOR_USER1]" "[OBJECT_ID_FOR_USER2]" "[OBJECT_ID_FOR_APP1]")

# Convert the object_ids array to a JSON array
object_ids_json=$(printf '%s\n' "${object_ids[@]}" | jq -R . | jq -s .)

# Request URL
url="https://management.azure.com/subscriptions/$subscription_id/resourceGroups/$resource_group/providers/Microsoft.Web/sites/$app_name/config/authsettingsV2?api-version=$api_version"

# JSON payload
json_payload=$(cat <<EOF
{
    "properties": {
        "platform": {
            "enabled": true,
            "runtimeVersion": "~1"
        },
        "globalValidation": {
            "requireAuthentication": true,
            "unauthenticatedClientAction": "AllowAnonymous"
        },
        "identityProviders": {
            "azureActiveDirectory": {
                "enabled": true,
                "registration": {
                    "openIdIssuer": "https://sts.windows.net/$tenant_id/",
                    "clientId": "$aad_client_id"
                },
                "validation": {
                    "jwtClaimChecks": {},
                    "allowedAudiences": [
                        "api://$aad_client_id"
                    ],
                    "defaultAuthorizationPolicy": {
                        "allowedPrincipals": {
                            "identities": $object_ids_json
                        }
                    }
                }
            },
            "facebook": {
                "enabled": false,
                "registration": {},
                "login": {}
            },
            "gitHub": {
                "enabled": false,
                "registration": {},
                "login": {}
            },
            "google": {
                "enabled": false,
                "registration": {},
                "login": {},
                "validation": {}
            },
            "twitter": {
                "enabled": false,
                "registration": {}
            },
            "legacyMicrosoftAccount": {
                "enabled": false,
                "registration": {},
                "login": {},
                "validation": {}
            },
            "apple": {
                "enabled": false,
                "registration": {},
                "login": {}
            }
        }
    }
}
EOF
)

# HTTP PUT request
curl -X PUT "$url" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $arm_token" \
    -d "$json_payload"
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#use-logic-apps-with-semantic-kernel-as-a-plugin)

### Use Logic Apps with Semantic Kernel as a plugin

Now that you have your Logic App secured and the metadata endpoints enabled, you’ve finished all the hard parts. You can now import your Logic App as a plugin into Semantic Kernel using the OpenAPI import method.

When you create your plugin, you’ll want to provide a custom HTTP client that can handle the authentication for your Logic App. This will allow you to use the plugin in your AI agents without needing to worry about the authentication.

Below is an example in C# that leverages interactive auth to acquire a token and authenticate the user for the Logic App.

C#Copy

```
string ClientId = "[AAD_CLIENT_ID]";
string TenantId = "[TENANT_ID]";
string Authority = $"https://login.microsoftonline.com/{TenantId}";
string[] Scopes = new string[] { "api://[AAD_CIENT_ID]/SKLogicApp" };

var app = PublicClientApplicationBuilder.Create(ClientId)
            .WithAuthority(Authority)
            .WithDefaultRedirectUri() // Uses http://localhost for a console app
            .Build();

AuthenticationResult authResult = null;
try
{
    authResult = await app.AcquireTokenInteractive(Scopes).ExecuteAsync();
}
catch (MsalException ex)
{
    Console.WriteLine("An error occurred acquiring the token: " + ex.Message);
}

// Add the plugin to the kernel with a custom HTTP client for authentication
kernel.Plugins.Add(await kernel.ImportPluginFromOpenApiAsync(
    pluginName: "[NAME_OF_PLUGIN]",
    uri: new Uri("https://[LOGIC_APP_NAME].azurewebsites.net/swagger.json"),
    executionParameters: new OpenApiFunctionExecutionParameters()
    {
        HttpClient = new HttpClient()
        {
            DefaultRequestHeaders =
            {
                Authorization = new AuthenticationHeaderValue("Bearer", authResult.AccessToken)
            }
        },
    }
));
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-logic-apps-as-plugins#next-steps)

## Next steps

Now that you know how to create a plugin, you can now learn how to use them with your AI agent. Depending on the type of functions you've added to your plugins, there are different patterns you should follow. For retrieval functions, refer to the [using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag) article. For task automation functions, refer to the [using task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions) article.

[Learn about using retrieval functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag)

1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-data-retrieval-functions-for-rag%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-data-retrieval-functions-for-rag%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Retrieve%20data%20from%20plugins%20for%20RAG%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-data-retrieval-functions-for-rag%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Retrieve%20data%20from%20plugins%20for%20RAG%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-data-retrieval-functions-for-rag%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Retrieve%20data%20from%20plugins%20for%20RAG%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Retrieve%20data%20from%20plugins%20for%20RAG%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-data-retrieval-functions-for-rag%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Using plugins for Retrieval Augmented Generation (RAG)

- Article
- 06/24/2024
- 1 contributor

Feedback

## In this article

1. [Semantic vs classic search](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#semantic-vs-classic-search)
2. [Dynamic vs pre-fetched data retrieval](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#dynamic-vs-pre-fetched-data-retrieval)
3. [Keeping data secure](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#keeping-data-secure)
4. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#next-steps)

Often, your AI agents must retrieve data from external sources to generate grounded responses. Without this additional context, your AI agents may hallucinate or provide incorrect information. To address this, you can use plugins to retrieve data from external sources.

When considering plugins for Retrieval Augmented Generation (RAG), you should ask yourself two questions:

1. How will you (or your AI agent) "search" for the required data? Do you need [semantic search](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#semantic-search) or [classic search](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#classic-search)?
2. Do you already know the data the AI agent needs ahead of time ([pre-fetched data](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#pre-fetched-data-retrieval)), or does the AI agent need to retrieve the data [dynamically](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#dynamic-data-retrieval)?
3. How will you keep your data secure and [prevent oversharing of sensitive information](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#keeping-data-secure)?

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#semantic-vs-classic-search)

## Semantic vs classic search

When developing plugins for Retrieval Augmented Generation (RAG), you can use two types of search: semantic search and classic search.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#semantic-search)

### Semantic Search

Semantic search utilizes vector databases to understand and retrieve information based on the meaning and context of the query rather than just matching keywords. This method allows the search engine to grasp the nuances of language, such as synonyms, related concepts, and the overall intent behind a query.

Semantic search excels in environments where user queries are complex, open-ended, or require a deeper understanding of the content. For example, searching for "best smartphones for photography" would yield results that consider the context of photography features in smartphones, rather than just matching the words "best," "smartphones," and "photography."

When providing an LLM with a semantic search function, you typically only need to define a function with a single search query. The LLM will then use this function to retrieve the necessary information. Below is an example of a semantic search function that uses Azure AI Search to find documents similar to a given query.

C#Copy

```
using System.ComponentModel;
using System.Text.Json.Serialization;
using Azure;
using Azure.Search.Documents;
using Azure.Search.Documents.Indexes;
using Azure.Search.Documents.Models;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.Embeddings;

public class InternalDocumentsPlugin
{
    private readonly ITextEmbeddingGenerationService _textEmbeddingGenerationService;
    private readonly SearchIndexClient _indexClient;

    public AzureAISearchPlugin(ITextEmbeddingGenerationService textEmbeddingGenerationService, SearchIndexClient indexClient)
    {
        _textEmbeddingGenerationService = textEmbeddingGenerationService;
        _indexClient = indexClient;
    }

    [KernelFunction("Search")]
    [Description("Search for a document similar to the given query.")]
    public async Task<string> SearchAsync(string query)
    {
        // Convert string query to vector
        ReadOnlyMemory<float> embedding = await _textEmbeddingGenerationService.GenerateEmbeddingAsync(query);

        // Get client for search operations
        SearchClient searchClient = _indexClient.GetSearchClient("default-collection");

        // Configure request parameters
        VectorizedQuery vectorQuery = new(embedding);
        vectorQuery.Fields.Add("vector");

        SearchOptions searchOptions = new() { VectorSearch = new() { Queries = { vectorQuery } } };

        // Perform search request
        Response<SearchResults<IndexSchema>> response = await searchClient.SearchAsync<IndexSchema>(searchOptions);

        // Collect search results
        await foreach (SearchResult<IndexSchema> result in response.Value.GetResultsAsync())
        {
            return result.Document.Chunk; // Return text from first result
        }

        return string.Empty;
    }

    private sealed class IndexSchema
    {
        [JsonPropertyName("chunk")]
        public string Chunk { get; set; }

        [JsonPropertyName("vector")]
        public ReadOnlyMemory<float> Vector { get; set; }
    }
}
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#classic-search)

### Classic Search

Classic search, also known as attribute-based or criteria-based search, relies on filtering and matching exact terms or values within a dataset. It is particularly effective for database queries, inventory searches, and any situation where filtering by specific attributes is necessary.

For example, if a user wants to find all orders placed by a particular customer ID or retrieve products within a specific price range and category, classic search provides precise and reliable results. Classic search, however, is limited by its inability to understand context or variations in language.

 Tip

In most cases, your existing services already support classic search. Before implementing a semantic search, consider whether your existing services can provide the necessary context for your AI agents.

Take for example, a plugin that retrieves customer information from a CRM system using classic search. Here, the AI simply needs to call the `GetCustomerInfoAsync` function with a customer ID to retrieve the necessary information.

C#Copy

```
using System.ComponentModel;
using Microsoft.SemanticKernel;

public class CRMPlugin
{
    private readonly CRMService _crmService;

    public CRMPlugin(CRMService crmService)
    {
        _crmService = crmService;
    }

    [KernelFunction("GetCustomerInfo")]
    [Description("Retrieve customer information based on the given customer ID.")]
    public async Task<Customer> GetCustomerInfoAsync(string customerId)
    {
        return await _crmService.GetCustomerInfoAsync(customerId);
    }
}
```

Achieving the same search functionality with semantic search would likely be impossible or impractical due to the non-deterministic nature of semantic queries.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#when-to-use-each)

### When to Use Each

Choosing between semantic and classic search depends on the nature of the query. It is ideal for content-heavy environments like knowledge bases and customer support where users might ask questions or look for products using natural language. Classic search, on the other hand, should be employed when precision and exact matches are important.

In some scenarios, you may need to combine both approaches to provide comprehensive search capabilities. For instance, a chatbot assisting customers in an e-commerce store might use semantic search to understand user queries and classic search to filter products based on specific attributes like price, brand, or availability.

Below is an example of a plugin that combines semantic and classic search to retrieve product information from an e-commerce database.

C#Copy

```
using System.ComponentModel;
using Microsoft.SemanticKernel;

public class ECommercePlugin
{
    [KernelFunction("search_products")]
    [Description("Search for products based on the given query.")]
    public async Task<IEnumerable<Product>> SearchProductsAsync(string query, ProductCategories category = null, decimal? minPrice = null, decimal? maxPrice = null)
    {
        // Perform semantic and classic search with the given parameters
    }
}
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#dynamic-vs-pre-fetched-data-retrieval)

## Dynamic vs pre-fetched data retrieval

When developing plugins for Retrieval Augmented Generation (RAG), you must also consider whether the data retrieval process is static or dynamic. This allows you to optimize the performance of your AI agents by retrieving data only when necessary.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#dynamic-data-retrieval)

### Dynamic data retrieval

In most cases, the user query will determine the data that the AI agent needs to retrieve. For example, a user might ask for the difference between two different products. The AI agent would then need to dynamically retrieve the product information from a database or API to generate a response using [function calling](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling). It would be impractical to pre-fetch all possible product information ahead of time and give it to the AI agent.

Below is an example of a back-and-forth chat between a user and an AI agent where dynamic data retrieval is necessary.

Expand table

|Role|Message|
|---|---|
|🔵 **User**|Can you tell me about the best mattresses?|
|🔴 **Assistant (function call)**|`Products.Search("mattresses")`|
|🟢 **Tool**|`[{"id": 25323, "name": "Cloud Nine"},{"id": 63633, "name": "Best Sleep"}]`|
|🔴 **Assistant**|Sure! We have both Cloud Nine and Best Sleep|
|🔵 **User**|What's the difference between them?|
|🔴 **Assistant (function call)**|`Products.GetDetails(25323)` `Products.GetDetails(63633)`|
|🟢 **Tool**|`{ "id": 25323, "name": "Cloud Nine", "price": 1000, "material": "Memory foam" }`|
|🟢 **Tool**|`{ "id": 63633, "name": "Best Sleep", "price": 1200, "material": "Latex" }`|
|🔴 **Assistant**|Cloud Nine is made of memory foam and costs $1000. Best Sleep is made of latex and costs $1200.|

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#pre-fetched-data-retrieval)

### Pre-fetched data Retrieval

Static data retrieval involves fetching data from external sources and _always_ providing it to the AI agent. This is useful when the data is required for every request or when the data is relatively stable and doesn't change frequently.

Take for example, an agent that always answers questions about the local weather. Assuming you have a `WeatherPlugin`, you can pre-fetch weather data from a weather API and provide it in the chat history. This allows the agent to generate responses about the weather without wasting time requesting the data from the API.

C#Copy

```
using System.Text.Json;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;

IKernelBuilder builder = Kernel.CreateBuilder();
builder.AddAzureOpenAIChatCompletion(deploymentName, endpoint, apiKey);
builder.Plugins.AddFromType<WeatherPlugin>();
Kernel kernel = builder.Build();

// Get the weather
var weather = await kernel.Plugins.GetFunction("WeatherPlugin", "get_weather").InvokeAsync(kernel);

// Initialize the chat history with the weather
ChatHistory chatHistory = new ChatHistory("The weather is:\n" + JsonSerializer.Serialize(weather));

// Simulate a user message
chatHistory.AddUserMessage("What is the weather like today?");

// Get the answer from the AI agent
IChatCompletionService chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();
var result = await chatCompletionService.GetChatMessageContentAsync(chatHistory);
```

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#keeping-data-secure)

## Keeping data secure

When retrieving data from external sources, it is important to ensure that the data is secure and that sensitive information is not exposed. To prevent oversharing of sensitive information, you can use the following strategies:

Expand table

|Strategy|Description|
|---|---|
|**Use the user's auth token**|Avoid creating service principals used by the AI agent to retrieve information for users. Doing so makes it difficult to verify that a user has access to the retrieved information.|
|**Avoid recreating search services**|Before creating a new search service with a vector DB, check if one already exists for the service that has the required data. By reusing existing services, you can avoid duplicating sensitive content, leverage existing access controls, and use existing filtering mechanisms that only return data the user has access to.|
|**Store reference in vector DBs instead of content**|Instead of duplicating sensitive content to vector DBs, you can store references to the actual data. For a user to access this information, their auth token must first be used to retrieve the real data.|

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-data-retrieval-functions-for-rag#next-steps)

## Next steps

Now that you now how to ground your AI agents with data from external sources, you can now learn how to use AI agents to automate business processes. To learn more, see [using task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions).

[Learn about task automation functions](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions)
1. [Learn](https://learn.microsoft.com/en-us/) 
 3. [Microsoft Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) 

Save

[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-task-automation-functions%3FWT.mc_id%3Dfacebook%26sharingId%3D119BC8B1C47F57ED)[](https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-task-automation-functions%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED&text=Today%20I%20completed%20%22Allow%20agents%20to%20automate%20tasks%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!&tw_p=tweetbutton&url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-task-automation-functions%3FWT.mc_id%3Dtwitter%26sharingId%3D119BC8B1C47F57ED)[](https://www.linkedin.com/feed/?shareActive=true&text=Today%20I%20completed%20%22Allow%20agents%20to%20automate%20tasks%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-task-automation-functions%3FWT.mc_id%3Dlinkedin%26sharingId%3D119BC8B1C47F57ED)[](mailto:?subject=%5BShared%20Article%5D%20Allow%20agents%20to%20automate%20tasks%20%7C%20Microsoft%20Learn&body=Today%20I%20completed%20%22Allow%20agents%20to%20automate%20tasks%20%7C%20Microsoft%20Learn%22!%20I%27m%20so%20proud%20to%20be%20celebrating%20this%20achievement%20and%20hope%20this%20inspires%20you%20to%20start%20your%20own%20%40MicrosoftLearn%20journey!%0A%0D%0Ahttps%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fsemantic-kernel%2Fconcepts%2Fplugins%2Fusing-task-automation-functions%3FWT.mc_id%3Demail%26sharingId%3D119BC8B1C47F57ED)

---

# Task automation with agents

- Article
- 09/09/2024
- 2 contributors

Feedback

Choose a programming language

C#PythonJava

## In this article

1. [Requiring user consent](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions?pivots=programming-language-csharp#requiring-user-consent)
2. [Next steps](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions?pivots=programming-language-csharp#next-steps)

Most AI agents today simply retrieve data and respond to user queries. AI agents, however, can achieve much more by using plugins to automate tasks on behalf of users. This allows users to delegate tasks to AI agents, freeing up time for more important work.

Once AI Agents start performing actions, however, it's important to ensure that they are acting in the best interest of the user. This is why we provide hooks / filters to allow you to control what actions the AI agent can take.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions?pivots=programming-language-csharp#requiring-user-consent)

## Requiring user consent

When an AI agent is about to perform an action on behalf of a user, it should first ask for the user's consent. This is especially important when the action involves sensitive data or financial transactions.

In Semantic Kernel, you can use the function invocation filter. This filter is always called whenever a function is invoked from an AI agent. To create a filter, you need to implement the `IFunctionInvocationFilter` interface and then add it as a service to the kernel.

Here's an example of a function invocation filter that requires user consent:

C#Copy

```
public class ApprovalFilterExample() : IFunctionInvocationFilter
{
    public async Task OnFunctionInvocationAsync(FunctionInvocationContext context, Func<FunctionInvocationContext, Task> next)
    {
        if (context.Function.PluginName == "DynamicsPlugin" && context.Function.Name == "create_order")
        {
            Console.WriteLine("System > The agent wants to create an approval, do you want to proceed? (Y/N)");
            string shouldProceed = Console.ReadLine()!;

            if (shouldProceed != "Y")
            {
                context.Result = new FunctionResult(context.Result, "The order creation was not approved by the user");
                return;
            }

            await next(context);
        }
    }
}
```

You can then add the filter as a service to the kernel:

C#Copy

```
IKernelBuilder builder = Kernel.CreateBuilder();
builder.Services.AddSingleton<IFunctionInvocationFilter, ApprovalFilterExample>();
Kernel kernel = builder.Build();
```

Now, whenever the AI agent tries to create an order using the `DynamicsPlugin`, the user will be prompted to approve the action.

 Tip

Whenever a function is cancelled or fails, you should provide the AI agent with a meaningful error message so it can respond appropriately. For example, if we didn't let the AI agent know that the order creation was not approved, it would assume that the order failed due to a technical issue and would try to create the order again.

[](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/using-task-automation-functions?pivots=programming-language-csharp#next-steps)

## Next steps

Now that you've learned how to allow agents to automate tasks, you can learn how to allow agents to automatically create plans to address user needs.
Semantic Kernel Built-in Plugins.md
1.73 KB • 43 extracted lines
Formatting may be inconsistent from source.
# Semantic Kernel Built-in Plugins

Semantic Kernel comes with several built-in plugins that provide various functionalities out of the box. Here's a list of these plugins along with brief descriptions:

1. **ConversationSummaryPlugin**
   - Summarizes conversations or text, useful for maintaining context in long interactions.

2. **TextMemoryPlugin**
   - Manages text-based memories, allowing for storage and retrieval of information.

3. **TimePlugin**
   - Provides various time-related functions, such as getting the current time, date, and performing time calculations.

4. **HttpPlugin**
   - Enables making HTTP requests, useful for interacting with web services and APIs.

5. **MathPlugin**
   - Performs basic mathematical operations and evaluations.

6. **TextPlugin**
   - Offers text manipulation functions like trimming, uppercase/lowercase conversion, and text length calculation.

7. **WaitPlugin**
   - Introduces delays in execution, useful for rate limiting or simulating time-consuming processes.

8. **WebSearchEnginePlugin**
   - Provides web search capabilities, allowing AI to access current information from the internet.

9. **LanguageCalculatorPlugin**
   - Interprets natural language expressions for mathematical calculations.

10. **PlannerPlugin**
    - Helps in creating and executing plans based on goals and available functions.

11. **FileIOPlugin**
    - Handles file input/output operations, including reading from and writing to files.

12. **GrpcPlugin**
    - Enables interaction with gRPC services, facilitating communication with other microservices.

These built-in plugins provide a solid foundation for many common tasks and can be easily extended or customized to suit specific needs in your Semantic Kernel applications.


